<!DOCTYPE html><html lang="zh-CN"><head><meta charset="utf-8"><meta name="X-UA-Compatible" content="IE=edge"><meta name="author"><title>Common - Resume · KLEON</title><meta name="description" content="Resumes.



TODO
Outline
Backend Developer Engineer

Experience
Skills


Machine Learning Engineer
后端开发工程师

工作经历


Q&amp;amp;A

Video Enhancement
Intellig"><meta name="og:description" content="Resumes.



TODO
Outline
Backend Developer Engineer

Experience
Skills


Machine Learning Engineer
后端开发工程师

工作经历


Q&amp;amp;A

Video Enhancement
Intellig"><meta name="twitter:site" content="KLEON"><meta name="twitter:title" content="Common - Resume"><meta name="twitter:card" content="summary"><meta name="keywords" content=""><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="renderer" content="webkit"><link rel="short icon" href="images/favicon.png" type="image/x-icon"><link rel="stylesheet" href="/css/github.min.css"><link rel="stylesheet" href="/css/bootstrap.min.css"><link rel="stylesheet" href="/css/font-awesome.min.css"><link rel="stylesheet" href="https://lf9-cdn-tos.bytecdntp.com/cdn/expire-1-M/KaTeX/0.10.2/katex.min.css"><link rel="stylesheet" href="/css/style.css"><link rel="alternate" type="application/atom+xml" title="ATOM 1.0" href="/atom.xml"><meta name="generator" content="Hexo 6.1.0"></head><body><div id="stage" class="container"><div class="row"><div id="side-bar" class="col-sm-3 col-xs-12 side-container invisible"><div class="vertical-text site-title"><h3 tabindex="-1" class="site-title-small"><a href="/" class="a-title"></a></h3><h1 tabindex="-1" class="site-title-large"><a href="/" class="a-title">吹拉弹唱</a></h1><!--h6(onclick="triggerSiteNav()") Trigger--></div><br class="visible-lg visible-md visible-sm"><div id="site-nav" class="site-title-links"><ul><li><a href="/">Home</a></li><li><a href="/archives">Archive</a></li><li><a href="/categories">Categories</a></li><li><a href="/tags">Tags</a></li><li><a href="/googlebe23cb0bc55fc412.html"></a></li><li><a href="/about/index.html"></a></li><li class="soc"><a href="https://github.com/kleon1024" target="_blank" rel="noopener noreferrer" aria-label="Github"><i class="fa fa-github">&nbsp;</i></a></li></ul><div class="visible-lg visible-md visible-sm site-nav-footer"><br class="site-nav-footer-br"><footer><p>&copy;&nbsp;2022&nbsp;<a target="_blank" href="https://blog.kleon.space" rel="noopener noreferrer">Kleon</a></p><p>Theme&nbsp;<a target="_blank" href="https://github.com/SumiMakito/hexo-theme-typography" rel="noopener noreferrer">Typography</a>&nbsp;by&nbsp;<a target="_blank" href="https://www.keep.moe" rel="noopener noreferrer">Makito</a></p><p>Proudly published with&nbsp;<a target="_blank" href="https://hexo.io" rel="noopener noreferrer">Hexo</a></p></footer></div></div></div><div id="main-container" class="col-sm-9 col-xs-12 main-container invisible"><div class="autopagerize_page_element"><div class="content"><div class="post-page"><div class="post-container"><p class="post-title"><a>Common - Resume</a></p><p class="post-meta"><span class="date meta-item">Posted at&nbsp;2022-04-20</span><span class="date meta-item">Updated at&nbsp;2022-05-14</span><span class="meta-item"><i class="fa fa-folder"></i><span>&nbsp;</span><a href="/categories/interview/" title="interview" class="a-tag">interview</a><span>&nbsp;</span></span><span class="meta-item"><i class="fa fa-tag"></i><span>&nbsp;</span><a href="/tags/interview/" title="interview" class="a-tag">interview</a><span>&nbsp;</span></span></p><p class="post-abstract"><p>Resumes.</p>
<div class="toc">
<!-- toc -->
<ul>
<li><a href="#todo">TODO</a></li>
<li><a href="#outline">Outline</a></li>
<li><a href="#backend-developer-engineer">Backend Developer Engineer</a>
<ul>
<li><a href="#experience">Experience</a></li>
<li><a href="#skills">Skills</a></li>
</ul>
</li>
<li><a href="#machine-learning-engineer">Machine Learning Engineer</a></li>
<li><a href="#hou-duan-kai-fa-gong-cheng-shi">后端开发工程师</a>
<ul>
<li><a href="#gong-zuo-jing-li">工作经历</a></li>
</ul>
</li>
<li><a href="#q-a">Q&amp;A</a>
<ul>
<li><a href="#video-enhancement">Video Enhancement</a></li>
<li><a href="#intelligent-marketing-platform">Intelligent Marketing Platform</a></li>
<li><a href="#recommend-system-recommend-engine">Recommend System &amp; Recommend Engine</a></li>
<li><a href="#performance-optimization-of-inference">Performance Optimization of Inference</a></li>
<li><a href="#self-developed-fpga-inference-acceleration-chip-solution">Self-developed FPGA inference acceleration chip solution</a></li>
<li><a href="#devops">DevOps</a></li>
<li><a href="#gao-bing-fa">高并发</a></li>
<li><a href="#liang-dian-zu-gou-shen-ru-zu-gou-liao-jie">亮点，足够深入，足够了解</a></li>
</ul>
</li>
</ul>
<!-- tocstop -->
</div>
<h1><a href="#todo" class="header-anchor">#</a><span id="todo"> TODO</span></h1>
<p><input type="checkbox" id="checkbox11"><label for="checkbox11">CAP</label><br>
<input type="checkbox" id="checkbox10"><label for="checkbox10">LoadBalance</label><br>
<input type="checkbox" id="checkbox9"><label for="checkbox9">Reverse-Proxy</label><br>
<input type="checkbox" id="checkbox8"><label for="checkbox8">Distributed Database</label><br>
<input type="checkbox" id="checkbox7"><label for="checkbox7">Distributed Transaction</label><br>
<input type="checkbox" id="checkbox6"><label for="checkbox6">Cache</label><br>
<input type="checkbox" id="checkbox5"><label for="checkbox5">CDN</label><br>
<input type="checkbox" id="checkbox4"><label for="checkbox4">Microservices</label><br>
<input type="checkbox" id="checkbox3"><label for="checkbox3">Service Discovery</label><br>
<input type="checkbox" id="checkbox2"><label for="checkbox2">Asynchronism</label><br>
<input type="checkbox" id="checkbox1"><label for="checkbox1">Communication Protocol</label><br>
<input type="checkbox" id="checkbox0"><label for="checkbox0">Security</label></p>
<p><input type="checkbox" id="checkbox16" checked="true"><label for="checkbox16">Redis</label><br>
<input type="checkbox" id="checkbox15" checked="true"><label for="checkbox15">ZooKeepr</label><br>
<input type="checkbox" id="checkbox14" checked="true"><label for="checkbox14">Kafka</label><br>
<input type="checkbox" id="checkbox13"><label for="checkbox13">RocketMQ</label><br>
<input type="checkbox" id="checkbox12"><label for="checkbox12">RabbitMQ</label></p>
<p><input type="checkbox" id="checkbox22"><label for="checkbox22">MySQL</label><br>
<input type="checkbox" id="checkbox21"><label for="checkbox21">PostgreSQL</label><br>
<input type="checkbox" id="checkbox20"><label for="checkbox20">MongoDB</label><br>
<input type="checkbox" id="checkbox19"><label for="checkbox19">HBase</label><br>
<input type="checkbox" id="checkbox18"><label for="checkbox18">Cassandra</label><br>
<input type="checkbox" id="checkbox17"><label for="checkbox17">Hologres</label></p>
<p><input type="checkbox" id="checkbox25"><label for="checkbox25">Kubernetes</label><br>
<input type="checkbox" id="checkbox24"><label for="checkbox24">Docker</label><br>
<input type="checkbox" id="checkbox23"><label for="checkbox23">Helm</label></p>
<p><input type="checkbox" id="checkbox28"><label for="checkbox28">Golang</label><br>
<input type="checkbox" id="checkbox27"><label for="checkbox27">Python</label><br>
<input type="checkbox" id="checkbox26"><label for="checkbox26">C++</label></p>
<p><input type="checkbox" id="checkbox33"><label for="checkbox33">Operating System</label><br>
<input type="checkbox" id="checkbox32"><label for="checkbox32">Network</label><br>
<input type="checkbox" id="checkbox31"><label for="checkbox31">Security/Authentication</label><br>
<input type="checkbox" id="checkbox30"><label for="checkbox30">CPU</label><br>
<input type="checkbox" id="checkbox29"><label for="checkbox29">GPU/CUDA</label></p>
<p><input type="checkbox" id="checkbox51"><label for="checkbox51">Tensorflow</label><br>
<input type="checkbox" id="checkbox50"><label for="checkbox50">PyTorch</label><br>
<input type="checkbox" id="checkbox49"><label for="checkbox49">Training</label><br>
<input type="checkbox" id="checkbox48"><label for="checkbox48">Inference</label><br>
<input type="checkbox" id="checkbox47"><label for="checkbox47">TensorRT</label><br>
<input type="checkbox" id="checkbox46"><label for="checkbox46"></label><s>TVM</s><br>
<input type="checkbox" id="checkbox45"><label for="checkbox45">ONNX Runtime</label><br>
<input type="checkbox" id="checkbox44"><label for="checkbox44">SR</label><br>
<input type="checkbox" id="checkbox43"><label for="checkbox43">GAN</label><br>
<input type="checkbox" id="checkbox42"><label for="checkbox42">ffmpeg</label><br>
<input type="checkbox" id="checkbox41"><label for="checkbox41">Feature Engineering</label><br>
<input type="checkbox" id="checkbox40"><label for="checkbox40">Sms Recall Modeling/Cross Validation</label><br>
<input type="checkbox" id="checkbox39"><label for="checkbox39">LR</label><br>
<input type="checkbox" id="checkbox38"><label for="checkbox38">GBDT/XGBOOST/RF</label><br>
<input type="checkbox" id="checkbox37"><label for="checkbox37">Overfit/Underfit/Feature Selecting/Data Clean</label><br>
<input type="checkbox" id="checkbox36"><label for="checkbox36">Recommend System</label><br>
<input type="checkbox" id="checkbox35"><label for="checkbox35">Recommend Modeling</label><br>
<input type="checkbox" id="checkbox34"><label for="checkbox34">KubeFlow</label></p>
<p><input type="checkbox" id="checkbox58"><label for="checkbox58">CI</label><br>
<input type="checkbox" id="checkbox57"><label for="checkbox57">Testing/Pressure Testing</label><br>
<input type="checkbox" id="checkbox56"><label for="checkbox56">System Level Optimization</label><br>
<input type="checkbox" id="checkbox55"><label for="checkbox55">Release</label><br>
<input type="checkbox" id="checkbox54"><label for="checkbox54">CR</label><br>
<input type="checkbox" id="checkbox53"><label for="checkbox53">Code Format</label><br>
<input type="checkbox" id="checkbox52"><label for="checkbox52">Team</label></p>
<p><input type="checkbox" id="checkbox65"><label for="checkbox65">Spark</label><br>
<input type="checkbox" id="checkbox64"><label for="checkbox64">Spark Streaming</label><br>
<input type="checkbox" id="checkbox63"><label for="checkbox63">Flink</label><br>
<input type="checkbox" id="checkbox62"><label for="checkbox62">MapReduce</label><br>
<input type="checkbox" id="checkbox61"><label for="checkbox61">Hive</label><br>
<input type="checkbox" id="checkbox60"><label for="checkbox60">Hadoop</label><br>
<input type="checkbox" id="checkbox59"><label for="checkbox59">ES</label></p>
<p><input type="checkbox" id="checkbox68"><label for="checkbox68">Event Tracking埋点</label><br>
<input type="checkbox" id="checkbox67"><label for="checkbox67">LogStash</label><br>
<input type="checkbox" id="checkbox66"><label for="checkbox66">ETL</label></p>
<h1><a href="#outline" class="header-anchor">#</a><span id="outline"> Outline</span></h1>
<ol>
<li>Business background</li>
<li>Solution</li>
<li>Implementation</li>
<li>Result (explained with data)</li>
<li>Problem/Bad case</li>
<li>Optimization</li>
</ol>
<h1><a href="#backend-developer-engineer" class="header-anchor">#</a><span id="backend-developer-engineer"> Backend Developer Engineer</span></h1>
<p>Mainly focus on the backend system design, middleware (MySQL/Postgres, Redis, Kafka, MongoDB) and golang.</p>
<h2><a href="#experience" class="header-anchor">#</a><span id="experience"> Experience</span></h2>
<p><strong>Senior Software Engineer</strong>, (August 2020 - present)<br>
Backend architecture and developer for AI application and SaaS, including recommendation engine, marketing platform with SMS ability. Integrated into Ali Cloud’s finance system.</p>
<ul>
<li>A general recommendation engine platform for traditional company like short videos, game distribution, e-commerce company.</li>
<li>A platform for marketing campaign integrated with algorithms predicting user behaviors and sms functionality.</li>
<li>A platform for video processing with the ability of AI enhancement. How many, how large, what kind of algorithm, performance, optimization?</li>
</ul>
<p><strong>Software Engineer</strong>, (July 2018 - July 2020)<br>
Developer on hardware, framework and inference optimization.</p>
<ul>
<li>Participated in the development of hardware accelerator of deep learning model. Designed and developed the hardware logic in Verilog, the universal runtime adapting different hardware arch and model in C++, integrated into Tensorflow and more.</li>
<li>Performance optimization with tools of TVM, TensorRT, Intel OneDNN and anything else.</li>
<li>Participated in the development of platform for AI infrastructure, including notebook, training platform, serverless inference platform.</li>
</ul>
<h2><a href="#skills" class="header-anchor">#</a><span id="skills"> Skills</span></h2>
<ul>
<li>Programming language of Golang, Python, C++, dart, javascript.</li>
<li>Knowledge of AI application, including recommendation engine, video enhancement.</li>
</ul>
<h1><a href="#machine-learning-engineer" class="header-anchor">#</a><span id="machine-learning-engineer"> Machine Learning Engineer</span></h1>
<p>Mainly focus on the framework (Tensorflow/PyTorch), specific algorithms and business applications.</p>
<h1><a href="#hou-duan-kai-fa-gong-cheng-shi" class="header-anchor">#</a><span id="hou-duan-kai-fa-gong-cheng-shi"> 后端开发工程师</span></h1>
<h2><a href="#gong-zuo-jing-li" class="header-anchor">#</a><span id="gong-zuo-jing-li"> 工作经历</span></h2>
<p><strong>高级开发工程师</strong> 2020-present</p>
<blockquote>
<p>AI Model/Go/Devops</p>
</blockquote>
<ul>
<li><strong>云端视频增强</strong>。技术责任人。负责设计实现云端视频增强服务，效果指标与友商基本持平，单位视频时间转换成本较友商公开数据低50%以上，在中小型电商与短视频平台尝试落地。模型效果层面，基于主流SISR模型，通过扩充训练集加入人像、字符、纹理等数据、业务场景数据fine-tune、调整模型结构、使用多种退化与增强做数据预处理等方法，模型可快速适配不同业务场景下的主观评分，平衡高频细节保留与降噪能力，同时避免了常见的伪影纹波等效应；模型性能层面，通过精简模型结构、量化与序列化等方法大幅提升推理性能，同时维持主观效果基本持平；服务层面使用Go提供API与任务状态同步、回调等服务，Python运行模型增强与编码服务，Kafka作为任务队列，通过Kubernetes集群弹性调度同时支持数百任务同时运行。</li>
</ul>
<blockquote>
<p>想想细节，分布式任务调度，遇到的问题和解决方案，分布式任务是job还是service。如果job怎么避免pull image的overhead，image cache是什么原理，GPU机器在image pulling时浪费的资源怎么算？如果是service，怎么解决分布式读数据库锁问题？有使用任务队列吗？Celery利弊？Kafka利弊？模型和编码怎么balance的？原始视频体积过大带宽受得了吗？用什么分布式存储？你觉得minio合适吗？pod之间共享怎么做？看过ffmpeg代码吗？</p>
</blockquote>
<ul>
<li><strong>营销增长平台</strong>。设计实现短信相关的内容注册与发送服务，管理营销相关的召回打分算法任务，与阿里云南天门产品和计量计费接口对接。短信服务基于Hologres(列存)与Kafka支持上万QPS短信输入，可支持每日千万级短信发送，通过分区表减小数据查询压力，通过拆分微服务配合k8s弹性扩缩容，包括API，短信发送，失败短信重发，发送统计，短信回执校验，定时分区，客户回执back-off推送，实时计费计量，定时短信服务，算法任务管理，监控服务等。算法层面支持通用数据传输协议，基于客户提供的数据质量，转化率有1-10%等不同程度的提升。</li>
</ul>
<blockquote>
<p>所以业务是发营销短信？通过算法节约成本或提高转化率。了解分布式任务系统吗？Kafka怎么用的？基本指标？为什么这么快？Hologres和HBase有什么区别？为什么不用MySQL，为什么不用MongoDB，为什么不用Redis。有流控吗？这么大QPS 数据库latency在多少？怎么优化的？开发过程中有遇到什么瓶颈吗？Kafka出错怎么处理？用的什么算法？怎么做通用化？有具体场景数据吗？k8s了解吗？怎么提供的服务？ingress是什么？有用过deployment吗？StatefulSet干什么的？k8s的基本模块了解吗？k8s遇到过性能问题吗？知道operator吗？写过吗？CRD写过吗？知道k8s底层资源限制是什么原理吗？</p>
</blockquote>
<ul>
<li><strong>推荐引擎</strong>。在跨境电商、短视频、游戏分发平台落地，业务指标提升满足客户需求。设计实现引擎架构，基于Golang实现，支持多数据源，支持召回(i2i,u2i,cf,离线)，打分，排序（精排，粗排，重排，加权），支持分页和已读过滤，支持离在线模型，支持客户端/服务端实时/近实时特征拼接(item/user/context)等功能，通用化+模块化的设计使得快速迁移到不同项目。</li>
</ul>
<blockquote>
<p>业务里用过什么模型？取得的效果如何？怎么通用化？怎么模块化？有遇到什么瓶颈吗？算法正确性怎么debug的？模块支持debug tracing，怎么实现的？有做什么性能优化吗？go的channel死锁知道吗？go为什么快？你们整个推荐端到端延迟是多少？模型怎么服务的？TensorFlow/PyTorch？模型怎么优化的？推荐类模型怎么优化的？模型训练知道吗？你们的Embedding怎么优化？有预热吗？有Cache吗？有Redis Cache吗？有Prefetch吗？模型怎么动态更新的？服务切流怎么不影响？服务版本和模型版本怎么适配的？有做Feature Store吗？离线特征怎么算的？在线特征是指什么？怎么拼接处理的？实时特征拼接指什么？怎么做的？Go有什么性能优化技巧吗？如果panic了怎么debug吗？数据库connection泄露了怎么查？sql相关有什么坑吗？怎么处理慢SQL？</p>
</blockquote>
<p><strong>开发工程师</strong> 2018-2020</p>
<blockquote>
<p>C++/Python/Tensorflow/PyTorch/TensorRT/Verilog</p>
</blockquote>
<ul>
<li>
<p><strong>推理优化</strong>。基于社区与厂商方案的集成推理优化工具。主要针对Intel CPU与NVidia GPU，使用如MKL-DNN，OpenVINO，TensorRT，TVM，ONNX Runtime等，从图层面、算子层面与系统层面进行优化，硬件不变的条件下加速比在2-5倍左右，模型服务端到端RT下降20%-80%。</p>
</li>
<li>
<p><strong>硬件加速</strong>。利用FPGA加速深度学习模型，支持CV，TTS，推荐类型模型，为芯片架构预研。负责编写硬件逻辑，软件通用化runtime与compiler, 以及接入Tensorflow，通过EAS平台(k8s model serving)/容器化/定制板卡等形式输出，模型加速效果数十倍到数百倍。</p>
</li>
</ul>
<h1><a href="#q-amp-a" class="header-anchor">#</a><span id="q-amp-a"> Q&amp;A</span></h1>
<h2><a href="#video-enhancement" class="header-anchor">#</a><span id="video-enhancement"> Video Enhancement</span></h2>
<p><strong>分布式任务系统</strong></p>
<ul>
<li>
<p>1 分布式任务是怎么实现的？基于 Job 还是 Service？</p>
<p>使用k8s的job和service来实现，自动调度和资源分配。</p>
</li>
<li>
<p>1.1 如果基于Job，怎么怎么避免image pull的overhead？</p>
<p>有两点，一个我们是基于ECI和ECS开发的，ECI是Elastic Container Image，负责弹性，ECS负责固定，ECI提供了ImageCache功能避免Image Pull。另一点是我们提前预热拉取image，随后就不需要了。</p>
</li>
<li>
<p>1.1.1 ImageCache的原理是什么？</p>
<p>一般情况下，k8s的node是VM，也就对应一个VM image，而eci维持了一个VM的pool，可以直接分配给第三方集群，同时提前制作一个ImageCache就相当于提前打包了一个包含目标docker image的VM image，启动pod时，eci会通过docker image的特征值查找对应的VM image，如果找到了就直接用对应的VM image，如此ECI就会assign pod到使用对应VM image的VM Node上，避免了每次的docker image重复拉取。基本上ImageCache可以做到30s内的启动。相对于ECS的弹性和docker image需要数分钟时间的启动过程，已经比较快了。</p>
</li>
<li>
<p>1.2 GPU在Pulling的时候占用Node吗？</p>
<p>问题在问Pod的生命周期<sup class="footnote-ref"><a href="#fn1" id="fnref1">[1]</a></sup>，容器Pulling的时候，Pod已经Scheduled了，Pod处于Pending状态。Pod处于Succeeded或Failed状态时释放资源。</p>
</li>
</ul>
<hr>
<ul>
<li>
<p>⚠️2 怎么处理任务状态同步问题？</p>
<p>任务直连数据库。</p>
</li>
<li>
<p>2.1 数据库连接数满了怎么办？你这个方案最多能支持多少任务并行？如果连接数满了，状态会不会丢，会不会卡任务？</p>
<p>扩容数据库？取决于连接数，会存在你说的情况。</p>
</li>
<li>
<p>2.1.1 可以优化一下吗？</p>
<p>使用状态写入服务批量写入，任务retry，可以扩容。但是实际还是出现了状态同步丢失的情况。<br>
或许可以状态写入服务可以加一个消息队列缓冲一下，from 3。</p>
</li>
<li>
<p>2</p>
</li>
</ul>
<hr>
<ul>
<li>
<p>⚠️3 如果是Service怎么实现的？</p>
<p>每个Service从数据库读取任务并且同步状态。</p>
</li>
<li>
<p>3.1 服务之间会重复读取吗？</p>
<p>有可能，需要加个分布式锁。</p>
</li>
<li>
<p>⚠️3.1.1 怎么加分布式锁？</p>
<p>参考<sup class="footnote-ref"><a href="#fn2" id="fnref2">[2]</a></sup><sup class="footnote-ref"><a href="#fn3" id="fnref3">[3]</a></sup></p>
<ol>
<li>ZooKeeper的临时顺序节点</li>
<li>Redis的setnx()、expire() 或者 setnx()、get()、getset()做分布式锁。</li>
</ol>
<p>分布式锁需要满足：</p>
<ul>
<li>互斥性: 任意时刻，只有一个客户端能持有锁。</li>
<li>锁超时释放：持有锁超时，可以释放，防止不必要的资源浪费，也可以防止死锁。</li>
<li>可重入性:一个线程如果获取了锁之后,可以再次对其请求加锁。</li>
<li>高性能和高可用：加锁和解锁需要开销尽可能低，同时也要保证高可用，避免分布式锁失效。</li>
<li>安全性：锁只能被持有的客户端删除，不能被其他客户端删除</li>
</ul>
</li>
<li>
<p>3.1.2 ZooKeeper知道吗？介绍一下加锁原理？ZooKeeper是Kafka的基本组件。</p>
<p><sup class="footnote-ref"><a href="#fn4" id="fnref4">[4]</a></sup><sup class="footnote-ref"><a href="#fn5" id="fnref5">[5]</a></sup></p>
<p>Zookeeper可以创建ephemeral sequence node，当多个客户端发起创建请求时，zookeeper会根据先后顺序创建一系列自增序号的ephemeral node，客户端获取同级兄弟节点，如果自己的序号是最小的，则说明加锁成功，否则向当前最小的节点注册监听器，当最小的节点被移除时，再次判断是否是序号最小的。</p>
<p>pros: 有效的解决单点问题，不可重入问题，非阻塞问题以及锁无法释放的问题。实现起来较为简单。<br>
cons: 性能上可能并没有缓存服务那么高，因为每次在创建锁和释放锁的过程中，都要动态创建、销毁临时节点来实现锁功能。ZK 中创建和删除节点只能通过 Leader 服务器来执行，然后将数据同步到所有的 Follower 机器上。还需要对 ZK的原理有所了解。</p>
</li>
<li>
<p>3.1.2.1 ZooKeeper怎么用的？API有哪些？</p>
<p>create_node flag.Ephemeral flag.Sequence<br>
set_node<br>
get_node</p>
</li>
<li>
<p>3.1.2.2 ZooKeeper有哪些应用？</p>
<ul>
<li>分布式锁</li>
<li>分布式协调</li>
<li>发布订阅</li>
<li>命名服务</li>
</ul>
</li>
<li>
<p>3.1.2.3 ZooKeeper 集群，ZooKeeper是怎么保证高可用的？</p>
<ul>
<li>
<p>ZAB协议<br>
Leader，Follower，Observer模式。Observer不参与投票。<br>
当Leader挂掉之后，进入恢复模式。</p>
<ul>
<li>选举出来的Leader的zxid一定要是所有的Follower中最大的</li>
<li>并且已有超过半数的Follower返回了ACK，表示认可选举出来的Leader<br>
选举出新Leader之后，进入广播模式。使用2PC(两阶段提交)保证可靠性（一致性）。n/2+1个ACK回复才提交。</li>
</ul>
</li>
<li>
<p>Leader election</p>
</li>
<li>
<p>Discovery (E#epoch establish)</p>
</li>
<li>
<p>Synchronization (5X#sync with followers)</p>
</li>
<li>
<p>Broadcast</p>
</li>
</ul>
</li>
<li>
<p>3.1.2.4 如何部署ZooKeeper集群？</p>
<p>参考<sup class="footnote-ref"><a href="#fn6" id="fnref6">[6]</a></sup><br>
没有实际部署过，但基于k8s应该有可用的operator。或者自己使用StatefulSet部署。</p>
</li>
<li>
<p>3.1.3 Redis是怎么加锁的？具体说说会有什么问题吗？</p>
<p>方案一：SETNX + EXPIRE<br>
setnx(lockkey, 1)，因为操作是原子的，如果返回 0，则说明占位失败；如果返回 1，则说明占位成功</p>
<p>在setnx之后如果redis挂掉了就会发生死锁。</p>
<p>可以用expire命令对lockkey设置超时时间。</p>
<p>但是这样做如果redis在setnx与expire之间挂掉也会死锁。</p>
<p>方案二：可以用setnx()、get()、getset()组合拳。SETNX + value值是(系统时间+过期时间)</p>
<ol>
<li>setnx(lockkey, 当前时间+过期超时时间)，如果返回 1，则获取锁成功；如果返回 0 则没有获取到锁，转向 2。</li>
<li>get(lockkey) 获取值 oldExpireTime ，并将这个 value 值与当前的系统时间进行比较，如果小于当前系统时间，则认为这个锁已经超时，可以允许别的请求重新获取，转向 3。</li>
<li>计算 newExpireTime = 当前时间+过期超时时间，然后 getset(lockkey, newExpireTime) 会返回当前 lockkey 的值currentExpireTime。</li>
<li>判断 currentExpireTime 与 oldExpireTime 是否相等，如果相等，说明当前 getset 设置成功，获取到了锁。如果不相等，说明这个锁又被别的请求获取走了，那么当前请求可以直接返回失败，或者继续重试。</li>
<li>在获取到锁之后，当前线程可以开始自己的业务处理，当处理完毕后，比较自己的处理时间和对于锁设置的超时时间，如果小于锁设置的超时时间，则直接执行 delete 释放锁；如果大于锁设置的超时时间，则不需要再锁进行处理。</li>
</ol>
<p>pros: 解决了方案一的问题<br>
cons:</p>
<ul>
<li>过期时间是客户端自己生成的（System.currentTimeMillis()是当前系统的时间），必须要求分布式环境下，每个客户端的时间必须同步。</li>
<li>如果锁过期的时候，并发多个客户端同时请求过来，都执行jedis.getSet()，最终只能有一个客户端加锁成功，但是该客户端锁的过期时间，可能被别的客户端覆盖</li>
<li>该锁没有保存持有者的唯一标识，可能被别的客户端释放/解锁。</li>
</ul>
<p>方案三：使用Lua脚本(包含SETNX + EXPIRE两条指令)</p>
<p>lua保证原子性，可查看redis lua指南<sup class="footnote-ref"><a href="#fn7" id="fnref7">[7]</a></sup></p>
<figure class="highlight lua"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs lua"><span class="hljs-keyword">if</span> redis.call(<span class="hljs-string">&#x27;setnx&#x27;</span>,KEYS[<span class="hljs-number">1</span>],ARGV[<span class="hljs-number">1</span>]) == <span class="hljs-number">1</span> <span class="hljs-keyword">then</span><br>  redis.call(<span class="hljs-string">&#x27;expire&#x27;</span>,KEYS[<span class="hljs-number">1</span>],ARGV[<span class="hljs-number">2</span>])<br><span class="hljs-keyword">else</span><br>  <span class="hljs-keyword">return</span> <span class="hljs-number">0</span><br><span class="hljs-keyword">end</span>;<br></code></pre></td></tr></table></figure>
<p>加锁代码如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-type">String</span> <span class="hljs-variable">lua_scripts</span> <span class="hljs-operator">=</span> <span class="hljs-string">&quot;if redis.call(&#x27;setnx&#x27;,KEYS[1],ARGV[1]) == 1 then&quot;</span> +<br>          <span class="hljs-string">&quot; redis.call(&#x27;expire&#x27;,KEYS[1],ARGV[2]) return 1 else return 0 end&quot;</span>;   <br><span class="hljs-type">Object</span> <span class="hljs-variable">result</span> <span class="hljs-operator">=</span> jedis.eval(lua_scripts, Collections.singletonList(key_resource_id), Collections.singletonList(values));<br><span class="hljs-comment">//判断是否成功</span><br><span class="hljs-keyword">return</span> result.equals(<span class="hljs-number">1L</span>);<br></code></pre></td></tr></table></figure>
<p>但保证原子性还不够，还有和方案四一样的缺点。</p>
<p>方案四：SET的扩展命令（SET EX PX NX）引入setnx expire的原子操作</p>
<p><code>SET key value[EX seconds][PX milliseconds][NX|XX]</code></p>
<blockquote>
<p>NX :表示key不存在的时候，才能set成功，也即保证只有第一个客户端请求才能获得锁，而其他客户端请求只能等其释放锁，才能获取。<br>
EX seconds :设定key的过期时间，时间单位是秒。<br>
PX milliseconds: 设定key的过期时间，单位为毫秒<br>
XX: 仅当key存在时设置值</p>
</blockquote>
<p><code>jedis.set(key_resource_id, lock_value, &quot;NX&quot;, &quot;EX&quot;, 100s)</code></p>
<p>cons:</p>
<ul>
<li>问题一：锁过期释放了，业务还没执行完。假设线程a获取锁成功，一直在执行临界区的代码。但是100s过去后，它还没执行完。但是，这时候锁已经过期了，此时线程b又请求过来。显然线程b就可以获得锁成功，也开始执行临界区的代码。那么问题就来了，临界区的业务代码都不是严格串行执行的啦。</li>
<li>问题二：锁被别的线程误删。假设线程a执行完后，去释放锁。但是它不知道当前的锁可能是线程b持有的（线程a去释放锁时，有可能过期时间已经到了，此时线程b进来占有了锁）。那线程a就把线程b的锁释放掉了，但是线程b临界区业务代码可能都还没执行完呢。</li>
</ul>
<p>方案五：SET EX PX NX + 校验唯一随机值,再删除</p>
<p><code>jedis.set(key_resource_id, uni_request_id, &quot;NX&quot;, &quot;EX&quot;, 100s)</code></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-comment">//判断是不是当前线程加的锁,是才释放</span><br><span class="hljs-keyword">if</span> (uni_request_id.equals(jedis.get(key_resource_id))) &#123;<br>  jedis.del(lockKey); <span class="hljs-comment">//释放锁</span><br>&#125;<br></code></pre></td></tr></table></figure>
<p>cons: 判断是不是当前线程加的锁和释放锁不是一个原子操作。</p>
<p>可以用lua脚本代替：</p>
<figure class="highlight lua"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs lua"><span class="hljs-keyword">if</span> redis.call(<span class="hljs-string">&#x27;get&#x27;</span>,KEYS[<span class="hljs-number">1</span>]) == ARGV[<span class="hljs-number">1</span>] <span class="hljs-keyword">then</span> <br>  <span class="hljs-keyword">return</span> redis.call(<span class="hljs-string">&#x27;del&#x27;</span>,KEYS[<span class="hljs-number">1</span>]) <br><span class="hljs-keyword">else</span><br>  <span class="hljs-keyword">return</span> <span class="hljs-number">0</span><br><span class="hljs-keyword">end</span>;<br></code></pre></td></tr></table></figure>
<p>方案六：Redisson框架<sup class="footnote-ref"><a href="#fn8" id="fnref8">[8]</a></sup></p>
<p>方案五还是可能存在锁过期释放，业务没执行完的问题。有些小伙伴认为，稍微把锁过期时间设置长一些就可以啦。其实我们设想一下，是否可以给获得锁的线程，开启一个定时守护线程，每隔一段时间检查锁是否还存在，存在则对锁的过期时间延长，防止锁过期提前释放。<br>
当前开源框架Redisson解决了这个问题。只要线程一加锁成功，就会启动一个watch dog看门狗，它是一个后台线程，会每隔10秒检查一下，如果线程1还持有锁，那么就会不断的延长锁key的生存时间。因此，Redisson就是使用Redisson解决了锁过期释放，业务没执行完问题。</p>
<p>Go version of redisson<sup class="footnote-ref"><a href="#fn9" id="fnref9">[9]</a></sup></p>
<figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs go">LockScript      = <span class="hljs-string">&quot;if redis.call(&#x27;exists&#x27;, KEYS[1]) == 0  then return redis.call(&#x27;setex&#x27;, KEYS[1], unpack(ARGV)) else return &#x27;-1&#x27; end&quot;</span><br>UnlockScript    = <span class="hljs-string">&quot;if redis.call(&#x27;get&#x27;, KEYS[1]) == ARGV[1]  then return redis.call(&#x27;del&#x27;, KEYS[1]) or true end&quot;</span><br>RenewLockScript = <span class="hljs-string">&quot;if redis.call(&#x27;get&#x27;, KEYS[1]) == ARGV[1]  then return redis.call(&#x27;expire&#x27;, KEYS[1],ARGV[2]) or true end&quot;</span><br></code></pre></td></tr></table></figure>
<p>方案七：多机实现的分布式锁Redlock+Redisson</p>
<p>前面六种方案都只是基于单机版的讨论，还不是很完美。其实Redis一般都是集群部署的：<br>
线程1,2同时向master加锁，但加锁的key还没同步到slave节点，如果此时master发生故障，slave升级为master，线程二就可以获取同个key的锁啦，但线程一也已经拿到锁了，锁的安全性就没了。</p>
<p>为了解决这个问题，Redis作者 antirez提出一种高级的分布式锁算法：Redlock。Redlock核心思想是这样的：</p>
<blockquote>
<p>搞多个Redis master部署，以保证它们不会同时宕掉。并且这些master节点是完全相互独立的，相互之间不存在数据同步。同时，需要确保在这多个master实例上，是与在Redis单实例，使用相同方法来获取和释放锁。<br>
1.获取当前时间，以毫秒为单位。<br>
2.按顺序向5个master节点请求加锁。客户端设置网络连接和响应超时时间，并且超时时间要小于锁的失效时间。（假设锁自动失效时间为10秒，则超时时间一般在5-50毫秒之间,我们就假设超时时间是50ms吧）。如果超时，跳过该master节点，尽快去尝试下一个master节点。<br>
3.客户端使用当前时间减去开始获取锁时间（即步骤1记录的时间），得到获取锁使用的时间。当且仅当超过一半（N/2+1，这里是5/2+1=3个节点）的Redis master节点都获得锁，并且使用的时间小于锁失效时间时，锁才算获取成功。（如上图，10s&gt; 30ms+40ms+50ms+4m0s+50ms）<br>
如果取到了锁，key的真正有效时间就变啦，需要减去获取锁所使用的时间。<br>
如果获取锁失败（没有在至少N/2+1个master实例取到锁，有或者获取锁时间已经超过了有效时间），客户端要在所有的master节点上解锁（即便有些master节点根本就没有加锁成功，也需要解锁，以防止有些漏网之鱼）。</p>
</blockquote>
<ul>
<li>按顺序向5个master节点请求加锁</li>
<li>根据设置的超时时间来判断，是不是要跳过该master节点。</li>
<li>如果大于等于三个节点加锁成功，并且使用的时间小于锁的有效期，即可认定加锁成功啦。</li>
<li>如果获取锁失败，解锁！</li>
</ul>
</li>
<li>
<p>3 如果是Service怎么实现的？</p>
<p>每个服务从任务队列里读任务，并且将状态写回消息队列。</p>
</li>
<li>
<p>3.1 用的什么消息队列？为什么用消息队列？</p>
<p>Kafka。</p>
<ol>
<li>Asynchronous</li>
<li>Peak Clipping</li>
<li>Decoupling</li>
</ol>
</li>
<li>
<p>3.1.1 会重复读吗？怎么做到不重复读？</p>
<p>不会，把所有服务设置为同一个Comsumer Group。</p>
</li>
<li>
<p>3.1.1.1 Consumer Group是怎么实现不重复读的？</p>
<p>这要说道Consumer的Rebalance机制，对于Consumer Group中的每个Consumer，服务端尽量做到每个Consumer分配不同的Partition，如果P的数量&gt;C，那一个C就可能获取多个P，反之，会有C空闲。</p>
</li>
<li>
<p>3.1.2 消息队列支持有连接数限制吗？会影响同时并行的服务数量吗？</p>
<p>通常建议每个broker不超过1k个客户端，因为每个客户端与broker都需要建立socket连接。当连接数过多时会消耗过多资源在Socket处理上。</p>
</li>
<li>
<p>3.1.3 Kafka的结构和运行原理知道吗？</p>
<p>基础的节点单位是Broker，每个Topic为一个队列，每个Topic会分为多个Partition，一个Partition有至少三个副本分布在不同Broker上，其中一个是Leader，其他两个是Follower，Leader负责处理对Partition的操作，Follower同步复制操作。ZooKeeper负责处理分布式节点监控与恢复以及Leader失效后重新选出新Leader。对于客户端，Producer负责写入数据，并且尽可能均匀的写入Partition，如果Key不null，根据Key的Hash值计算分区号，如果Key null，则轮询写入。Consumer负责读取数据，通过Rebalance获取自己在Consumer Group中可以读取的Partition序号，顺序读取数据。</p>
</li>
<li>
<p>3.1.4 Kafka保序吗？如何保序？</p>
<p>参考<sup class="footnote-ref"><a href="#fn10" id="fnref10">[10]</a></sup>。Kafka分布式的单位是Partition，同一个Partition可以保证FIFO，不同Partition之间不能保证顺序。但是可以通过message key来保序，同一个key只会发送到同一个partition，能保证同一个key的message是保序的。同时如果需要所有信息严格保序，只设置一个partition即可。</p>
</li>
<li>
<p>3.1.4.1 如果Key Skew了怎么办？</p>
<p>区分原因，如果Key分布相对均匀，可以换Hash函数，如果Key分布不均匀，考虑去掉Key，或者重新选择Key，比如uid换成order id之类的。</p>
</li>
<li>
<p>⚠️3.1.4.1.1 Kafka常用的Key Hash函数有哪些？</p>
<ol>
<li>murmur2</li>
</ol>
</li>
<li>
<p>3.1.5 Rebalance是什么？讲讲具体过程？如何避免Rebalance？</p>
<p>参考<sup class="footnote-ref"><a href="#fn10" id="fnref10:1">[10:1]</a></sup><sup class="footnote-ref"><a href="#fn11" id="fnref11">[11]</a></sup>。<br>
Rebalance发生在以下情况，需要避免:</p>
<ol>
<li>Consumer加入或退出或无心跳之后</li>
<li>在Partition数量变更之后</li>
<li>订阅主题数变更。在使用正则匹配Topic时新增了Topic订阅Topic数量发生改变之后</li>
</ol>
</li>
<li>
<p>⚠️3.1.5.1 Rebalance策略有哪些？各自的优缺点是什么？</p>
<p><sup class="footnote-ref"><a href="#fn11" id="fnref11:1">[11:1]</a></sup><br>
Range<br>
pros: 单个Topic分配均匀，但当加入或移除consumer时，会大范围重分配。<br>
cons: 如果订阅了多个Topic，字典序靠前的消费组中的消费者比较 “ 贪婪 ” ，因此Consumer负载不均衡。</p>
<p>RoundRobin<br>
RoundRobinAssignor 的分配策略是将消费组内订阅的所有 Topic 的分区及所有消费者进行排序后尽量均衡的分配（RangeAssignor 是针对单个 Topic 的分区进行排序分配的）<br>
pros: 单个Topic分配均匀。多个Topic，尽量分配平衡。<br>
cons: 对于消费组内消费者订阅 Topic 不一致的情况，还是会出现不均衡。C0-&gt;T1{0,1,2},T2{0} C1-&gt;T2{1}</p>
<p>Sticky<br>
尽管 RoundRobinAssignor 已经在 RangeAssignor 上做了一些优化来更均衡的分配分区，但是在一些情况下依旧会产生严重的分配偏差，比如消费组中订阅的Topic 列表不相同的情况下。 更核心的问题是无论是RangeAssignor ，还是 RoundRobinAssignor ，当前的分区分配算法都没有考虑上一次的分配结果 。显然，在执行一次新的分配之前，如果能考虑到上一次分配的结果，尽量少的调整分区分配的变动，显然是能节省很多开销的。</p>
<ol>
<li>分区的分配尽量的均衡</li>
<li>每一次重分配的结果尽量与上一次分配结果保持一致<br>
当这两个目标发生冲突时，优先保证第一个目标。第一个目标是每个分配算法都尽量尝试去完成的，而第二个目标才真正体现出StickyAssignor 特性的。</li>
</ol>
</li>
<li>
<p>3.1.6 Kafka怎么实现超高并发/吞吐的？为什么这么快？</p>
<ol>
<li>分区数据并行处理。</li>
<li>Partition顺序写入磁盘。</li>
<li>利用PageCache批量写入磁盘。</li>
<li>零拷贝技术。</li>
<li>批量发送读取。</li>
<li>数据压缩节省磁盘网络延迟。</li>
<li>reactor模式，I/O多路复用<sup class="footnote-ref"><a href="#fn12" id="fnref12">[12]</a></sup>。</li>
</ol>
</li>
<li>
<p>⚠️3.1.7 知道其他消息队列吗？为什么不用？</p>
<p>参考<sup class="footnote-ref"><a href="#fn13" id="fnref13">[13]</a></sup><sup class="footnote-ref"><a href="#fn14" id="fnref14">[14]</a></sup>。</p>
<p>RabbitMQ，RocketMQ。</p>
<ol>
<li>团队中目前已经有了Kafka集群，可以复用。</li>
<li>经过调研，Kafka可以满足需求。暂时没有消息超时等需求。</li>
<li>在保证可靠性的情况下，Kafka的性能和其他队列差不多。</li>
</ol>
</li>
<li>
<p>3.1.7.1 RocketMQ有什么优势？</p>
<p><sup class="footnote-ref"><a href="#fn15" id="fnref15">[15]</a></sup><sup class="footnote-ref"><a href="#fn16" id="fnref16">[16]</a></sup>。</p>
</li>
<li>
<p>3.1.7.2 RocketMQ是什么架构？</p>
<p><sup class="footnote-ref"><a href="#fn17" id="fnref17">[17]</a></sup></p>
</li>
<li>
<p>3.1.8 如何保证幂等性？也就是不重复消费？</p>
</li>
<li>
<p>3.1.9 如果MQ挂了怎么办？整个系统就挂了吗？</p>
</li>
<li>
<p>3.1.10 怎么保证Kafka消息不丢失？</p>
<p><strong>Producer</strong><br>
配置ack=-1，保证写入所有follower之后返回，延迟更大<br>
<strong>Consumer</strong><br>
关闭自动offset commit，手动提交<br>
<strong>Broker</strong><br>
partition replication</p>
<p>参考<sup class="footnote-ref"><a href="#fn18" id="fnref18">[18]</a></sup></p>
</li>
<li>
<p>3.1.11 Kafka怎么选举的？</p>
<p>参考<sup class="footnote-ref"><a href="#fn19" id="fnref19">[19]</a></sup></p>
</li>
<li>
<p>3.1.12 Kafka用的哪个库？为什么？</p>
<p>segmentio/kafka-go，是一个纯Go实现的客户端，可以在多端上测试运行，免去了CGo的依赖，性能实际使用下来时足够的。</p>
</li>
<li>
<p>3.1.13 Kafka的MirrorMaker知道吗？用过吗？</p>
<p>用于异地复制，在不同集群间同步。</p>
</li>
<li>
<p>⚠️3.2 如何区分优先级？</p>
</li>
<li>
<p>⚠️3.3 如何区分不同用户？每个用户应该有自己的任务队列，否则一个用户可能会耗尽资源。</p>
</li>
<li>
<p>3.4 如果临时终止任务怎么处理？</p>
<p>使用KILL TASK队列，每个Service 作为单独的Consumer读取，如果TASK ID和当前正在处理的任务一致则终止任务，并发送任务状态。</p>
</li>
<li>
<p>3.5 如何处理失败任务？</p>
<p>加异常处理，因各种原因失败的任务发送任务状态，以及失败原因。</p>
</li>
<li>
<p>3.6 如何处理节点突然失效？</p>
<p>如果是Node失效或Pod Crash，k8s的重启机制会保证Service重启，重新订阅Topic。如果是Pod本身卡死，则需要发送心跳包，维护一个在线Service列表，一旦心跳包超时则需要重启Service。Task心跳包超时后需重新下发Task。</p>
</li>
<li>
<p>3.7 怎么添加监控的？监控了什么指标？如何Alert？</p>
<p>监控Service状态，当前各状态的Task数量分布，输入输出视频的平均码率。</p>
</li>
<li>
<p>⚠️3.8 为什么不用成熟的任务调度框架？</p>
</li>
<li>
<p>3.9 怎么更新服务和模型的？</p>
</li>
<li>
<p>3.10 可以给不同用户使用不同模型吗？</p>
</li>
<li>
<p>4 视频的处理过程是怎样的？能详细说说吗？</p>
<p>视频处理分两阶段，先做模型处理，再做编码压缩。模型处理服务初始化或者更新的时候首先加载模型，使用OpenCV读取视频，并根据视频尺寸Batch化，根据GPU Memory大小，每种尺寸对应不同的Batch Size，防止OOM。处理好的视频OpenCV以无损格式写出。处理完成后的视频传输至Object Storage，我们搭建了一个VPC内的minio作为视频交换媒介。编码服务拉取视频并根据配置编码，回传至公网Object Storage，并回调通知用户服务。</p>
</li>
<li>
<p>4.1 无损格式写出的中间视频体积很大，会消耗存储和传输资源，这部分可以怎么避免吗？Minio没有出现过带宽瓶颈吗？</p>
</li>
<li>
<p>5 网络基本知识</p>
</li>
<li>
<p>5.1 HTTP格式？</p>
</li>
<li>
<p>5.2 HTTPS基本原理？如何加密的？</p>
</li>
<li>
<p>5.3 长轮询怎么做？什么原理？</p>
</li>
<li>
<p>5.4 Websocket用过吗？</p>
</li>
</ul>
<p><strong>算法与模型</strong></p>
<ul>
<li>
<p>1 模型基本结构是什么？效果如何？有什么评价指标吗？</p>
</li>
<li>
<p>2 主流的超分或者视频增强模型有哪些？结构上有什么不同？可以用Transformer吗？</p>
</li>
<li>
<p>3 用什么方法避免ringing effect和artifact伪影呢？</p>
</li>
<li>
<p>4 用的什么Loss？</p>
</li>
<li>
<p>5 为什么要用GAN？用了有什么效果？</p>
</li>
<li>
<p>6 用了什么退化？</p>
</li>
<li>
<p>7 怎么训练的？分布式？为什么不用集群？</p>
</li>
</ul>
<p><strong>视频编码</strong></p>
<ul>
<li>
<p>1 ffmpeg编码质量怎么配置的？有改过代码吗？</p>
</li>
<li>
<p>2 用的什么编码？H264还是H265。</p>
</li>
<li>
<p>3 编码时间比是多少？怎么加速？</p>
</li>
</ul>
<h2><a href="#intelligent-marketing-platform" class="header-anchor">#</a><span id="intelligent-marketing-platform"> Intelligent Marketing Platform</span></h2>
<p><strong>高吞吐微服务系统</strong></p>
<ul>
<li>
<p>1 怎么支撑这么高的并发的？</p>
<p>通过5点：</p>
<ol>
<li>API-Server是无状态Deployment服务，可以扩容并行处理输入。</li>
<li>发送短信时需要阿里云鉴权，验证签名和模板的有效性，我们使用了阿里云本地的鉴权客户端，并且加了签名模板等资源的本地缓存，保证基本不读取数据库。</li>
<li>在API侧写数据库压力很大，并且因为API限制了每次请求batch数量，写入数据库的query碎片化，所以直接写入Kafka，等到发送完成后再写入数据库。这样就避免了同一条短信数据的两次数据库写入操作，节省了数据库带宽。</li>
<li>一开始是以短信为单位写入Kafka，发现写入和读取的速度相对比较慢，后面优化为以用户请求batch为单位为Kafka的一条信息，读写的速度有了明显提高，不再是瓶颈。</li>
<li>多协程操作，大batch化操作数据库，利用GoRoutine处理数据，放入写数据库channel中积累到一定数据或达到超时阈值后统一写回数据库。大Batch相比多次小Batch延迟明显降低。</li>
</ol>
</li>
<li>
<p>2 有做流控吗？怎么做的？</p>
<p>有做，分别在网关层，API输入层，短信发送层做了流控。</p>
<ul>
<li>网关层是阿里云提供的系统级流控，包括产品级与API级访问控制。</li>
<li>API输入层可配置策略限制单用户或单IP的QPS，防止挤占其他用户。</li>
<li>短信发送层配置短信发送速率，这是因为下游服务提供商没有提供有效的队列，当发送速率过高时短信的发送失败率过高。</li>
</ul>
<p>流控方法基本上就是滑动窗口法。</p>
</li>
<li>
<p>3 数据库有遇到瓶颈吗？Latency平均在多少？为什么不用MySQL/MongoDB/HBase之类的？</p>
</li>
<li>
<p>4 介绍一下Hologres的原理？</p>
<p>参考<sup class="footnote-ref"><a href="#fn20" id="fnref20">[20]</a></sup><sup class="footnote-ref"><a href="#fn21" id="fnref21">[21]</a></sup><sup class="footnote-ref"><a href="#fn22" id="fnref22">[22]</a></sup>。<br>
<img src="/images/hologres.png" alt="hologres"></p>
<p>每个分片（Table Group Shard， 简称Shard）构成了一个存储管理和恢复的单元 （Recovery Unit）。上图显示了一个分片的基本架构。一个分片由多个tablet组成，这些tablet会共享一个日志（Write-Ahead Log，WAL）。存储引擎用了Log-Structured Merge （LSM）的技术，所有的新数据都是以append-only的形式插入的。 数据先写到tablet所在的内存表 (MemTable)，积累到一定规模后写入到文件中。当一个数据文件关闭后，里面的内容就不会变了。新的数据以及后续的更新都会写到新的文件。 与传统数据库的B±tree数据结构相比，LSM减少了随机IO，大幅的提高了写的性能。</p>
<p>当写操作不断进来，每个tablet里会积累出很多文件。当一个tablet里小文件积累到一定数量时，存储引擎会在后台把小文件合并起来 （Compaction），这样系统就不需要同时打开很多文件，能减少使用系统资源，更重要的是合并后， 文件减少了，提高了读的性能。</p>
<p>在DML的功能上，存储引擎提供了单条或者批量的创建，查询，更新，和删除（CRUD操作）访问方法的接口，查询引擎可以通过这些接口访问存储的数据。</p>
<p>Distributed Database With PostgreSQL Query Engine Support. Hologres divides data into different shards by hashing the key, stores data into DFS(Pangu,HDFS,OSS) and aggregates the results from different shards. and provides dictionary index and bitmap index to accelerate the execution. A shard consists of multiple tablets. And those tablets shares a common write-ahead log (WAL for short).</p>
</li>
<li>
<p>4.1 Hologres的行存列存数据格式？</p>
</li>
<li>
<p>5 本地缓存怎么做的？</p>
<p>go的Cache包，设置过期时间，使用LFU淘汰策略。</p>
</li>
<li>
<p>5.1 会有数据一致性问题吗？</p>
<p>不会，没有强一致性要求，因为需要缓存的对象设计的时候避免了Update操作，User表在用户首次开通产品时就已经确定无法更改。Signature表与Template表同样。在前端加入了从已有新建的快捷操作。</p>
</li>
<li>
<p>5.2 为什么不用Redis？</p>
<p>需要缓存的规模比较小，而且没有很强的一致性要求，所以就用了Local Cache。像用户Session信息都是由阿里云的网关服务负责的，我们产品的服务收到的请求头部里有用户相关的各类信息，比如用户主账号id，子账号id，以及一系列其他的鉴权相关的信息。<br>
问题其实在问什么时候应该用Redis，参考<sup class="footnote-ref"><a href="#fn20" id="fnref20:1">[20:1]</a></sup>，同时也是在问用Local Cache的局限性，参考<sup class="footnote-ref"><a href="#fn23" id="fnref23">[23]</a></sup>，同时也是在问能否结合Redis与本地缓存<sup class="footnote-ref"><a href="#fn24" id="fnref24">[24]</a></sup><sup class="footnote-ref"><a href="#fn25" id="fnref25">[25]</a></sup>。</p>
</li>
<li>
<p>5.3 Redis为什么快？</p>
<ol>
<li>in-memory 内存不需要访问磁盘。</li>
<li>single thread处理，减小多线程竞争的context switching开销，避免加锁开销以及死锁的情况。</li>
<li>IO 多路复用，处理并发连接。</li>
<li>数据结构简单，操作也简单，提升性能。</li>
<li>使用底层模型不同，它们之间底层实现方式以及与客户端之间通信的应用协议不一样，Redis 直接自己构建了 VM 机制 ，因为一般的系统调用系统函数的话，会浪费一定的时间去移动和请求。</li>
</ol>
<p>参考<sup class="footnote-ref"><a href="#fn26" id="fnref26">[26]</a></sup>。</p>
</li>
<li>
<p>5.3.1 说一下Redis的内存模型？</p>
<p><sup class="footnote-ref"><a href="#fn27" id="fnref27">[27]</a></sup><br>
字符串、哈希、列表、集合、有序集合<br>
redisObject</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-keyword">typedef</span> <span class="hljs-keyword">struct</span> <span class="hljs-title class_">redisObject</span> &#123;<br>　　<span class="hljs-type">unsigned</span> type:<span class="hljs-number">4</span>;<br>　　<span class="hljs-type">unsigned</span> encoding:<span class="hljs-number">4</span>;<br>　　<span class="hljs-type">unsigned</span> lru:REDIS_LRU_BITS; <span class="hljs-comment">/* lru time (relative to server.lruclock) */</span><br>　　<span class="hljs-type">int</span> refcount;<br>　　<span class="hljs-type">void</span> *ptr;<br>&#125; robj;<br></code></pre></td></tr></table></figure>
<p><strong>SDS</strong><br>
Redis没有直接使用C字符串(即以空字符’\0’结尾的字符数组)作为默认的字符串表示，而是使用了SDS。SDS是简单动态字符串(Simple Dynamic String)的缩写。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs plaintext">struct sdshdr &#123;<br>    int len;<br>    int free;<br>    char buf[];<br>&#125;;<br></code></pre></td></tr></table></figure>
<p><strong>String</strong><br>
int<br>
embstr 39Byte why? 39 + redisObject 16 + sds 9 jemalloc正好可以分配64字节的内存单元。<br>
raw len(string)&gt;39或者modified(append)</p>
<p><strong>List</strong></p>
<ul>
<li>压缩列表 ziplist<br>
连续数组结构，节约内存，修改复杂度高<br>
len(list) &lt; 512 &amp;&amp; len(str) &lt; 64<br>
其中，单个字符串不能超过64字节，是为了便于统一分配每个节点的长度；这里的64字节是指字符串的长度，不包括SDS结构，因为压缩列表使用连续、定长内存块存储字符串，不需要SDS结构指明长度。后面提到压缩列表，也会强调长度不超过64字节，原理与这里类似。</li>
<li>双端列表 linkedlist<br>
保存前后向指针，节点数量多时，双端列表更好，修改增删的复杂度低于压缩列表</li>
</ul>
<p><strong>Hash</strong></p>
<ul>
<li>压缩列表 ziplist<br>
len(hashtable) &lt; 512 &amp;&amp; len(k) &lt; 64 &amp;&amp; len(v) &lt; 64</li>
<li>哈希表 hashtable</li>
</ul>
<p><strong>Set</strong></p>
<ul>
<li>整数集合 intset<br>
len(set) &lt; 512 &amp;&amp; int</li>
<li>哈希表 hashtable</li>
</ul>
<p><strong>SortedSet</strong></p>
<ul>
<li>压缩列表 ziplist<br>
len(sortedset) &lt; 128 &amp;&amp; len(str) &lt; 64</li>
<li>跳表 skiplist<br>
跳跃表是一种有序数据结构，通过在每个节点中维持多个指向其他节点的指针，从而达到快速访问节点的目的。除了跳跃表，实现有序数据结构的另一种典型实现是平衡树；大多数情况下，跳跃表的效率可以和平衡树媲美，且跳跃表实现比平衡树简单很多，因此redis中选用跳跃表代替平衡树。跳跃表支持平均O(logN)、最坏O(N)的复杂点进行节点查找，并支持顺序操作。Redis的跳跃表实现由zskiplist和zskiplistNode两个结构组成：前者用于保存跳跃表信息（如头结点、尾节点、长度等），后者用于表示跳跃表节点。具体结构相对比较复杂，略。</li>
</ul>
</li>
<li>
<p>5.3.1.1 如何优化内存占用？</p>
<ol>
<li>
<p>利用jemalloc特性进行优化<br>
上一小节所讲述的90000个键值便是一个例子。由于jemalloc分配内存时数值是不连续的，因此key/value字符串变化一个字节，可能会引起占用内存很大的变动；在设计时可以利用这一点。<br>
例如，如果key的长度如果是8个字节，则SDS为17字节，jemalloc分配32字节；此时将key长度缩减为7个字节，则SDS为16字节，jemalloc分配16字节；则每个key所占用的空间都可以缩小一半。</p>
</li>
<li>
<p>使用整型/长整型<br>
如果是整型/长整型，Redis会使用int类型（8字节）存储来代替字符串，可以节省更多空间。因此在可以使用长整型/整型代替字符串的场景下，尽量使用长整型/整型。</p>
</li>
<li>
<p>共享对象<br>
利用共享对象，可以减少对象的创建（同时减少了redisObject的创建），节省内存空间。目前redis中的共享对象只包括10000个整数（0-9999）；可以通过调整REDIS_SHARED_INTEGERS参数提高共享对象的个数；例如将REDIS_SHARED_INTEGERS调整到20000，则0-19999之间的对象都可以共享。<br>
考虑这样一种场景：论坛网站在redis中存储了每个帖子的浏览数，而这些浏览数绝大多数分布在0-20000之间，这时候通过适当增大REDIS_SHARED_INTEGERS参数，便可以利用共享对象节省内存空间。</p>
</li>
<li>
<p>避免过度设计<br>
然而需要注意的是，不论是哪种优化场景，都要考虑内存空间与设计复杂度的权衡；而设计复杂度会影响到代码的复杂度、可维护性。<br>
如果数据量较小，那么为了节省内存而使得代码的开发、维护变得更加困难并不划算；还是以前面讲到的90000个键值对为例，实际上节省的内存空间只有几MB。但是如果数据量有几千万甚至上亿，考虑内存的优化就比较必要了。</p>
</li>
</ol>
</li>
<li>
<p>5.3.1.2 Redis内存碎片？</p>
<p>内存碎片率是一个重要的参数，对redis 内存的优化有重要意义。</p>
<p>如果内存碎片率过高（jemalloc在1.03左右比较正常），说明内存碎片多，内存浪费严重；这时便可以考虑重启redis服务，在内存中对数据进行重排，减少内存碎片。</p>
<p>如果内存碎片率小于1，说明redis内存不足，部分数据使用了虚拟内存（即swap）；由于虚拟内存的存取速度比物理内存差很多（2-3个数量级），此时redis的访问速度可能会变得很慢。因此必须设法增大物理内存（可以增加服务器节点数量，或提高单机内存），或减少redis中的数据。</p>
<p>要减少redis中的数据，除了选用合适的数据类型、利用共享对象等，还有一点是要设置合理的数据回收策略（maxmemory-policy），当内存达到一定量后，根据不同的优先级对内存进行回收。</p>
</li>
<li>
<p>5.3.2 Redis是单线程的吗？</p>
<p>参考<sup class="footnote-ref"><a href="#fn28" id="fnref28">[28]</a></sup>。Redis在处理客户端的请求时，包括获取 (socket 读)、解析、执行、内容返回 (socket 写) 等都由一个顺序串行的主线程处理，这就是所谓的“单线程”。但如果严格来讲从Redis4.0之后并不是单线程，除了主线程外，它也有后台线程在处理一些较为缓慢的操作，例如清理脏数据、无用连接的释放、大 key 的删除等等。</p>
</li>
<li>
<p>5.3.2.1 为什么Redis不用多线程？</p>
<p>参考<sup class="footnote-ref"><a href="#fn29" id="fnref29">[29]</a></sup>。</p>
<p>官方曾做过类似问题的回复：使用Redis时，几乎不存在CPU成为瓶颈的情况， Redis主要受限于内存和网络。例如在一个普通的Linux系统上，Redis通过使用pipelining每秒可以处理100万个请求，所以如果应用程序主要使用O(N)或O(log(N))的命令，它几乎不会占用太多CPU。</p>
<p>使用了单线程后，可维护性高。多线程模型虽然在某些方面表现优异，但是它却引入了程序执行顺序的不确定性，带来了并发读写的一系列问题，增加了系统复杂度、同时可能存在线程切换、甚至加锁解锁、死锁造成的性能损耗。Redis通过AE事件模型以及IO多路复用等技术，处理性能非常高，因此没有必要使用多线程。单线程机制使得 Redis 内部实现的复杂度大大降低，Hash 的惰性 Rehash、Lpush 等等 “线程不安全” 的命令都可以无锁进行。</p>
</li>
<li>
<p>5.3.2.2 知道Redis 6.0之后多线程化了吗？为什么要引入多线程？</p>
<p>参考<sup class="footnote-ref"><a href="#fn29" id="fnref29:1">[29:1]</a></sup>。</p>
<p>Redis将所有数据放在内存中，内存的响应时长大约为100纳秒，对于小数据包，Redis服务器可以处理80,000到100,000 QPS，这也是Redis处理的极限了，对于80%的公司来说，单线程的Redis已经足够使用了。</p>
<p>但随着越来越复杂的业务场景，有些公司动不动就上亿的交易量，因此需要更大的QPS。常见的解决方案是在分布式架构中对数据进行分区并采用多个服务器，但该方案有非常大的缺点，例如要管理的Redis服务器太多，维护代价大；某些适用于单个Redis服务器的命令不适用于数据分区；数据分区无法解决热点读/写问题；数据偏斜，重新分配和放大/缩小变得更加复杂等等。</p>
<p>从Redis自身角度来说，因为读写网络的read/write系统调用占用了Redis执行期间大部分CPU时间，瓶颈主要在于网络的 IO 消耗, 优化主要有两个方向:</p>
<ul>
<li>提高网络 IO 性能，典型的实现比如使用 DPDK 来替代内核网络栈的方式</li>
<li>使用多线程充分利用多核，典型的实现比如 Memcached。</li>
</ul>
<p>协议栈优化的这种方式跟 Redis 关系不大，支持多线程是一种最有效最便捷的操作方式。所以总结起来，redis支持多线程主要就是两个原因：</p>
<ul>
<li>可以充分利用服务器 CPU 资源，目前主线程只能利用一个核</li>
<li>多线程任务可以分摊 Redis 同步 IO 读写负荷</li>
</ul>
</li>
<li>
<p>5.3.2.3 知道怎么配置6.0的多线程吗？</p>
<p>Redis6.0的多线程默认是禁用的，只使用主线程。如需开启需要修改redis.conf配置文件：io-threads-do-reads yes<br>
开启多线程后，还需要设置线程数，否则是不生效的。同样修改redis.conf配置文件。关于线程数的设置，官方有一个建议：4核的机器建议设置为2或3个线程，8核的建议设置为6个线程，线程数一定要小于机器核数。还需要注意的是，线程数并不是越大越好，官方认为超过了8个基本就没什么意义了。</p>
</li>
<li>
<p>5.3.2.4 开启多线程之后的性能如何？</p>
<p>Redis 作者 antirez 在 RedisConf 2019分享时曾提到：Redis 6 引入的多线程 IO 特性对性能提升至少是一倍以上。国内也有大牛曾使用unstable版本在阿里云esc进行过测试，GET/SET 命令在4线程 IO时性能相比单线程是几乎是翻倍了。<br>
说明1：这些性能验证的测试并没有针对严谨的延时控制和不同并发的场景进行压测。数据仅供验证参考而不能作为线上指标。<br>
说明2：如果开启多线程，至少要4核的机器，且Redis实例已经占用相当大的CPU耗时的时候才建议采用，否则使用多线程没有意义。所以估计80%的公司开发人员看看就好。</p>
</li>
<li>
<p>5.3.2.5 多线程的实现机制？</p>
<p>流程简述如下：</p>
<ol>
<li>主线程负责接收建立连接请求，获取 socket 放入全局等待读处理队列</li>
<li>主线程处理完读事件之后，通过 RR(Round Robin) 将这些连接分配给这些 IO 线程</li>
<li>主线程阻塞等待 IO 线程读取 socket 完毕</li>
<li>主线程通过单线程的方式执行请求命令，请求数据读取并解析完成，但并不执行</li>
<li>主线程阻塞等待 IO 线程将数据回写 socket 完毕</li>
<li>解除绑定，清空等待队列</li>
</ol>
</li>
<li>
<p>5.3.3 说一下什么是IO多路复用？</p>
<p>多路指的是多个socket连接，复用指的是复用一个线程。多路复用主要有三种技术：select，poll，epoll。epoll是最新的也是目前最好的多路复用技术。采用多路 I/O 复用技术可以让单个线程高效的处理多个连接请求（尽量减少网络IO的时间消耗），且Redis在内存中操作数据的速度非常快（内存内的操作不会成为这里的性能瓶颈），主要以上两点造就了Redis具有很高的吞吐量。</p>
</li>
<li>
<p>5.3.3.1 什么是epoll？</p>
<p>参考<sup class="footnote-ref"><a href="#fn30" id="fnref30">[30]</a></sup>。</p>
<p>select 和 poll 是 Linux 的底层synchronous通信机制。</p>
<p>epoll 是改进版。</p>
</li>
<li>
<p>5.3.4 Redis的基本数据结构？底层是怎么实现的？</p>
<p>参考<sup class="footnote-ref"><a href="#fn31" id="fnref31">[31]</a></sup>。</p>
<ul>
<li>string</li>
<li>list</li>
<li>hash</li>
<li>set</li>
<li>sorted set</li>
</ul>
</li>
<li>
<p>5.3.5 说说Redis的VM机制。</p>
<p>参考<sup class="footnote-ref"><a href="#fn32" id="fnref32">[32]</a></sup>。</p>
<p>Redis自己实现了一套虚拟内存的管理机制。</p>
</li>
<li>
<p>5.3.6 Redis Cluster的功能是？怎么实现的？有限制吗？可以无限扩展吗？</p>
<p>为了解决Redis单机容量有限的问题，提高并发量。本质上就是Sharding，在于扩展主从结构的写能力。<br>
官方推荐最大的节点数量为1000，由于Cluster架构中无Proxy层，Master与Slave之间使用异步replication。<br>
客户端容忍一定程度的数据丢失，集群尽可能保存Client write操作的数据，保证数据一致性。<br>
Redis集群通过partition来提供一定程度的可用性，当集群中的一部分节点失效或者无法进行通讯时，集群仍可以继续提供服务。</p>
<p>参考<sup class="footnote-ref"><a href="#fn33" id="fnref33">[33]</a></sup><sup class="footnote-ref"><a href="#fn34" id="fnref34">[34]</a></sup></p>
</li>
<li>
<p>5.3.6.1 为什么节点数量为1000？过多的节点数量会有什么问题？</p>
<p>Redis 集群的键空间被分割为 16384 个槽（slot）， 集群的最大节点数量也是 16384 个。 推荐的最大节点数量为1000 个左右。 每个主节点都负责处理 16384 个哈希槽的其中一部分。每个 key 通过 CRC16 算法计算的结果，对 16384 取模后放到对应的编号在 0-16383 之间的哈希槽。</p>
<p>原作者回答：<br>
The reason is:<br>
Normal heartbeat packets carry the full configuration of a node, that can be replaced in an idempotent way with the old in order to update an old config. This means they contain the slots configuration for a node, in raw form, that uses 2k of space with16k slots, but would use a prohibitive 8k of space using 65k slots.<br>
At the same time it is unlikely that Redis Cluster would scale to more than 1000 mater nodes because of other design tradeoffs.<br>
So 16k was in the right range to ensure enough slots per master with a max of 1000 maters, but a small enough number to propagate the slot configuration as a raw bitmap easily. Note that in small clusters the bitmap would be hard to compress because when N is small the bitmap would have slots/N bits set that is a large percentage of bits set.</p>
<p>到底数据信息究竟多大？<br>
在消息头中，最占空间的是myslots[CLUSTER_SLOTS/8]。这块的大小是:<br>
16384÷8÷1024=2kb<br>
那在消息体中，会携带一定数量的其他节点信息用于交换。<br>
那这个其他节点的信息，到底是几个节点的信息呢？<br>
约为集群总节点数量的1/10，至少携带3个节点的信息。<br>
这里的重点是:节点数量越多，消息体内容越大。</p>
<p>消息体大小是10个节点的状态信息约1kb。</p>
<p>那定期的频率是什么样的？<br>
redis集群内节点，每秒都在发ping消息。规律如下<br>
(1)每秒会随机选取5个节点，找出最久没有通信的节点发送ping消息<br>
(2)每100毫秒(1秒10次)都会扫描本地节点列表，如果发现节点最近一次接受pong消息的时间大于cluster-node-timeout/2 则立刻发送ping消息<br>
因此，每秒单节点发出ping消息数量为<br>
数量=1+10<em>num(node.pong_received&gt;cluster_node_timeout/2)<br>
200-15/2</em>5=162.5 x (2kb+0.1kb)=341.25Kb/node x 200 = 68250Kb = 66.65Mb</p>
<p>一个总结点数为200的Redis集群，部署在20台物理机上每台划分10个节点，cluster-node-time=15s默认，pingpong带宽高达25Mb。如果cluster-node-time=20s，pingpong带宽消耗低于15Mb。</p>
<p>(1) 如果槽位为65536，发送心跳信息的消息头达8k，发送的心跳包过于庞大。<br>
如上所述，在消息头中，最占空间的是myslots[CLUSTER_SLOTS/8]。<br>
当槽位为65536时，这块的大小是:<br>
65536÷8÷1024=8kb<br>
因为每秒钟，redis节点需要发送一定数量的ping消息作为心跳包，如果槽位为65536，这个ping消息的消息头太大了，浪费带宽。<br>
(2) redis的集群主节点数量基本不可能超过1000个。<br>
如上所述，集群节点越多，心跳包的消息体内携带的数据越多。如果节点过1000个，也会导致网络拥堵。因此redis作者，不建议redis cluster节点数量超过1000个。<br>
那么，对于节点数在1000以内的redis cluster集群，16384个槽位够用了。没有必要拓展到65536个。<br>
(3) 槽位越小，节点少的情况下，压缩比高<br>
Redis主节点的配置信息中，它所负责的哈希槽是通过一张bitmap的形式来保存的，在传输过程中，会对bitmap进行压缩，但是如果bitmap的填充率slots / N很高的话(N表示节点数)，bitmap的压缩率就很低。<br>
如果节点数很少，而哈希槽数量很多的话，bitmap的压缩率就很低。</p>
<p>ps：文件压缩率指的是，文件压缩前后的大小比。</p>
</li>
<li>
<p>5.3.6.2 Key是如何Sharding的？</p>
<p>哈希分区的基本思路是：对数据的特征值（如key）进行哈希，然后根据哈希值决定数据落在哪个节点。常见的哈希分区包括：哈希取余分区、一致性哈希分区、带虚拟节点的一致性哈希分区等。</p>
<p>衡量数据分区方法好坏的标准有很多，其中比较重要的两个因素是(1)数据分布是否均匀(2)增加或删减节点对数据分布的影响。由于哈希的随机性，哈希分区基本可以保证数据分布均匀；因此在比较哈希分区方案时，重点要看增减节点对数据分布的影响。</p>
<p>三种方案：</p>
<ol>
<li>哈希取余分区<br>
哈希取余分区思路非常简单：计算key的hash值，然后对节点数量进行取余，从而决定数据映射到哪个节点上。该方案最大的问题是，当新增或删减节点时，节点数量发生变化，系统中所有的数据都需要重新计算映射关系，引发大规模数据迁移。</li>
<li>一致性哈希分区<br>
一致性哈希算法将整个哈希值空间组织成一个虚拟的圆环，如下图所示，范围为0-2^32-1；对于每个数据，根据key计算hash值，确定数据在环上的位置，然后从此位置沿环顺时针行走，找到的第一台服务器就是其应该映射到的服务器。</li>
<li>虚拟节点一致性哈希分区<br>
通过增加虚拟节点的方式，使ABC三个节点在圆环上的位置更加均匀，平均了落在每一个节点上的概率。这样一来就解决了上文提到的数据存储存在不均匀的问题了，这就是一致性哈希的虚拟节点机制。</li>
</ol>
</li>
<li>
<p>5.3.6.3 什么是一致性哈希算法？如何解决哈希不均衡？Redis用的是什么算法？</p>
<p>哈希算法是对master实例数量来取模，而一致性哈希则是对2^32取模，也就是值的范围在[0, 2^32 -1]。一致性哈希将其范围抽象成了一个圆环，使用CRC16算法计算出来的哈希值会落到圆环上的某个地方。</p>
<p>假设我们有A、B、C三个Redis实例按照如图所示的位置分布在圆环上，此时计算出来的hash值，取模之后位置落在了位置D，那么我们按照顺时针的顺序，就能够找到我们这个key应该分配的Redis实例B。同理如果我们计算出来位置在E，那么对应选择的Redis的实例就是A。</p>
<p>即使这个时候Redis实例B挂了，也不会影响到实例A和C的缓存。</p>
<p>例如此时节点B挂了，那之前计算出来在位置D的key，此时会按照顺时针的顺序，找到节点C。相当于自动的把原来节点B的流量给转移到了节点C上去。而其他原本就在节点A和节点C的数据则完全不受影响。</p>
<p>这就是一致性哈希，能够在我们后续需要新增节点或者删除节点的时候，不影响其他节点的正常运行。</p>
</li>
<li>
<p>5.3.6.4 Redis用的是什么哈希算法？</p>
<p>上面提到过，Redis Cluster采用的是类一致性哈希算法，之所以是类一致性哈希算法是因为它们实现的方式还略微有差别。</p>
<p>例如一致性哈希是对2^32取模，而Redis Cluster则是对2^14（也就是16384）取模。Redis Cluster将自己分成了16384个Slot（槽位）。通过CRC16算法计算出来的哈希值会跟16384取模，取模之后得到的值就是对应的槽位，然后每个Redis节点都会负责处理一部分的槽位，就像下表这样。</p>
<p>每个Redis实例会自己维护一份slot - Redis节点的映射关系，假设你在节点A上设置了某个key，但是这个key通过CRC16计算出来的槽位是由节点B维护的，那么就会提示你需要去节点B上进行操作。</p>
<p>CRC16，就是把需要校验的数据与多项式进行循环异或（XOR）</p>
<p>计算法：</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-function"><span class="hljs-type">unsigned</span> <span class="hljs-type">int</span> <span class="hljs-title">calccrc</span><span class="hljs-params">(<span class="hljs-type">unsigned</span> <span class="hljs-type">char</span> crcbuf, <span class="hljs-type">unsigned</span> <span class="hljs-type">int</span> crc)</span></span><br><span class="hljs-function"></span>&#123;<br>  <span class="hljs-type">unsigned</span> <span class="hljs-type">char</span> i;<br>  crc = crc ^ crcbuf;<br>  <span class="hljs-keyword">for</span> (i = <span class="hljs-number">0</span>; i &lt; <span class="hljs-number">8</span>; i++)<br>  &#123;<br>    <span class="hljs-type">unsigned</span> <span class="hljs-type">char</span> chk;<br>    chk = crc &amp; <span class="hljs-number">1</span>;<br>    crc = crc &gt;&gt; <span class="hljs-number">1</span>;<br>    crc = crc &amp; <span class="hljs-number">0x7fff</span>;<br>    <span class="hljs-keyword">if</span> (chk == <span class="hljs-number">1</span>) crc = crc ^ <span class="hljs-number">0xa001</span>;<br>    crc = crc &amp; <span class="hljs-number">0xffff</span>;<br>  &#125;<br>  <span class="hljs-keyword">return</span> crc;<br>&#125;<br><br><span class="hljs-function"><span class="hljs-type">unsigned</span> <span class="hljs-type">int</span> <span class="hljs-title">chkcrc</span><span class="hljs-params">(<span class="hljs-type">unsigned</span> <span class="hljs-type">char</span> *buf, <span class="hljs-type">unsigned</span> <span class="hljs-type">char</span> len)</span></span><br><span class="hljs-function"></span>&#123;<br>  <span class="hljs-type">unsigned</span> <span class="hljs-type">char</span> hi, lo;<br>  <span class="hljs-type">unsigned</span> <span class="hljs-type">int</span> i;<br>  <span class="hljs-type">unsigned</span> <span class="hljs-type">int</span> crc;<br>  crc = <span class="hljs-number">0xFFFF</span>;<br>  <span class="hljs-keyword">for</span> (i = <span class="hljs-number">0</span>; i &lt; len; i++)<br>  &#123;<br>    crc = <span class="hljs-built_in">calccrc</span>(*buf, crc);<br>    buf++;<br>  &#125;<br>  hi = crc % <span class="hljs-number">256</span>;<br>  lo = crc / <span class="hljs-number">256</span>;<br>  crc = (hi &lt;&lt; <span class="hljs-number">8</span>) | lo;<br>  <span class="hljs-keyword">return</span> crc;<br>&#125;<br></code></pre></td></tr></table></figure>
<p>查表法：</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-comment">// 逆序CRC表</span><br><span class="hljs-type">unsigned</span> <span class="hljs-type">char</span> aucCRCHi[]&#123;<br>  <span class="hljs-number">0x00</span>, <span class="hljs-number">0xC1</span>, <span class="hljs-number">0x81</span>, <span class="hljs-number">0x40</span>, <span class="hljs-number">0x01</span>, <span class="hljs-number">0xC0</span>, <span class="hljs-number">0x80</span>, <span class="hljs-number">0x41</span>, <span class="hljs-number">0x01</span>, <span class="hljs-number">0xC0</span>, <span class="hljs-number">0x80</span>, <span class="hljs-number">0x41</span>,<br>  <span class="hljs-number">0x00</span>, <span class="hljs-number">0xC1</span>, <span class="hljs-number">0x81</span>, <span class="hljs-number">0x40</span>, <span class="hljs-number">0x01</span>, <span class="hljs-number">0xC0</span>, <span class="hljs-number">0x80</span>, <span class="hljs-number">0x41</span>, <span class="hljs-number">0x00</span>, <span class="hljs-number">0xC1</span>, <span class="hljs-number">0x81</span>, <span class="hljs-number">0x40</span>,<br>  <span class="hljs-number">0x00</span>, <span class="hljs-number">0xC1</span>, <span class="hljs-number">0x81</span>, <span class="hljs-number">0x40</span>, <span class="hljs-number">0x01</span>, <span class="hljs-number">0xC0</span>, <span class="hljs-number">0x80</span>, <span class="hljs-number">0x41</span>, <span class="hljs-number">0x01</span>, <span class="hljs-number">0xC0</span>, <span class="hljs-number">0x80</span>, <span class="hljs-number">0x41</span>,<br>  <span class="hljs-number">0x00</span>, <span class="hljs-number">0xC1</span>, <span class="hljs-number">0x81</span>, <span class="hljs-number">0x40</span>, <span class="hljs-number">0x00</span>, <span class="hljs-number">0xC1</span>, <span class="hljs-number">0x81</span>, <span class="hljs-number">0x40</span>, <span class="hljs-number">0x01</span>, <span class="hljs-number">0xC0</span>, <span class="hljs-number">0x80</span>, <span class="hljs-number">0x41</span>,<br>  <span class="hljs-number">0x00</span>, <span class="hljs-number">0xC1</span>, <span class="hljs-number">0x81</span>, <span class="hljs-number">0x40</span>, <span class="hljs-number">0x01</span>, <span class="hljs-number">0xC0</span>, <span class="hljs-number">0x80</span>, <span class="hljs-number">0x41</span>, <span class="hljs-number">0x01</span>, <span class="hljs-number">0xC0</span>, <span class="hljs-number">0x80</span>, <span class="hljs-number">0x41</span>,<br>  <span class="hljs-number">0x00</span>, <span class="hljs-number">0xC1</span>, <span class="hljs-number">0x81</span>, <span class="hljs-number">0x40</span>, <span class="hljs-number">0x01</span>, <span class="hljs-number">0xC0</span>, <span class="hljs-number">0x80</span>, <span class="hljs-number">0x41</span>, <span class="hljs-number">0x00</span>, <span class="hljs-number">0xC1</span>, <span class="hljs-number">0x81</span>, <span class="hljs-number">0x40</span>,<br>  <span class="hljs-number">0x00</span>, <span class="hljs-number">0xC1</span>, <span class="hljs-number">0x81</span>, <span class="hljs-number">0x40</span>, <span class="hljs-number">0x01</span>, <span class="hljs-number">0xC0</span>, <span class="hljs-number">0x80</span>, <span class="hljs-number">0x41</span>, <span class="hljs-number">0x00</span>, <span class="hljs-number">0xC1</span>, <span class="hljs-number">0x81</span>, <span class="hljs-number">0x40</span>,<br>  <span class="hljs-number">0x01</span>, <span class="hljs-number">0xC0</span>, <span class="hljs-number">0x80</span>, <span class="hljs-number">0x41</span>, <span class="hljs-number">0x01</span>, <span class="hljs-number">0xC0</span>, <span class="hljs-number">0x80</span>, <span class="hljs-number">0x41</span>, <span class="hljs-number">0x00</span>, <span class="hljs-number">0xC1</span>, <span class="hljs-number">0x81</span>, <span class="hljs-number">0x40</span>,<br>  <span class="hljs-number">0x00</span>, <span class="hljs-number">0xC1</span>, <span class="hljs-number">0x81</span>, <span class="hljs-number">0x40</span>, <span class="hljs-number">0x01</span>, <span class="hljs-number">0xC0</span>, <span class="hljs-number">0x80</span>, <span class="hljs-number">0x41</span>, <span class="hljs-number">0x01</span>, <span class="hljs-number">0xC0</span>, <span class="hljs-number">0x80</span>, <span class="hljs-number">0x41</span>,<br>  <span class="hljs-number">0x00</span>, <span class="hljs-number">0xC1</span>, <span class="hljs-number">0x81</span>, <span class="hljs-number">0x40</span>, <span class="hljs-number">0x01</span>, <span class="hljs-number">0xC0</span>, <span class="hljs-number">0x80</span>, <span class="hljs-number">0x41</span>, <span class="hljs-number">0x00</span>, <span class="hljs-number">0xC1</span>, <span class="hljs-number">0x81</span>, <span class="hljs-number">0x40</span>,<br>  <span class="hljs-number">0x00</span>, <span class="hljs-number">0xC1</span>, <span class="hljs-number">0x81</span>, <span class="hljs-number">0x40</span>, <span class="hljs-number">0x01</span>, <span class="hljs-number">0xC0</span>, <span class="hljs-number">0x80</span>, <span class="hljs-number">0x41</span>, <span class="hljs-number">0x01</span>, <span class="hljs-number">0xC0</span>, <span class="hljs-number">0x80</span>, <span class="hljs-number">0x41</span>,<br>  <span class="hljs-number">0x00</span>, <span class="hljs-number">0xC1</span>, <span class="hljs-number">0x81</span>, <span class="hljs-number">0x40</span>, <span class="hljs-number">0x00</span>, <span class="hljs-number">0xC1</span>, <span class="hljs-number">0x81</span>, <span class="hljs-number">0x40</span>, <span class="hljs-number">0x01</span>, <span class="hljs-number">0xC0</span>, <span class="hljs-number">0x80</span>, <span class="hljs-number">0x41</span>,<br>  <span class="hljs-number">0x00</span>, <span class="hljs-number">0xC1</span>, <span class="hljs-number">0x81</span>, <span class="hljs-number">0x40</span>, <span class="hljs-number">0x01</span>, <span class="hljs-number">0xC0</span>, <span class="hljs-number">0x80</span>, <span class="hljs-number">0x41</span>, <span class="hljs-number">0x01</span>, <span class="hljs-number">0xC0</span>, <span class="hljs-number">0x80</span>, <span class="hljs-number">0x41</span>,<br>  <span class="hljs-number">0x00</span>, <span class="hljs-number">0xC1</span>, <span class="hljs-number">0x81</span>, <span class="hljs-number">0x40</span>, <span class="hljs-number">0x00</span>, <span class="hljs-number">0xC1</span>, <span class="hljs-number">0x81</span>, <span class="hljs-number">0x40</span>, <span class="hljs-number">0x01</span>, <span class="hljs-number">0xC0</span>, <span class="hljs-number">0x80</span>, <span class="hljs-number">0x41</span>,<br>  <span class="hljs-number">0x01</span>, <span class="hljs-number">0xC0</span>, <span class="hljs-number">0x80</span>, <span class="hljs-number">0x41</span>, <span class="hljs-number">0x00</span>, <span class="hljs-number">0xC1</span>, <span class="hljs-number">0x81</span>, <span class="hljs-number">0x40</span>, <span class="hljs-number">0x01</span>, <span class="hljs-number">0xC0</span>, <span class="hljs-number">0x80</span>, <span class="hljs-number">0x41</span>,<br>  <span class="hljs-number">0x00</span>, <span class="hljs-number">0xC1</span>, <span class="hljs-number">0x81</span>, <span class="hljs-number">0x40</span>, <span class="hljs-number">0x00</span>, <span class="hljs-number">0xC1</span>, <span class="hljs-number">0x81</span>, <span class="hljs-number">0x40</span>, <span class="hljs-number">0x01</span>, <span class="hljs-number">0xC0</span>, <span class="hljs-number">0x80</span>, <span class="hljs-number">0x41</span>,<br>  <span class="hljs-number">0x00</span>, <span class="hljs-number">0xC1</span>, <span class="hljs-number">0x81</span>, <span class="hljs-number">0x40</span>, <span class="hljs-number">0x01</span>, <span class="hljs-number">0xC0</span>, <span class="hljs-number">0x80</span>, <span class="hljs-number">0x41</span>, <span class="hljs-number">0x01</span>, <span class="hljs-number">0xC0</span>, <span class="hljs-number">0x80</span>, <span class="hljs-number">0x41</span>,<br>  <span class="hljs-number">0x00</span>, <span class="hljs-number">0xC1</span>, <span class="hljs-number">0x81</span>, <span class="hljs-number">0x40</span>, <span class="hljs-number">0x01</span>, <span class="hljs-number">0xC0</span>, <span class="hljs-number">0x80</span>, <span class="hljs-number">0x41</span>, <span class="hljs-number">0x00</span>, <span class="hljs-number">0xC1</span>, <span class="hljs-number">0x81</span>, <span class="hljs-number">0x40</span>,<br>  <span class="hljs-number">0x00</span>, <span class="hljs-number">0xC1</span>, <span class="hljs-number">0x81</span>, <span class="hljs-number">0x40</span>, <span class="hljs-number">0x01</span>, <span class="hljs-number">0xC0</span>, <span class="hljs-number">0x80</span>, <span class="hljs-number">0x41</span>, <span class="hljs-number">0x01</span>, <span class="hljs-number">0xC0</span>, <span class="hljs-number">0x80</span>, <span class="hljs-number">0x41</span>,<br>  <span class="hljs-number">0x00</span>, <span class="hljs-number">0xC1</span>, <span class="hljs-number">0x81</span>, <span class="hljs-number">0x40</span>, <span class="hljs-number">0x00</span>, <span class="hljs-number">0xC1</span>, <span class="hljs-number">0x81</span>, <span class="hljs-number">0x40</span>, <span class="hljs-number">0x01</span>, <span class="hljs-number">0xC0</span>, <span class="hljs-number">0x80</span>, <span class="hljs-number">0x41</span>,<br>  <span class="hljs-number">0x00</span>, <span class="hljs-number">0xC1</span>, <span class="hljs-number">0x81</span>, <span class="hljs-number">0x40</span>, <span class="hljs-number">0x01</span>, <span class="hljs-number">0xC0</span>, <span class="hljs-number">0x80</span>, <span class="hljs-number">0x41</span>, <span class="hljs-number">0x01</span>, <span class="hljs-number">0xC0</span>, <span class="hljs-number">0x80</span>, <span class="hljs-number">0x41</span>,<br>  <span class="hljs-number">0x00</span>, <span class="hljs-number">0xC1</span>, <span class="hljs-number">0x81</span>, <span class="hljs-number">0x40</span><br>&#125;;<br><br><span class="hljs-type">unsigned</span> <span class="hljs-type">char</span> aucCRCLo[]&#123;<br>  <span class="hljs-number">0x00</span>, <span class="hljs-number">0xC0</span>, <span class="hljs-number">0xC1</span>, <span class="hljs-number">0x01</span>, <span class="hljs-number">0xC3</span>, <span class="hljs-number">0x03</span>, <span class="hljs-number">0x02</span>, <span class="hljs-number">0xC2</span>, <span class="hljs-number">0xC6</span>, <span class="hljs-number">0x06</span>, <span class="hljs-number">0x07</span>, <span class="hljs-number">0xC7</span>,<br>  <span class="hljs-number">0x05</span>, <span class="hljs-number">0xC5</span>, <span class="hljs-number">0xC4</span>, <span class="hljs-number">0x04</span>, <span class="hljs-number">0xCC</span>, <span class="hljs-number">0x0C</span>, <span class="hljs-number">0x0D</span>, <span class="hljs-number">0xCD</span>, <span class="hljs-number">0x0F</span>, <span class="hljs-number">0xCF</span>, <span class="hljs-number">0xCE</span>, <span class="hljs-number">0x0E</span>,<br>  <span class="hljs-number">0x0A</span>, <span class="hljs-number">0xCA</span>, <span class="hljs-number">0xCB</span>, <span class="hljs-number">0x0B</span>, <span class="hljs-number">0xC9</span>, <span class="hljs-number">0x09</span>, <span class="hljs-number">0x08</span>, <span class="hljs-number">0xC8</span>, <span class="hljs-number">0xD8</span>, <span class="hljs-number">0x18</span>, <span class="hljs-number">0x19</span>, <span class="hljs-number">0xD9</span>,<br>  <span class="hljs-number">0x1B</span>, <span class="hljs-number">0xDB</span>, <span class="hljs-number">0xDA</span>, <span class="hljs-number">0x1A</span>, <span class="hljs-number">0x1E</span>, <span class="hljs-number">0xDE</span>, <span class="hljs-number">0xDF</span>, <span class="hljs-number">0x1F</span>, <span class="hljs-number">0xDD</span>, <span class="hljs-number">0x1D</span>, <span class="hljs-number">0x1C</span>, <span class="hljs-number">0xDC</span>,<br>  <span class="hljs-number">0x14</span>, <span class="hljs-number">0xD4</span>, <span class="hljs-number">0xD5</span>, <span class="hljs-number">0x15</span>, <span class="hljs-number">0xD7</span>, <span class="hljs-number">0x17</span>, <span class="hljs-number">0x16</span>, <span class="hljs-number">0xD6</span>, <span class="hljs-number">0xD2</span>, <span class="hljs-number">0x12</span>, <span class="hljs-number">0x13</span>, <span class="hljs-number">0xD3</span>,<br>  <span class="hljs-number">0x11</span>, <span class="hljs-number">0xD1</span>, <span class="hljs-number">0xD0</span>, <span class="hljs-number">0x10</span>, <span class="hljs-number">0xF0</span>, <span class="hljs-number">0x30</span>, <span class="hljs-number">0x31</span>, <span class="hljs-number">0xF1</span>, <span class="hljs-number">0x33</span>, <span class="hljs-number">0xF3</span>, <span class="hljs-number">0xF2</span>, <span class="hljs-number">0x32</span>,<br>  <span class="hljs-number">0x36</span>, <span class="hljs-number">0xF6</span>, <span class="hljs-number">0xF7</span>, <span class="hljs-number">0x37</span>, <span class="hljs-number">0xF5</span>, <span class="hljs-number">0x35</span>, <span class="hljs-number">0x34</span>, <span class="hljs-number">0xF4</span>, <span class="hljs-number">0x3C</span>, <span class="hljs-number">0xFC</span>, <span class="hljs-number">0xFD</span>, <span class="hljs-number">0x3D</span>,<br>  <span class="hljs-number">0xFF</span>, <span class="hljs-number">0x3F</span>, <span class="hljs-number">0x3E</span>, <span class="hljs-number">0xFE</span>, <span class="hljs-number">0xFA</span>, <span class="hljs-number">0x3A</span>, <span class="hljs-number">0x3B</span>, <span class="hljs-number">0xFB</span>, <span class="hljs-number">0x39</span>, <span class="hljs-number">0xF9</span>, <span class="hljs-number">0xF8</span>, <span class="hljs-number">0x38</span>,<br>  <span class="hljs-number">0x28</span>, <span class="hljs-number">0xE8</span>, <span class="hljs-number">0xE9</span>, <span class="hljs-number">0x29</span>, <span class="hljs-number">0xEB</span>, <span class="hljs-number">0x2B</span>, <span class="hljs-number">0x2A</span>, <span class="hljs-number">0xEA</span>, <span class="hljs-number">0xEE</span>, <span class="hljs-number">0x2E</span>, <span class="hljs-number">0x2F</span>, <span class="hljs-number">0xEF</span>,<br>  <span class="hljs-number">0x2D</span>, <span class="hljs-number">0xED</span>, <span class="hljs-number">0xEC</span>, <span class="hljs-number">0x2C</span>, <span class="hljs-number">0xE4</span>, <span class="hljs-number">0x24</span>, <span class="hljs-number">0x25</span>, <span class="hljs-number">0xE5</span>, <span class="hljs-number">0x27</span>, <span class="hljs-number">0xE7</span>, <span class="hljs-number">0xE6</span>, <span class="hljs-number">0x26</span>,<br>  <span class="hljs-number">0x22</span>, <span class="hljs-number">0xE2</span>, <span class="hljs-number">0xE3</span>, <span class="hljs-number">0x23</span>, <span class="hljs-number">0xE1</span>, <span class="hljs-number">0x21</span>, <span class="hljs-number">0x20</span>, <span class="hljs-number">0xE0</span>, <span class="hljs-number">0xA0</span>, <span class="hljs-number">0x60</span>, <span class="hljs-number">0x61</span>, <span class="hljs-number">0xA1</span>,<br>  <span class="hljs-number">0x63</span>, <span class="hljs-number">0xA3</span>, <span class="hljs-number">0xA2</span>, <span class="hljs-number">0x62</span>, <span class="hljs-number">0x66</span>, <span class="hljs-number">0xA6</span>, <span class="hljs-number">0xA7</span>, <span class="hljs-number">0x67</span>, <span class="hljs-number">0xA5</span>, <span class="hljs-number">0x65</span>, <span class="hljs-number">0x64</span>, <span class="hljs-number">0xA4</span>,<br>  <span class="hljs-number">0x6C</span>, <span class="hljs-number">0xAC</span>, <span class="hljs-number">0xAD</span>, <span class="hljs-number">0x6D</span>, <span class="hljs-number">0xAF</span>, <span class="hljs-number">0x6F</span>, <span class="hljs-number">0x6E</span>, <span class="hljs-number">0xAE</span>, <span class="hljs-number">0xAA</span>, <span class="hljs-number">0x6A</span>, <span class="hljs-number">0x6B</span>, <span class="hljs-number">0xAB</span>,<br>  <span class="hljs-number">0x69</span>, <span class="hljs-number">0xA9</span>, <span class="hljs-number">0xA8</span>, <span class="hljs-number">0x68</span>, <span class="hljs-number">0x78</span>, <span class="hljs-number">0xB8</span>, <span class="hljs-number">0xB9</span>, <span class="hljs-number">0x79</span>, <span class="hljs-number">0xBB</span>, <span class="hljs-number">0x7B</span>, <span class="hljs-number">0x7A</span>, <span class="hljs-number">0xBA</span>,<br>  <span class="hljs-number">0xBE</span>, <span class="hljs-number">0x7E</span>, <span class="hljs-number">0x7F</span>, <span class="hljs-number">0xBF</span>, <span class="hljs-number">0x7D</span>, <span class="hljs-number">0xBD</span>, <span class="hljs-number">0xBC</span>, <span class="hljs-number">0x7C</span>, <span class="hljs-number">0xB4</span>, <span class="hljs-number">0x74</span>, <span class="hljs-number">0x75</span>, <span class="hljs-number">0xB5</span>,<br>  <span class="hljs-number">0x77</span>, <span class="hljs-number">0xB7</span>, <span class="hljs-number">0xB6</span>, <span class="hljs-number">0x76</span>, <span class="hljs-number">0x72</span>, <span class="hljs-number">0xB2</span>, <span class="hljs-number">0xB3</span>, <span class="hljs-number">0x73</span>, <span class="hljs-number">0xB1</span>, <span class="hljs-number">0x71</span>, <span class="hljs-number">0x70</span>, <span class="hljs-number">0xB0</span>,<br>  <span class="hljs-number">0x50</span>, <span class="hljs-number">0x90</span>, <span class="hljs-number">0x91</span>, <span class="hljs-number">0x51</span>, <span class="hljs-number">0x93</span>, <span class="hljs-number">0x53</span>, <span class="hljs-number">0x52</span>, <span class="hljs-number">0x92</span>, <span class="hljs-number">0x96</span>, <span class="hljs-number">0x56</span>, <span class="hljs-number">0x57</span>, <span class="hljs-number">0x97</span>,<br>  <span class="hljs-number">0x55</span>, <span class="hljs-number">0x95</span>, <span class="hljs-number">0x94</span>, <span class="hljs-number">0x54</span>, <span class="hljs-number">0x9C</span>, <span class="hljs-number">0x5C</span>, <span class="hljs-number">0x5D</span>, <span class="hljs-number">0x9D</span>, <span class="hljs-number">0x5F</span>, <span class="hljs-number">0x9F</span>, <span class="hljs-number">0x9E</span>, <span class="hljs-number">0x5E</span>,<br>  <span class="hljs-number">0x5A</span>, <span class="hljs-number">0x9A</span>, <span class="hljs-number">0x9B</span>, <span class="hljs-number">0x5B</span>, <span class="hljs-number">0x99</span>, <span class="hljs-number">0x59</span>, <span class="hljs-number">0x58</span>, <span class="hljs-number">0x98</span>, <span class="hljs-number">0x88</span>, <span class="hljs-number">0x48</span>, <span class="hljs-number">0x49</span>, <span class="hljs-number">0x89</span>,<br>  <span class="hljs-number">0x4B</span>, <span class="hljs-number">0x8B</span>, <span class="hljs-number">0x8A</span>, <span class="hljs-number">0x4A</span>, <span class="hljs-number">0x4E</span>, <span class="hljs-number">0x8E</span>, <span class="hljs-number">0x8F</span>, <span class="hljs-number">0x4F</span>, <span class="hljs-number">0x8D</span>, <span class="hljs-number">0x4D</span>, <span class="hljs-number">0x4C</span>, <span class="hljs-number">0x8C</span>,<br>  <span class="hljs-number">0x44</span>, <span class="hljs-number">0x84</span>, <span class="hljs-number">0x85</span>, <span class="hljs-number">0x45</span>, <span class="hljs-number">0x87</span>, <span class="hljs-number">0x47</span>, <span class="hljs-number">0x46</span>, <span class="hljs-number">0x86</span>, <span class="hljs-number">0x82</span>, <span class="hljs-number">0x42</span>, <span class="hljs-number">0x43</span>, <span class="hljs-number">0x83</span>,<br>  <span class="hljs-number">0x41</span>, <span class="hljs-number">0x81</span>, <span class="hljs-number">0x80</span>, <span class="hljs-number">0x40</span><br>&#125;;<br><br><span class="hljs-function"><span class="hljs-type">unsigned</span> <span class="hljs-type">short</span> <span class="hljs-title">GetQuickCRC16</span><span class="hljs-params">(<span class="hljs-type">unsigned</span> <span class="hljs-type">char</span> * pBuffer, <span class="hljs-type">int</span> Length)</span> </span><br><span class="hljs-function"></span>&#123;<br>  <span class="hljs-type">unsigned</span> <span class="hljs-type">char</span> CRCHi = <span class="hljs-number">0xFF</span>;<br>  <span class="hljs-type">unsigned</span> <span class="hljs-type">char</span> CRCLo = <span class="hljs-number">0xFF</span>;<br>  <span class="hljs-type">unsigned</span> <span class="hljs-type">char</span> iIndex = <span class="hljs-number">0</span>;<br>  <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; Length; i++)<br>  &#123;<br>    iIndex = CRCHi ^ pBuffer[i];<br>    CRCHi = CRCLo ^ aucCRCHi[iIndex];<br>    CRCLo = aucCRCLo[iIndex];<br>  &#125;<br>  <span class="hljs-keyword">return</span> (<span class="hljs-type">unsigned</span> <span class="hljs-type">int</span>)( CRCHi &lt;&lt; <span class="hljs-number">8</span> | CRCLo);<span class="hljs-comment">// CRC校验返回值 </span><br>&#125;<br></code></pre></td></tr></table></figure>
</li>
<li>
<p>5.3.6.5 Redis为什么用CRC不用MD5/checksum?</p>
<p>可能MD5、SHA都是128位的，用于加密或者校验，CRC形式灵活。</p>
</li>
<li>
<p>5.3.6.6 Redis Cluster 怎么保证高可用？</p>
<p>参考<sup class="footnote-ref"><a href="#fn35" id="fnref35">[35]</a></sup>。</p>
<ul>
<li>故障转移，当一个Master被其他Master判定为客观下线后，Master发起投票，选出故障Master的Slave之一作为新Master，Slave执行slaveof no one成为新Master并发出pong。</li>
</ul>
</li>
<li>
<p>5.3.6.7 Redis Cluster 使用起来有什么需要注意的？</p>
</li>
<li>
<p>5.3.6.8 Redis Cluster有什么限制？</p>
<p>由于集群中的数据分布在不同节点中，导致一些功能受限，包括：</p>
<ol>
<li>key批量操作受限：例如mget、mset操作，只有当操作的key都位于一个槽时，才能进行。针对该问题，一种思路是在客户端记录槽与key的信息，每次针对特定槽执行mget/mset；另外一种思路是使用Hash Tag，将在下一小节介绍。</li>
<li>keys/flushall等操作：keys/flushall等操作可以在任一节点执行，但是结果只针对当前节点，例如keys操作只返回当前节点的所有键。针对该问题，可以在客户端使用cluster nodes获取所有节点信息，并对其中的所有主节点执行keys/flushall等操作。</li>
<li>事务/Lua脚本：集群支持事务及Lua脚本，但前提条件是所涉及的key必须在同一个节点。Hash Tag可以解决该问题。</li>
<li>数据库：单机Redis节点可以支持16个数据库<sup class="footnote-ref"><a href="#fn36" id="fnref36">[36]</a></sup>，集群模式下只支持一个，即db0。</li>
<li>复制结构：只支持一层复制结构，不支持嵌套。</li>
<li>key是数据分区的最小粒度：不支持bigkey分区</li>
</ol>
</li>
<li>
<p>5.3.6.8.1 Redis的数据库是什么概念？</p>
<p>关系型数据库多个库常用于存储不同应用程序的数据 ，且没有方式可以同时清空实例下的所有库数据。所以对于Redis来说这些db更像是一种命名空间，且不适宜存储不同应用程序的数据。比如可以使用0号数据库存储某个应用生产环境中的数据，使用1号数据库存储测试环境中的数据，但不适宜使用0号数据库存储A应用的数据而使用1号数据库B应用的数据，不同的应用应该使用不同的Redis实例存储数据。Redis非常轻量级，一个空Redis实例占用的内在只有1M左右，所以不用担心多个Redis实例会额外占用很多内存。</p>
</li>
<li>
<p>5.3.6.8.2 什么是Hash Tag？</p>
<p>Hash Tag原理是：当一个key包含 {} 的时候，不对整个key做hash，而仅对 {} 包括的字符串做hash。</p>
<p>Hash Tag可以让不同的key拥有相同的hash值，从而分配在同一个槽里；这样针对不同key的批量操作(mget/mset等)，以及事务、Lua脚本等都可以支持。不过Hash Tag可能会带来数据分配不均的问题，这时需要：(1)调整不同节点中槽的数量，使数据分布尽量均匀；(2)避免对热点数据使用Hash Tag，导致请求分布不均。</p>
</li>
<li>
<p>5.3.6.9 Redis Cluster如何通信的？</p>
<p><strong>两个端口</strong><br>
在哨兵系统中，节点分为数据节点和哨兵节点：前者存储数据，后者实现额外的控制功能。在集群中，没有数据节点与非数据节点之分：所有的节点都存储数据，也都参与集群状态的维护。为此，集群中的每个节点，都提供了两个TCP端口：</p>
<ul>
<li>普通端口：即我们在前面指定的端口(7000等)。普通端口主要用于为客户端提供服务（与单机节点类似）；但在节点间数据迁移时也会使用。</li>
<li>集群端口：端口号是普通端口+10000（10000是固定值，无法改变），如7000节点的集群端口为17000。集群端口只用于节点之间的通信，如搭建集群、增减节点、故障转移等操作时节点间的通信；不要使用客户端连接集群接口。为了保证集群可以正常工作，在配置防火墙时，要同时开启普通端口和集群端口。</li>
</ul>
<p><strong>Gossip协议</strong><br>
节点间通信，按照通信协议可以分为几种类型：单对单、广播、Gossip协议等。重点是广播和Gossip的对比。</p>
<p>广播是指向集群内所有节点发送消息；优点是集群的收敛速度快(集群收敛是指集群内所有节点获得的集群信息是一致的)，缺点是每条消息都要发送给所有节点，CPU、带宽等消耗较大。</p>
<p>Gossip协议的特点是：在节点数量有限的网络中，每个节点都“随机”的与部分节点通信（并不是真正的随机，而是根据特定的规则选择通信的节点），经过一番杂乱无章的通信，每个节点的状态很快会达到一致。Gossip协议的优点有负载(比广播)低、去中心化、容错性高(因为通信有冗余)等；缺点主要是集群的收敛速度慢。</p>
<p><strong>消息类型</strong><br>
集群中的节点采用固定频率（每秒10次）的定时任务进行通信相关的工作：判断是否需要发送消息及消息类型、确定接收节点、发送消息等。如果集群状态发生了变化，如增减节点、槽状态变更，通过节点间的通信，所有节点会很快得知整个集群的状态，使集群收敛。</p>
<p>节点间发送的消息主要分为5种：meet消息、ping消息、pong消息、fail消息、publish消息。不同的消息类型，通信协议、发送的频率和时机、接收节点的选择等是不同的。</p>
<ul>
<li>MEET消息：在节点握手阶段，当节点收到客户端的CLUSTER MEET命令时，会向新加入的节点发送MEET消息，请求新节点加入到当前集群；新节点收到MEET消息后会回复一个PONG消息。</li>
<li>PING消息：集群里每个节点每秒钟会选择部分节点发送PING消息，接收者收到消息后会回复一个PONG消息。PING消息的内容是自身节点和部分其他节点的状态信息；作用是彼此交换信息，以及检测节点是否在线。PING消息使用Gossip协议发送，接收节点的选择兼顾了收敛速度和带宽成本，具体规则如下：(1)随机找5个节点，在其中选择最久没有通信的1个节点(2)扫描节点列表，选择最近一次收到PONG消息时间大于cluster_node_timeout/2的所有节点，防止这些节点长时间未更新。</li>
<li>PONG消息：PONG消息封装了自身状态数据。可以分为两种：第一种是在接到MEET/PING消息后回复的PONG消息；第二种是指节点向集群广播PONG消息，这样其他节点可以获知该节点的最新信息，例如故障恢复后新的主节点会广播PONG消息。</li>
<li>FAIL消息：当一个主节点判断另一个主节点进入FAIL状态时，会向集群广播这一FAIL消息；接收节点会将这一FAIL消息保存起来，便于后续的判断。</li>
<li>PUBLISH消息：节点收到PUBLISH命令后，会先执行该命令，然后向集群广播这一消息，接收节点也会执行该PUBLISH命令。</li>
</ul>
</li>
<li>
<p>5.3.6.10 redis cluster的参数如何配置？</p>
<p>cluster_node_timeout<br>
cluster_node_timeout参数在前面已经初步介绍；它的默认值是15s，影响包括：</p>
<ol>
<li>影响PING消息接收节点的选择：值越大对延迟容忍度越高，选择的接收节点越少，可以降低带宽，但会降低收敛速度；应根据带宽情况和应用要求进行调整。</li>
<li>影响故障转移的判定和时间：值越大，越不容易误判，但完成转移消耗时间越长；应根据网络状况和应用要求进行调整。</li>
</ol>
<p>cluster-require-full-coverage<br>
前面提到，只有当16384个槽全部分配完毕时，集群才能上线。这样做是为了保证集群的完整性，但同时也带来了新的问题：当主节点发生故障而故障转移尚未完成，原主节点中的槽不在任何节点中，此时会集群处于下线状态，无法响应客户端的请求。<br>
cluster-require-full-coverage参数可以改变这一设定：如果设置为no，则当槽没有完全分配时，集群仍可以上线。参数默认值为yes，如果应用对可用性要求较高，可以修改为no，但需要自己保证槽全部分配。</p>
</li>
<li>
<p>5.3.6.11 用过redis-trib.rb吗？</p>
</li>
<li>
<p>5.3.6.12 Redis的选举流程？</p>
<p>Raft算法。<sup class="footnote-ref"><a href="#fn37" id="fnref37">[37]</a></sup><sup class="footnote-ref"><a href="#fn21" id="fnref21:1">[21:1]</a></sup></p>
<figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs js"><span class="hljs-title class_">Node1</span>                 <span class="hljs-title class_">Node2</span>                 <span class="hljs-title class_">Node3</span><br>   |                    |                     |<br>timeout                 |                     |<br>   X----<span class="hljs-title class_">RequestVote</span>----&gt;|                     |<br>   X--------------------|-----<span class="hljs-title class_">RequestVote</span>----&gt;|<br>   |&lt;-------vote--------X                     |<br>   |&lt;-------vote--------|-------------- ------X<br>become leader           |                     |<br></code></pre></td></tr></table></figure>
</li>
<li>
<p>5.3.7 如果Redis挂了怎么吗？数据会丢失吗？说说Redis是提供了哪些高可用方案？</p>
<ol>
<li>持久化机制。AOF(Append Only File) 和 RDB (Redis Database)。</li>
<li>主从复制。</li>
<li>哨兵。Sentinel。</li>
<li>Cluster。<br>
<sup class="footnote-ref"><a href="#fn38" id="fnref38">[38]</a></sup></li>
</ol>
</li>
<li>
<p>5.3.7.1 具体讲讲持久化两个方案的原理和具体机制，以及如何配置？</p>
<p><sup class="footnote-ref"><a href="#fn39" id="fnref39">[39]</a></sup><br>
RDB全量和AOF增量<br>
RBD：<br>
定时fork执行全量导出。</p>
<ol>
<li>cron每100ms检测，满足save m n，n次变化in m秒。</li>
<li>如果达成，主进程fork，此时阻塞，fork后恢复</li>
<li>子进程根据主进程内存快照生成RDB文件，写入磁盘完成原子替换。</li>
</ol>
<figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs js">[<span class="hljs-variable constant_">REDIS</span>][<span class="hljs-variable constant_">DB_VERSION</span>][<span class="hljs-variable constant_">SELECTDB</span>][<span class="hljs-number">0</span>][pairs][<span class="hljs-variable constant_">SELECTDB</span>][<span class="hljs-number">3</span>][pairs][<span class="hljs-variable constant_">EOF</span>][checksum]<br></code></pre></td></tr></table></figure>
<p>AOF：<br>
实时写出写命令，定时flush落盘。</p>
<ol>
<li>命令追加(append)：将Redis的写命令追加到缓冲区aof_buf；</li>
<li>文件写入(write)和文件同步(sync)：根据不同的同步策略将aof_buf中的内容同步到硬盘；</li>
<li>文件重写(rewrite)：定期重写AOF文件，达到压缩的目的。</li>
</ol>
<p>appendfsync always[always] no[30s] everysec[1s]</p>
</li>
<li>
<p>5.3.7.2 讲讲哨兵Sentinel机制？</p>
<p><sup class="footnote-ref"><a href="#fn40" id="fnref40">[40]</a></sup><br>
通过一个sentinel集群监控master节点，sentinel集群内的节点是无状态等价的，并持有相同的元信息。</p>
<ol>
<li>定时任务：每个哨兵节点维护了3个定时任务。定时任务的功能分别如下：通过向主从节点发送info命令获取最新的主从结构；通过发布订阅功能获取其他哨兵节点的信息；通过向其他节点发送ping命令进行心跳检测，判断是否下线。</li>
<li>主观下线：哨兵节点在对主节点进行主观下线后，会通过sentinel is-master-down-by-addr命令询问其他哨兵节点该主节点的状态；如果判断主节点下线的哨兵数量达到一定数值，则对该主节点进行客观下线。</li>
<li>客观下线：哨兵节点在对主节点进行主观下线后，会通过sentinel is-master-down-by-addr命令询问其他哨兵节点该主节点的状态；如果判断主节点下线的哨兵数量达到一定数值，则对该主节点进行客观下线。如果从节点和哨兵节点发生故障，被哨兵主观下线后，不会再有后续的客观下线和故障转移操作。</li>
<li>选举领导者哨兵节点：当主节点被判断客观下线以后，各个哨兵节点会进行协商，选举出一个领导者哨兵节点，并由该领导者节点对其进行故障转移操作。监视该主节点的所有哨兵都有可能被选为领导者，选举使用的算法是Raft算法；Raft算法的基本思路是先到先得：即在一轮选举中，哨兵A向B发送成为领导者的申请，如果B没有同意过其他哨兵，则会同意A成为领导者。选举的具体过程这里不做详细描述，一般来说，哨兵选择的过程很快，谁先完成客观下线，一般就能成为领导者。</li>
<li>故障转移：选举出的领导者哨兵，开始进行故障转移操作，该操作大体可以分为3个步骤：</li>
<li>在从节点中选择新的主节点：选择的原则是，首先过滤掉不健康的从节点；然后选择优先级最高的从节点(由slave-priority指定)；如果优先级无法区分，则选择复制偏移量最大的从节点；如果仍无法区分，则选择runid最小的从节点。</li>
<li>更新主从状态：通过slaveof no one命令，让选出来的从节点成为主节点；并通过slaveof命令让其他节点成为其从节点。</li>
<li>将已经下线的主节点(即6379)设置为新的主节点的从节点，当6379重新上线后，它会成为新的主节点的从节点。</li>
</ol>
</li>
<li>
<p>5.3.7.2.1 实际配置sentinel有哪些坑？</p>
<ol>
<li>哨兵节点的数量应不止一个，一方面增加哨兵节点的冗余，避免哨兵本身成为高可用的瓶颈；另一方面减少对下线的误判。此外，这些不同的哨兵节点应部署在不同的物理机上。</li>
<li>哨兵节点的数量应该是奇数，便于哨兵通过投票做出“决策”：领导者选举的决策、客观下线的决策等。</li>
<li>各个哨兵节点的配置应一致，包括硬件、参数等；此外，所有节点都应该使用ntp或类似服务，保证时间准确、一致。</li>
<li>哨兵的配置提供者和通知客户端功能，需要客户端的支持才能实现，如前文所说的Jedis；如果开发者使用的库未提供相应支持，则可能需要开发者自己实现。</li>
<li>当哨兵系统中的节点在docker（或其他可能进行端口映射的软件）中部署时，应特别注意端口映射可能会导致哨兵系统无法正常工作，因为哨兵的工作基于与其他节点的通信，而docker的端口映射可能导致哨兵无法连接到其他节点。例如，哨兵之间互相发现，依赖于它们对外宣称的IP和port，如果某个哨兵A部署在做了端口映射的docker中，那么其他哨兵使用A宣称的port无法连接到A。</li>
</ol>
</li>
<li>
<p>5.3.7.3 Redis是怎么主从复制的？</p>
<p><sup class="footnote-ref"><a href="#fn41" id="fnref41">[41]</a></sup></p>
<p>连接建立阶段（即准备阶段）、数据同步阶段、命令传播阶段</p>
<p><strong>连接建立阶段</strong></p>
<p>从节点发起连接请求。</p>
<p><strong>数据同步阶段</strong><br>
主从节点之间的连接建立以后，便可以开始进行数据同步，该阶段可以理解为从节点数据的初始化。具体执行的方式是：从节点向主节点发送psync命令（Redis2.8以前是sync命令），开始同步。</p>
<p>数据同步阶段是主从复制最核心的阶段，根据主从节点当前状态的不同，可以分为全量复制和部分复制，下面会有一章专门讲解这两种复制方式以及psync命令的执行过程，这里不再详述。</p>
<p>需要注意的是，在数据同步阶段之前，从节点是主节点的客户端，主节点不是从节点的客户端；而到了这一阶段及以后，主从节点互为客户端。原因在于：在此之前，主节点只需要响应从节点的请求即可，不需要主动发请求，而在数据同步阶段和后面的命令传播阶段，主节点需要主动向从节点发送请求（如推送缓冲区中的写命令），才能完成复制。</p>
<p>2.8之前是全量复制</p>
<ol>
<li>主节点通过bgsave命令fork子进程进行RDB持久化，该过程是非常消耗CPU、内存(页表复制)、硬盘IO的；关于bgsave的性能问题，可以参考 深入学习Redis（2）：持久化</li>
<li>主节点通过网络将RDB文件发送给从节点，对主从节点的带宽都会带来很大的消耗</li>
<li>从节点清空老数据、载入新RDB文件的过程是阻塞的，无法响应客户端的命令；如果从节点执行bgrewriteaof，也会带来额外的消耗</li>
</ol>
<p>之后引入部分复制</p>
<ol>
<li>
<p>复制偏移量<br>
主节点和从节点分别维护一个复制偏移量（offset），代表的是主节点向从节点传递的字节数；主节点每次向从节点传播N个字节数据时，主节点的offset增加N；从节点每次收到主节点传来的N个字节数据时，从节点的offset增加N。</p>
<p>offset用于判断主从节点的数据库状态是否一致：如果二者offset相同，则一致；如果offset不同，则不一致，此时可以根据两个offset找出从节点缺少的那部分数据。例如，如果主节点的offset是1000，而从节点的offset是500，那么部分复制就需要将offset为501-1000的数据传递给从节点。而offset为501-1000的数据存储的位置，就是下面要介绍的复制积压缓冲区。</p>
</li>
<li>
<p>复制积压缓冲区<br>
复制积压缓冲区<br>
复制积压缓冲区是由主节点维护的、固定长度的、先进先出(FIFO)队列，默认大小1MB；当主节点开始有从节点时创建，其作用是备份主节点最近发送给从节点的数据。注意，无论主节点有一个还是多个从节点，都只需要一个复制积压缓冲区。</p>
<p>在命令传播阶段，主节点除了将写命令发送给从节点，还会发送一份给复制积压缓冲区，作为写命令的备份；除了存储写命令，复制积压缓冲区中还存储了其中的每个字节对应的复制偏移量（offset）。由于复制积压缓冲区定长且是先进先出，所以它保存的是主节点最近执行的写命令；时间较早的写命令会被挤出缓冲区。</p>
<p>由于该缓冲区长度固定且有限，因此可以备份的写命令也有限，当主从节点offset的差距过大超过缓冲区长度时，将无法执行部分复制，只能执行全量复制。反过来说，为了提高网络中断时部分复制执行的概率，可以根据需要增大复制积压缓冲区的大小(通过配置repl-backlog-size)；例如如果网络中断的平均时间是60s，而主节点平均每秒产生的写命令(特定协议格式)所占的字节数为100KB，则复制积压缓冲区的平均需求为6MB，保险起见，可以设置为12MB，来保证绝大多数断线情况都可以使用部分复制。</p>
<p>从节点将offset发送给主节点后，主节点根据offset和缓冲区大小决定能否执行部分复制：</p>
<ul>
<li>如果offset偏移量之后的数据，仍然都在复制积压缓冲区里，则执行部分复制；</li>
<li>如果offset偏移量之后的数据已不在复制积压缓冲区中（数据已被挤出），则执行全量复制。</li>
</ul>
</li>
<li>
<p>服务器运行ID(runid)<br>
每个Redis节点(无论主从)，在启动时都会自动生成一个随机ID(每次启动都不一样)，由40个随机的十六进制字符组成；runid用来唯一识别一个Redis节点。通过info Server命令，可以查看节点的runid：<br>
<code>redis-cli info server | grep runid</code><br>
主从节点初次复制时，主节点将自己的runid发送给从节点，从节点将这个runid保存起来；当断线重连时，从节点会将这个runid发送给主节点；主节点根据runid判断能否进行部分复制：</p>
<ul>
<li>如果从节点保存的runid与主节点现在的runid相同，说明主从节点之前同步过，主节点会继续尝试使用部分复制(到底能不能部分复制还要看offset和复制积压缓冲区的情况)；</li>
<li>如果从节点保存的runid与主节点现在的runid不同，说明从节点在断线前同步的Redis节点并不是当前的主节点，只能进行全量复制。</li>
</ul>
</li>
</ol>
<p><strong>命令传播阶段</strong><br>
数据同步阶段完成后，主从节点进入命令传播阶段；在这个阶段主节点将自己执行的写命令发送给从节点，从节点接收命令并执行，从而保证主从节点数据的一致性。</p>
<p>在命令传播阶段，除了发送写命令，主从节点还维持着心跳机制：PING和REPLCONF ACK。由于心跳机制的原理涉及部分复制，因此将在介绍了部分复制的相关内容后单独介绍该心跳机制。</p>
<p>需要注意的是，命令传播是异步的过程，即主节点发送写命令后并不会等待从节点的回复；因此实际上主从节点之间很难保持实时的一致性，延迟在所难免。数据不一致的程度，与主从节点之间的网络状况、主节点写命令的执行频率、以及主节点中的repl-disable-tcp-nodelay配置等有关。</p>
<p>repl-disable-tcp-nodelay no：该配置作用于命令传播阶段，控制主节点是否禁止与从节点的TCP_NODELAY；默认no，即不禁止TCP_NODELAY。当设置为yes时，TCP会对包进行合并从而减少带宽，但是发送的频率会降低，从节点数据延迟增加，一致性变差；具体发送频率与Linux内核的配置有关，默认配置为40ms。当设置为no时，TCP会立马将主节点的数据发送给从节点，带宽增加但延迟变小。</p>
<p>一般来说，只有当应用对Redis数据不一致的容忍度较高，且主从节点之间网络状况不好时，才会设置为yes；多数情况使用默认值no。</p>
<p>1） 主从节点彼此都有心跳检测机制， 各自模拟成对方的客户端进行通信， 通过client list命令查看复制相关客户端信息， 主节点的连接状态为flags=M， 从节点连接状态为flags=S。<br>
2） 主节点默认每隔10秒对从节点发送ping命令， 判断从节点的存活性和连接状态。 可通过参数repl-ping-slave-period控制发送频率。<br>
3） 从节点在主线程中每隔1秒发送replconf ack{offset}命令， 给主节点上报自身当前的复制偏移量。</p>
</li>
<li>
<p>5.3.8 如何排查redis的性能问题？</p>
<p><strong>Fork阻塞</strong><br>
在Redis的实践中，众多因素限制了Redis单机的内存不能过大，例如：</p>
<ol>
<li>当面对请求的暴增，需要从库扩容时，Redis内存过大会导致扩容时间太长；</li>
<li>当主机宕机时，切换主机后需要挂载从库，Redis内存过大导致挂载速度过慢；</li>
<li>以及持久化过程中的fork操作，下面详细说明。<br>
父进程通过fork操作可以创建子进程；子进程创建后，父子进程共享代码段，不共享进程的数据空间，但是子进程会获得父进程的数据空间的副本。在操作系统fork的实际实现中，基本都采用了写时复制技术，即在父/子进程试图修改数据空间之前，父子进程实际上共享数据空间；但是当父/子进程的任何一个试图修改数据空间时，操作系统会为修改的那一部分(内存的一页)制作一个副本。</li>
</ol>
<p>虽然fork时，子进程不会复制父进程的数据空间，但是会复制内存页表（页表相当于内存的索引、目录）；父进程的数据空间越大，内存页表越大，fork时复制耗时也会越多。</p>
<p>在Redis中，无论是RDB持久化的bgsave，还是AOF重写的bgrewriteaof，都需要fork出子进程来进行操作。如果Redis内存过大，会导致fork操作时复制内存页表耗时过多；而Redis主进程在进行fork时，是完全阻塞的，也就意味着无法响应客户端的请求，会造成请求延迟过大。</p>
<p>对于不同的硬件、不同的操作系统，fork操作的耗时会有所差别，一般来说，如果Redis单机内存达到了10GB，fork时耗时可能会达到百毫秒级别（如果使用Xen虚拟机，这个耗时可能达到秒级别）。因此，一般来说Redis单机内存一般要限制在10GB以内；不过这个数据并不是绝对的，可以通过观察线上环境fork的耗时来进行调整。观察的方法如下：执行命令info stats，查看latest_fork_usec的值，单位为微秒。</p>
<p>为了减轻fork操作带来的阻塞问题，除了控制Redis单机内存的大小以外，还可以适度放宽AOF重写的触发条件、选用物理机或高效支持fork操作的虚拟化技术等，例如使用Vmware或KVM虚拟机，不要使用Xen虚拟机。</p>
<p><strong>AOF追加阻塞</strong><br>
前面提到过，在AOF中，如果AOF缓冲区的文件同步策略为everysec，则：在主线程中，命令写入aof_buf后调用系统write操作，write完成后主线程返回；fsync同步文件操作由专门的文件同步线程每秒调用一次。</p>
<p>这种做法的问题在于，如果硬盘负载过高，那么fsync操作可能会超过1s；如果Redis主线程持续高速向aof_buf写入命令，硬盘的负载可能会越来越大，IO资源消耗更快；如果此时Redis进程异常退出，丢失的数据也会越来越多，可能远超过1s。</p>
<p>为此，Redis的处理策略是这样的：主线程每次进行AOF会对比上次fsync成功的时间；如果距上次不到2s，主线程直接返回；如果超过2s，则主线程阻塞直到fsync同步完成。因此，如果系统硬盘负载过大导致fsync速度太慢，会导致Redis主线程的阻塞；此外，使用everysec配置，AOF最多可能丢失2s的数据，而不是1s。</p>
<p>AOF追加阻塞问题定位的方法：</p>
<p>（1）监控info Persistence中的aof_delayed_fsync：当AOF追加阻塞发生时（即主线程等待fsync而阻塞），该指标累加。</p>
<p>（2）AOF阻塞时的Redis日志：</p>
<p>Asynchronous AOF fsync is taking too long (disk is busy?). Writing the AOF buffer without waiting for fsync to complete, this may slow down Redis.</p>
<p>（3）如果AOF追加阻塞频繁发生，说明系统的硬盘负载太大；可以考虑更换IO速度更快的硬盘，或者通过IO监控分析工具对系统的IO负载进行分析，如iostat（系统级io）、iotop（io版的top）、pidstat等。</p>
<p><strong>内存碎片</strong><br>
mem_fragmentation_ratio一般大于1，且该值越大，内存碎片比例越大。mem_fragmentation_ratio&lt;1，说明Redis使用了虚拟内存，由于虚拟内存的媒介是磁盘，比内存速度要慢很多，当这种情况出现时，应该及时排查，如果内存不足应该及时处理，如增加Redis节点、增加Redis服务器的内存、优化应用等。</p>
</li>
<li>
<p>5.3.9 如何优化redis的性能？</p>
<ol>
<li>持久化，fork和aof阻塞</li>
<li>网络，gossip协议timeout的超时改大，降低带宽占用</li>
</ol>
</li>
<li>
<p>5.3.10 redis的内存是越大越好吗？</p>
<p>在 深入学习Redis（2）：持久化 一文中，讲到了fork操作对Redis单机内存大小的限制。实际上在Redis的使用中，限制单机内存大小的因素非常之多，下面总结一下在主从复制中，单机内存过大可能造成的影响：</p>
<ol>
<li>切主：当主节点宕机时，一种常见的容灾策略是将其中一个从节点提升为主节点，并将其他从节点挂载到新的主节点上，此时这些从节点只能进行全量复制；如果Redis单机内存达到10GB，一个从节点的同步时间在几分钟的级别；如果从节点较多，恢复的速度会更慢。如果系统的读负载很高，而这段时间从节点无法提供服务，会对系统造成很大的压力。</li>
<li>从库扩容：如果访问量突然增大，此时希望增加从节点分担读负载，如果数据量过大，从节点同步太慢，难以及时应对访问量的暴增。</li>
<li>缓冲区溢出：（1）和（2）都是从节点可以正常同步的情形（虽然慢），但是如果数据量过大，导致全量复制阶段主节点的复制缓冲区溢出，从而导致复制中断，则主从节点的数据同步会全量复制-&gt;复制缓冲区溢出导致复制中断-&gt;重连-&gt;全量复制-&gt;复制缓冲区溢出导致复制中断……的循环。</li>
<li>超时：如果数据量过大，全量复制阶段主节点fork+保存RDB文件耗时过大，从节点长时间接收不到数据触发超时，主从节点的数据同步同样可能陷入全量复制-&gt;超时导致复制中断-&gt;重连-&gt;全量复制-&gt;超时导致复制中断……的循环。</li>
</ol>
<p>此外，主节点单机内存除了绝对量不能太大，其占用主机内存的比例也不应过大：最好只使用50%-65%的内存，留下30%-45%的内存用于执行bgsave命令和创建复制缓冲区等。</p>
</li>
<li>
<p>6 Kafka 是你们自己搭的吗？是怎么配置的？</p>
</li>
<li>
<p>6.1 Kafka为什么这么快？</p>
<ol>
<li>分Partition并行处理。kafka中的topic中的内容可以被分为多分区存在，每个分区又分为多个段，所以每次操作都是针对一小部分做操作，很轻便，并且增加并行操作的能力。</li>
<li>顺序写入磁盘。kafka的消息是不断追加到文件中的，这个特性使kafka可以充分利用磁盘的顺序读写性能，顺序读写不需要硬盘磁头的寻道时间，只需很少的扇区旋转时间，所以速度远快于随机读写。对于SSD而言，同样也是顺序读写速度高于随机读写。</li>
<li>Page Cache，减少写磁盘次数。</li>
<li>压缩，减少传输的数据量。。</li>
<li>批量发送。</li>
<li>零拷贝。利用Linux kernel&quot;零拷贝(zero-copy)&quot;系统调用机制，就是跳过“用户缓冲区”的拷贝，建立一个磁盘空间和内存的直接映射，数据不再复制到“用户态缓冲区”。</li>
</ol>
</li>
<li>
<p>6.2 Kafka 怎么扩容？需要做什么处理？</p>
<p><sup class="footnote-ref"><a href="#fn42" id="fnref42">[42]</a></sup>扩容Broker。在扩容之前就已经存在的topic并不会自动地分配分区到新节点上。<br>
增加分区：</p>
<figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs js">./bin/kafka-topics.<span class="hljs-property">sh</span> –zookeeper <span class="hljs-attr">ip</span>:host,<span class="hljs-attr">ip</span>:host,<span class="hljs-attr">ip</span>:host –alter –partitions <span class="hljs-number">5</span> –topic <span class="hljs-title function_">XXX</span>(topic)<br></code></pre></td></tr></table></figure>
<p>重新分区：<a target="_blank" rel="noopener" href="http://kafka-reassign-partitions.sh">kafka-reassign-partitions.sh</a></p>
<ul>
<li>generate模式，给定需要重新分配的topic，自动生成reassign plan（只是生成，并不执行）</li>
<li>execute模式，根据指定的reassign plan重新分配Partition</li>
<li>verify模式，验证重新分配Partition是否成功</li>
</ul>
<ol>
<li>topics-to-move.json</li>
</ol>
<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs json"><span class="hljs-punctuation">&#123;</span><span class="hljs-attr">&quot;topics&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">[</span><span class="hljs-punctuation">&#123;</span><span class="hljs-attr">&quot;topic&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;topic1&quot;</span><span class="hljs-punctuation">&#125;</span><span class="hljs-punctuation">,</span><br>            <span class="hljs-punctuation">&#123;</span><span class="hljs-attr">&quot;topic&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;topic2&quot;</span><span class="hljs-punctuation">&#125;</span><span class="hljs-punctuation">]</span><span class="hljs-punctuation">,</span><br><span class="hljs-attr">&quot;version&quot;</span><span class="hljs-punctuation">:</span><span class="hljs-number">1</span><br><span class="hljs-punctuation">&#125;</span><br></code></pre></td></tr></table></figure>
<ol start="2">
<li>生成partition分配表</li>
</ol>
<figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs js">./kafka-reassign-partitions --zookeeper $&#123;zk_address&#125; --topics-to-move-json-file  topic-to-move.<span class="hljs-property">json</span> --broker-list <span class="hljs-string">&quot;140,141&quot;</span> --generate<br></code></pre></td></tr></table></figure>
<figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs js"><span class="hljs-title class_">Current</span> partition replica assignment<br><br>&#123;<span class="hljs-string">&quot;version&quot;</span>:<span class="hljs-number">1</span>,<span class="hljs-string">&quot;partitions&quot;</span>:[&#123;<span class="hljs-string">&quot;topic&quot;</span>:<span class="hljs-string">&quot;testTopic&quot;</span>,<span class="hljs-string">&quot;partition&quot;</span>:<span class="hljs-number">1</span>,<span class="hljs-string">&quot;replicas&quot;</span>:[<span class="hljs-number">61</span>,<span class="hljs-number">62</span>]&#125;,&#123;<span class="hljs-string">&quot;topic&quot;</span>:<span class="hljs-string">&quot;testTopic&quot;</span>,<span class="hljs-string">&quot;partition&quot;</span>:<span class="hljs-number">0</span>,<span class="hljs-string">&quot;replicas&quot;</span>:[<span class="hljs-number">62</span>,<span class="hljs-number">61</span>]&#125;]&#125;<br><br><span class="hljs-title class_">Proposed</span> partition reassignment configuration<br><br>&#123;<span class="hljs-string">&quot;version&quot;</span>:<span class="hljs-number">1</span>,<span class="hljs-string">&quot;partitions&quot;</span>:[&#123;<span class="hljs-string">&quot;topic&quot;</span>:<span class="hljs-string">&quot;testTopic&quot;</span>,<span class="hljs-string">&quot;partition&quot;</span>:<span class="hljs-number">1</span>,<span class="hljs-string">&quot;replicas&quot;</span>:[<span class="hljs-number">140</span>,<span class="hljs-number">141</span>]&#125;,&#123;<span class="hljs-string">&quot;topic&quot;</span>:<span class="hljs-string">&quot;testTopic&quot;</span>,<span class="hljs-string">&quot;partition&quot;</span>:<span class="hljs-number">0</span>,<span class="hljs-string">&quot;replicas&quot;</span>:[<span class="hljs-number">141</span>,<span class="hljs-number">140</span>]&#125;]&#125;<br></code></pre></td></tr></table></figure>
<ol start="3">
<li>执行迁移</li>
</ol>
<figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs js">./kafka-reassign-partitions --zookeeper $&#123;zk_address&#125;  --reassignment-json-file expand-cluster-reassignment.<span class="hljs-property">json</span> --execute<br></code></pre></td></tr></table></figure>
<ol start="4">
<li>查看迁移进度</li>
</ol>
<figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs js">./kafka-reassign-partitions --zookeeper $&#123;zk_address&#125; --reassignment-json-file expand-cluster-reassignment.<span class="hljs-property">json</span> --verify<br></code></pre></td></tr></table></figure>
</li>
<li>
<p>6.3 Partition越多越好吗？为什么？</p>
<p><sup class="footnote-ref"><a href="#fn43" id="fnref43">[43]</a></sup></p>
<ul>
<li>
<p>越多的partition可以提供更高的吞吐量，但是网络IO资源受限于Broker。</p>
</li>
<li>
<p>越多的分区需要打开更多的文件句柄。<br>
在kafka的数据日志文件目录中，每个日志数据段都会分配两个文件，一个索引文件和一个数据文件。因此，随着partition的增多，需要的文件句柄数急剧增加，必要时需要调整操作系统允许打开的文件句柄数。</p>
</li>
<li>
<p>更多的分区会导致端对端的延迟<br>
kafka端对端的延迟为producer端发布消息到consumer端消费消息所需的时间，即consumer接收消息的时间减去produce发布消息的时间。kafka在消息正确接收后才会暴露给消费者，即在保证in-sync副本复制成功之后才会暴露，瓶颈则来自于此。在一个broker上的副本从其他broker的leader上复制数据的时候只会开启一个线程，假设partition数量为n，每个副本同步的时间为1ms，那in-sync操作完成所需的时间即n*1ms，若n为10000，则需要10秒才能返回同步状态，数据才能暴露给消费者，这就导致了较大的端对端的延迟。</p>
</li>
<li>
<p>越多的partition意味着需要更多的内存<br>
在新版本的kafka中可以支持批量提交和批量消费，而设置了批量提交和批量消费后，每个partition都会需要一定的内存空间。假设为100k，当partition为100时，producer端和consumer端都需要10M的内存；当partition为100000时，producer端和consumer端则都需要10G内存。无限的partition数量很快就会占据大量的内存，造成性能瓶颈。</p>
</li>
<li>
<p>越多的partition会导致更长时间的恢复期，降低高可用性<br>
kafka通过多副本复制技术，实现kafka的高可用性和稳定性。每个partition都会有多个副本存在于多个broker中，其中一个副本为leader，其余的为follower。当kafka集群其中一个broker出现故障时，在这个broker上的leader会需要在其他broker上重新选择一个副本启动为leader，这个过程由kafka controller来完成，主要是从Zookeeper读取和修改受影响partition的一些元数据信息。</p>
<p>通常情况下，当一个broker有计划的停机上，该broker上的partition leader会在broker停机前有次序的一一移走，假设移走一个需要1ms，10个partition leader则需要10ms，这影响很小，并且在移动其中一个leader的时候，其他九个leader是可用的，因此实际上每个partition leader的不可用时间为1ms。但是在宕机情况下，所有的10个partition</p>
<p>leader同时无法使用，需要依次移走，最长的leader则需要10ms的不可用时间窗口，平均不可用时间窗口为5.5ms，假设有10000个leader在此宕机的broker上，平均的不可用时间窗口则为5.5s。</p>
<p>更极端的情况是，当时的broker是kafka controller所在的节点，那需要等待新的kafka leader节点在投票中产生并启用，之后新启动的kafka leader还需要从zookeeper中读取每一个partition的元数据信息用于初始化数据。在这之前partition leader的迁移一直处于等待状态。</p>
</li>
<li>
<p>如何确定分区数量呢？</p>
<p>可以遵循一定的步骤来尝试确定分区数：创建一个只有1个分区的topic，然后测试这个topic的producer吞吐量和consumer吞吐量。假设它们的值分别是Tp和Tc，单位可以是MB/s。然后假设总的目标吞吐量是Tt，那么分区数 =  Tt / max(Tp, Tc)</p>
<p>说明：Tp表示producer的吞吐量。测试producer通常是很容易的，因为它的逻辑非常简单，就是直接发送消息到Kafka就好了。Tc表示consumer的吞吐量。测试Tc通常与应用的关系更大， 因为Tc的值取决于你拿到消息之后执行什么操作，因此Tc的测试通常也要麻烦一些。</p>
</li>
</ul>
</li>
<li>
<p>7 怎么部署的服务？</p>
<p>阿里云ACK集群，k8s。</p>
</li>
<li>
<p>7.1 k8s的服务结构知道？</p>
<p><img src="/images/kubernetes-high-level-component-archtecture.jpg" alt="k8s arch"></p>
<p>Control Plane:</p>
<ul>
<li>etcd 分布式KV数据库，用于保存集群状态</li>
<li>api-server 提供了资源操作的唯一入口，并提供认证、授权、访问控制、API 注册和发现等机制</li>
<li>scheduler 负责资源的调度，按照预定的调度策略将 Pod 调度到相应的机器上</li>
<li>controller-manager 负责维护集群的状态，比如故障检测、自动扩展、滚动更新等</li>
<li>cloud-controller-manager 可选，云服务商API</li>
</ul>
<p>Node:</p>
<ul>
<li>kube-proxy 为 Service 提供 cluster 内部的服务发现和负载均衡</li>
<li>kubelet 负责维护容器的生命周期，同时也负责 Volume（CSI）和网络（CNI）的管理</li>
<li>container runtime 负责镜像管理以及 Pod 和容器的真正运行（CRI）</li>
</ul>
<p>Plugin:</p>
<ul>
<li>CoreDNS 负责为整个集群提供 DNS 服务</li>
<li>Ingress Controller 为服务提供外网入口</li>
<li>Prometheus 提供资源监控</li>
<li>Dashboard 提供 GUI</li>
<li>Federation 提供跨可用区的集群</li>
</ul>
</li>
<li>
<p>7.2 StatefulSet知道吗？说说功能和原理？</p>
<p>用于保证一组pod的启动顺序和固定分配名称。即使挂掉后重启依然使用之前的名称，用于有状态的系统部署，如MySQL，ZooKeeper等。<br>
使用Headless Service暴露Pod域名。</p>
</li>
<li>
<p>7.3 怎么Debug，比如系统Latency高，QPS低等，怎么排查问题？</p>
<p>查看节点资源利用率。如果是网络问题使用抓包软件dump，需要检查是否集群配置了规格过低的NAT，错误地使用了公网域名而不是VPC域名。<br>
需要在预发环境下重现，并逐级排查。<br>
可以在代码中添加tracing。</p>
<ul>
<li>
<p>7.3.1 怎么Tracing？</p>
</li>
<li>
<p>7.3.2 如果预发环境复现不了怎么办？</p>
</li>
<li>
<p>7.3.3 怎么测试和修复不影响线上？</p>
</li>
</ul>
</li>
<li>
<p>7.4 什么是Headless Service? 有什么用？</p>
<p><sup class="footnote-ref"><a href="#fn44" id="fnref44">[44]</a></sup><br>
有时候不需要将pod作为一组服务暴露，可以把ClusterIP设为None，这时就是Headless Service，暴露所有endpoints，不经过kube-proxy，可以直接访问pod的域名，搭配StatefulSet可以获得固定pod地址。</p>
</li>
<li>
<p>7.5 Docker Swarm 和 Kubernetes 有什么区别？</p>
<p><sup class="footnote-ref"><a href="#fn45" id="fnref45">[45]</a></sup></p>
</li>
<li>
<p>7.6 在k8s上部署过有状态应用吗？遇到了什么麻烦？</p>
</li>
<li>
<p>7.7 Init Container功能是什么？怎么执行的？</p>
</li>
<li>
<p>7.8 什么是Operator？功能是什么？写过吗？</p>
</li>
<li>
<p>8 计量计费这块是怎么做的？怎么防止计费出错？</p>
<p>我们每五分钟统计一次消耗quota，并且推送到阿里云的计量计费系统，系统也是每五分钟发起出账任务，类型为实时按月重批价。<br>
出错分几种情况：</p>
<ol>
<li>无法往里写入时间戳，等待并重试3次。写入时间戳和统计数量作为一个transaction，写入或统计出错会回滚。交由下个时间点合并统计。</li>
<li>向计量系统推送出错，back-off重试。</li>
<li>pipeline向数据库写入，可在推送前数据手工处理。</li>
<li>可发起手工任务向计量系统推送。</li>
</ol>
</li>
<li>
<p>9 怎么做的监控？</p>
<p>Prometheus &amp; Grafana Alter</p>
</li>
<li>
<p>9.1 prometheus监控了什么？做了什么配置？</p>
<p>微服务内，使用go-prometheus的接口监控API指标，短信发送速率，发送量等，监控与报警。<br>
ACK提供了node和pod的监控与报警。</p>
</li>
<li>
<p>10 怎么管理短信发送和算法任务的？</p>
<p>由统一的任务启动器启动和删除。通过k8s的API启动Job/CronJob。</p>
</li>
<li>
<p>10.1 如何监控这些启动任务的状态的？</p>
</li>
<li>
<p>11 怎么区分不同优先级和不同用户的？</p>
<p>我们在三个维度上区分优先级。</p>
<ol>
<li>短信类型。短信类型可以分成营销、通知和验证码三类，分别对应的通道质量和要求是不一样的。营销短信的时效性通常在一天到一周左右，有可能遭到用户屏蔽。通知类短信的时效性在小时级别，验证码的时效性在分钟级别，因此这三类短信是分别用不同质量的通道账号维护的，会在API服务写入不同的Kafka Topic，每个Topic并行发送，互相独立，超时等配置略有区别，保证验证码短信的时效性和通道质量。</li>
<li>用户类型。在短信类型的维度上区分用户类型，优先保证VIP客户的发送质量，同样使用Topic区隔。</li>
<li>用户间，用户可能会出现一个用户集中发送，导致其他用户排队的情况，目前我们没有专门处理，而是使用Kafka的Key分区机制，让不同uid的客户分配到不同的Partition上去，consumer消费时尽量round robin交叉消费，缓解排队问题。如果有用户需要完全独立不受影响的通道或者更高质量的通道，我们可以增加一系列user_xxx的topic，并且用完全匹配或者正则匹配消费topic。或者在消费端增加用户Specific的Channel。</li>
</ol>
</li>
<li>
<p>11.1 Kafka的Topic有数量限制吗？为什么？</p>
<p>超过1000个会明显影响性能。因为Kafka的每个Topic都是独立顺序写入自己的缓冲区的，因此在Topic数量越多，越碎片化，越接近随机读写。</p>
</li>
<li>
<p>12 服务节点挂了怎么处理？升级的时候怎么不影响业务？</p>
</li>
<li>
<p>13 Go的基础知识</p>
</li>
<li>
<p>13.1 怎么管理go的包的，会有版本冲突问题吗？</p>
</li>
<li>
<p>13.2 go为什么这么快？</p>
</li>
<li>
<p>13.3 go的并发模型？</p>
<p>CSP。 CSP（communicating sequential processes）</p>
<ul>
<li>并发实体，通常可以理解为执行线程，它们相互独立，且并发执行；</li>
<li>通道，并发实体之间使用通道发送信息。</li>
</ul>
</li>
<li>
<p>13.3.1 go的线程模型和常见的线程模型有什么区别。</p>
<p><sup class="footnote-ref"><a href="#fn46" id="fnref46">[46]</a></sup><sup class="footnote-ref"><a href="#fn47" id="fnref47">[47]</a></sup></p>
<p>常见的线程模型是1级模型，包括1:1, 1:M，M:N。Go用的是GMP模型，两级模型。GMP分别表示Goroutine，Machine和Process，第一级是Goroutine到Process，goroutine被分配到全局队列和process的队列，第二级是Process到Machine，Machine对应操作系统的内核线程，当Machine不足时会创建新的M。</p>
<p>G理论上没有数量上限限制的。查看当前G的数量可以使用runtime. NumGoroutine()。<br>
P由启动时环境变量 $GOMAXPROCS 或者是由runtime.GOMAXPROCS() 决定。这意味着在程序执行的任意时刻都只有 $GOMAXPROCS 个 goroutine 在同时运行。<br>
M go 语言本身的限制：go 程序启动时，会设置 M 的最大数量，默认 10000. 但是内核很难支持这么多的线程数，所以这个限制可以忽略。 runtime/debug 中的 SetMaxThreads 函数，设置 M 的最大数量 一个 M 阻塞了，会创建新的 M。M 与 P 的数量没有绝对关系，一个 M 阻塞，P 就会去创建或者切换另一个 M，所以，即使 P 的默认数量是 1，也有可能会创建很多个 M 出来。</p>
</li>
<li>
<p>13.3.2 Linux的线程调度模型是1:1，1:M，还是M:N？</p>
<p>是1:1。Linux历史上经历了三个主要版本的线程模型，首先是LinuxThreads，是1:1模型，但因为LinuxThreads不符合POSIX规范并且有许多缺陷，后来IBM开发了NGPT，是M:N模型，性能比LinuxThreads高，但比较复杂。后来NPTL又出现，是1:1模型，性能更高，曾经它也想用M:N模型，但过于复杂，需要对内核进行大范围改动。<sup class="footnote-ref"><a href="#fn48" id="fnref48">[48]</a></sup><sup class="footnote-ref"><a href="#fn49" id="fnref49">[49]</a></sup></p>
</li>
<li>
<p>13.4 go的内存模型？</p>
<p>TCMalloc</p>
</li>
<li>
<p>13.4.1 tcmalloc有什么问题？有代替方案吗？</p>
<p><sup class="footnote-ref"><a href="#fn50" id="fnref50">[50]</a></sup></p>
</li>
<li>
<p>13.5 go的gc怎么做的？</p>
<p>三色标记法</p>
</li>
<li>
<p>13.6 为什么goroutine可以开很多，有数量限制吗？和线程和进程有什么区别？</p>
<p>goroutine是在user space的轻量级调度结构，由go runtime调度。相比之下，线程与进程是由操作系统调度，context switching的开销要大很多。</p>
</li>
<li>
<p>13.6.1 协程，线程和进程具体有什么区别？</p>
</li>
<li>
<p>13.7 go怎么做错误处理，sub goroutine的panic怎么处理。</p>
</li>
<li>
<p>13.8 go有什么问题？</p>
</li>
<li>
<p>13.9 channel有什么坑？</p>
</li>
<li>
<p>13.9.1 无缓冲 chan 的发送和接收是否同步？</p>
<p>发送端会阻塞直到接受。</p>
</li>
<li>
<p>13.9.2 channel是怎么实现的？</p>
<p>环形队列加锁。Circular Queue With Mutex。</p>
</li>
<li>
<p>13.9.3 如果使用了channel，在线上升级版本的时候会不会丢失数据，怎么保证不丢失数据？</p>
</li>
<li>
<p>13.10 GOPATH 和 GOROOT 有什么区别？</p>
</li>
<li>
<p>13.11 go的逃逸分析有什么用？</p>
</li>
<li>
<p>13.12 线程安全，怎么启动多个goroutine并等待所有goroutine执行完成。</p>
</li>
<li>
<p>13.12.1 怎么加锁？</p>
</li>
<li>
<p>13.12.2 如何顺序输出？</p>
</li>
<li>
<p>13.12.3 goroutine泄露有什么成因？怎么处理？</p>
</li>
<li>
<p>13.12.4 除了mutex外还有哪些方式安全读写共享变量？</p>
</li>
<li>
<p>14 模型分布式训练系统，大数据系统是什么结构？怎么搭建的？知道怎么用开源方式搭建吗？</p>
<p>Hadoop, HBase, MapReduce, Spark</p>
</li>
<li>
<p>14.1 介绍一下Hadoop？</p>
</li>
<li>
<p>14.2 介绍一下HBase，它比PostgreSQL或者MySQL有什么优缺点？</p>
</li>
<li>
<p>14.3 流式处理怎么做的？</p>
</li>
<li>
<p>15 说说分布式事务？</p>
</li>
<li>
<p>15.1 什么是脏读（Dirty Read)、不可重复读（Non-repeatable Read）、幻读（Phantom Read）？怎么解决？</p>
</li>
<li>
<p>15.2 什么CAP？怎么理解？</p>
</li>
<li>
<p>15.3 什么是MVCC？</p>
<p>Multi-Version Concurrency Control<sup class="footnote-ref"><a href="#fn51" id="fnref51">[51]</a></sup>，多版本并发控制，用于在READ COMMITTED和REAPEATABLE READ两个隔离级别下实现读写并发。而READ UNCOMMITTED总是读取最新的数据行，而不是符合当前事务版本的数据行。SERIALIZABLE则会对所有读取的行都加锁。</p>
</li>
<li>
<p>15.4 什么是OLTP和OLAP？</p>
</li>
<li>
<p>15.5 什么是索引？索引有哪些？</p>
</li>
</ul>
<p><strong>算法与模型</strong></p>
<ul>
<li>
<p>1 你们用的哪类算法？效果如何？</p>
</li>
<li>
<p>2 数据怎么清洗的？特征工程怎么做的？</p>
</li>
<li>
<p>3 模型怎么训练的？分布式训练知道怎么做吗？</p>
<ul>
<li>
<p>3.1 知道分布式训练的原理吗？</p>
</li>
<li>
<p>3.2 分布式训练遇到过什么坑吗？</p>
</li>
</ul>
</li>
</ul>
<h2><a href="#recommend-system-amp-recommend-engine" class="header-anchor">#</a><span id="recommend-system-amp-recommend-engine"> Recommend System &amp; Recommend Engine</span></h2>
<p><strong>Domain Specific System</strong></p>
<ul>
<li>
<p>1 描述一下系统有哪些模块，是怎么组织的？</p>
</li>
<li>
<p>2 如何训练并Serve模型的？</p>
</li>
<li>
<p>3 你提到了KubeFlow私有化部署，你们是怎么使用KubeFlow的？</p>
</li>
<li>
<p>4 如何热更新feature和model？</p>
</li>
<li>
<p>5 如何解决online&amp;offline feature的一致性？</p>
</li>
<li>
<p>6 如何排查数据正确性？</p>
</li>
<li>
<p>7 如何排查精度问题？</p>
</li>
<li>
<p>8 如何排查性能问题？</p>
</li>
</ul>
<p><strong>算法与模型</strong></p>
<ul>
<li>
<p>1 特征工程怎么做？</p>
</li>
<li>
<p>2 线下提升线上效果不好为什么，怎么解决？</p>
</li>
</ul>
<h2><a href="#performance-optimization-of-inference" class="header-anchor">#</a><span id="performance-optimization-of-inference"> Performance Optimization of Inference</span></h2>
<p><strong>框架相关</strong></p>
<p><strong>Device相关</strong></p>
<h2><a href="#self-developed-fpga-inference-acceleration-chip-solution" class="header-anchor">#</a><span id="self-developed-fpga-inference-acceleration-chip-solution"> Self-developed FPGA inference acceleration chip solution</span></h2>
<p><strong>芯片相关</strong></p>
<p><strong>软件相关</strong></p>
<h2><a href="#devops" class="header-anchor">#</a><span id="devops"> DevOps</span></h2>
<ul>
<li>
<ol>
<li>如何做CI的？</li>
</ol>
</li>
<li>
<ol start="2">
<li>如何做Test的？</li>
</ol>
</li>
<li>
<ol start="3">
<li>如何做版本发布和回滚的？</li>
</ol>
</li>
<li>
<ol start="4">
<li>怎么搭私网CI环境？</li>
</ol>
</li>
<li>
<ol start="5">
<li>如何提升效率与性能？</li>
</ol>
</li>
</ul>
<h2><a href="#gao-bing-fa" class="header-anchor">#</a><span id="gao-bing-fa"> 高并发</span></h2>
<ul>
<li>1 高并发缓存、限流、降级</li>
</ul>
<h2><a href="#liang-dian-zu-gou-shen-ru-zu-gou-liao-jie" class="header-anchor">#</a><span id="liang-dian-zu-gou-shen-ru-zu-gou-liao-jie"> 亮点，足够深入，足够了解</span></h2>
<p>性能优化、工程化、缓存、http</p>
<hr>
<hr class="footnotes-sep">
<section class="footnotes">
<ol class="footnotes-list">
<li id="fn1" class="footnote-item"><p><a target="_blank" rel="noopener" href="https://kubernetes.io/zh/docs/concepts/workloads/pods/pod-lifecycle/">Pod生命周期</a> <a href="#fnref1" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn2" class="footnote-item"><p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/42056183">分布式锁看这篇就够了</a> <a href="#fnref2" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn3" class="footnote-item"><p><a target="_blank" rel="noopener" href="https://juejin.cn/post/6844903688088059912">再有人问你分布式锁，这篇文章扔给他</a> <a href="#fnref3" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn4" class="footnote-item"><p><a target="_blank" rel="noopener" href="https://www.cnblogs.com/detectiveHLH/p/14713438.html">深入了解Zookeeper核心原理</a> <a href="#fnref4" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn5" class="footnote-item"><p><a target="_blank" rel="noopener" href="https://www.cnblogs.com/detectiveHLH/p/14677914.html">Zookeeper基础原理&amp;应用场景详解</a> <a href="#fnref5" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn6" class="footnote-item"><p><a target="_blank" rel="noopener" href="https://kubernetes.io/zh/docs/tutorials/stateful-application/zookeeper/">K8S部署ZooKeeper</a> <a href="#fnref6" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn7" class="footnote-item"><p><a target="_blank" rel="noopener" href="https://segmentfault.com/a/1190000037518418">Redis Lua脚本完全入门</a> <a href="#fnref7" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn8" class="footnote-item"><p><a target="_blank" rel="noopener" href="https://juejin.cn/post/6936956908007850014">Redis分布式锁</a> <a href="#fnref8" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn9" class="footnote-item"><p><a target="_blank" rel="noopener" href="https://pkg.go.dev/github.com/ainiaa/go-redisson">Redisson</a> <a href="#fnref9" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn10" class="footnote-item"><p><a target="_blank" rel="noopener" href="https://www.zhihu.com/question/266390197">kafka分布式的情况下，如何保证消息的顺序?</a> <a href="#fnref10" class="footnote-backref">↩︎</a> <a href="#fnref10:1" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn11" class="footnote-item"><p><a target="_blank" rel="noopener" href="https://blog.csdn.net/yidan7063/article/details/108234222">kafka 笔记四 kafka消费者 再均衡</a> <a href="#fnref11" class="footnote-backref">↩︎</a> <a href="#fnref11:1" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn12" class="footnote-item"><p><a target="_blank" rel="noopener" href="https://www.tpvlog.com/article/283">透彻理解Kafka（五）——通信机制：多路复用</a> <a href="#fnref12" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn13" class="footnote-item"><p><a target="_blank" rel="noopener" href="http://www.wangqingzheng.com/huaweiyun/15/218415.html">17 个方面，综合对比 Kafka、RabbitMQ、RocketMQ、ActiveMQ</a> <a href="#fnref13" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn14" class="footnote-item"><p><a target="_blank" rel="noopener" href="https://www.cnblogs.com/detectiveHLH/p/14412391.html">消息队列杂谈</a> <a href="#fnref14" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn15" class="footnote-item"><p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/60196818">技术选型：RocketMQ or Kafka</a> <a href="#fnref15" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn16" class="footnote-item"><p><a target="_blank" rel="noopener" href="https://blog.csdn.net/prestigeding/article/details/110408415">Kafka与RocketMQ性能对比大揭秘</a> <a href="#fnref16" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn17" class="footnote-item"><p><a target="_blank" rel="noopener" href="https://blog.csdn.net/shi_hong_fei_hei/article/details/115603204">RocketMQ 架构设计和设计原理</a> <a href="#fnref17" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn18" class="footnote-item"><p><a target="_blank" rel="noopener" href="https://juejin.cn/post/6999572991340183588">Kafka：保证消息不重复不丢失</a> <a href="#fnref18" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn19" class="footnote-item"><p><a target="_blank" rel="noopener" href="https://yangyangmm.cn/2021/10/21/Kafka%E7%9A%84leader%E9%80%89%E4%B8%BE%E6%9C%BA%E5%88%B6/">Kafka的leader选举机制</a> <a href="#fnref19" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn20" class="footnote-item"><p><a target="_blank" rel="noopener" href="https://developer.aliyun.com/article/778789">Hologres产品介绍与技术揭秘</a> <a href="#fnref20" class="footnote-backref">↩︎</a> <a href="#fnref20:1" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn21" class="footnote-item"><p><a target="_blank" rel="noopener" href="https://raft.github.io/">Leader election Simulation</a> <a href="#fnref21" class="footnote-backref">↩︎</a> <a href="#fnref21:1" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn22" class="footnote-item"><p><a target="_blank" rel="noopener" href="https://developer.aliyun.com/article/779284">首次揭秘云原生Hologres存储引擎</a> <a href="#fnref22" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn23" class="footnote-item"><p><a target="_blank" rel="noopener" href="https://juejin.cn/post/6986470315584913415">什么时候使用Redis缓存</a> <a href="#fnref23" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn24" class="footnote-item"><p><a target="_blank" rel="noopener" href="https://blog.csdn.net/you18131371836/article/details/118212987">缓存基础----本地缓存、分布式缓存以及多级缓存</a> <a href="#fnref24" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn25" class="footnote-item"><p><a target="_blank" rel="noopener" href="https://juejin.cn/post/7000263632151904293">Redis与本地缓存组合</a> <a href="#fnref25" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn26" class="footnote-item"><p><a target="_blank" rel="noopener" href="https://blog.csdn.net/a745233700/article/details/113488673">Redis为什么这么快？Redis的线程模型与Redis多线程</a> <a href="#fnref26" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn27" class="footnote-item"><p><a target="_blank" rel="noopener" href="https://www.cnblogs.com/kismetv/p/8654978.html">深入学习Redis（1）：Redis内存模型 </a> <a href="#fnref27" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn28" class="footnote-item"><p><a target="_blank" rel="noopener" href="https://juejin.cn/post/7065960336335044645">Redis 究竟是单线程还是多线程呢？</a> <a href="#fnref28" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn29" class="footnote-item"><p><a target="_blank" rel="noopener" href="https://www.51cto.com/article/616601.html">Redis 6.0 新特性-多线程连环13问！</a> <a href="#fnref29" class="footnote-backref">↩︎</a> <a href="#fnref29:1" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn30" class="footnote-item"><p><a target="_blank" rel="noopener" href="https://segmentfault.com/a/1190000003063859">Linux IO模式及 select、poll、epoll详解</a> <a href="#fnref30" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn31" class="footnote-item"><p><a target="_blank" rel="noopener" href="https://blog.csdn.net/a745233700/article/details/113449889">Redis的五种数据结构的底层实现原理</a> <a href="#fnref31" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn32" class="footnote-item"><p><a target="_blank" rel="noopener" href="https://cloud.tencent.com/developer/article/1846145">拒绝躺平，Redis选择实现了自己的VM</a> <a href="#fnref32" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn33" class="footnote-item"><p><a target="_blank" rel="noopener" href="https://www.cnblogs.com/detectiveHLH/p/14154665.html">深度图解Redis Cluster原理</a> <a href="#fnref33" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn34" class="footnote-item"><p><a target="_blank" rel="noopener" href="https://www.cnblogs.com/kismetv/p/9853040.html">深入学习Redis（5）：集群</a> <a href="#fnref34" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn35" class="footnote-item"><p><a target="_blank" rel="noopener" href="https://segmentfault.com/a/1190000039995230">Redis 高可用篇：Cluster 集群能支持的数据量有多大？</a> <a href="#fnref35" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn36" class="footnote-item"><p><a target="_blank" rel="noopener" href="https://www.51cto.com/article/605020.html">Redis为什么默认16个数据库？</a> <a href="#fnref36" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn37" class="footnote-item"><p><a target="_blank" rel="noopener" href="https://segmentfault.com/a/1190000038671078">谈谈分布式一致性算法—— paxos zab raft gossip</a> <a href="#fnref37" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn38" class="footnote-item"><p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/62947738">Redis哨兵、复制、集群的设计原理与区别</a> <a href="#fnref38" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn39" class="footnote-item"><p><a target="_blank" rel="noopener" href="https://juejin.cn/post/6844903655527677960">一文看懂Redis的持久化原理</a> <a href="#fnref39" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn40" class="footnote-item"><p><a target="_blank" rel="noopener" href="https://www.cnblogs.com/kismetv/p/9609938.html">深入学习Redis（4）：哨兵</a> <a href="#fnref40" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn41" class="footnote-item"><p><a target="_blank" rel="noopener" href="https://www.cnblogs.com/kismetv/p/9236731.html">深入学习Redis（3）：主从复制</a> <a href="#fnref41" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn42" class="footnote-item"><p><a target="_blank" rel="noopener" href="https://huabantang.github.io/2019/05/22/How-to-assign-Partitions-to-new-brokers-after-Kafka-expansion/">Kafka扩容后如何将Partitions分区分配到新brokers节点上?kafka数据倾斜问题如何解决？</a> <a href="#fnref42" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn43" class="footnote-item"><p><a target="_blank" rel="noopener" href="https://www.jianshu.com/p/cdfc3df9e4c6">Kafka partition的数量问题</a> <a href="#fnref43" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn44" class="footnote-item"><p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/54153164">K8S容器编排之Headless浅谈</a> <a href="#fnref44" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn45" class="footnote-item"><p><a target="_blank" rel="noopener" href="https://circleci.com/blog/docker-swarm-vs-kubernetes/">Docker Swarm vs Kubernetes: how to choose a container orchestration tool</a> <a href="#fnref45" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn46" class="footnote-item"><p><a target="_blank" rel="noopener" href="https://go.cyub.vip/gmp/gmp-model.html">GMP模型</a> <a href="#fnref46" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn47" class="footnote-item"><p><a target="_blank" rel="noopener" href="https://learnku.com/articles/41728">Golang 调度器 GMP 原理与调度全分析</a> <a href="#fnref47" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn48" class="footnote-item"><p><a target="_blank" rel="noopener" href="https://www.jianshu.com/p/6c507b966ad1">【译】Linux 线程模型比较：LinuxThreads 和 NPTL</a> <a href="#fnref48" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn49" class="footnote-item"><p><a target="_blank" rel="noopener" href="https://www.linuxidc.com/Linux/2016-01/127559.htm">Linux历史上线程的3种实现模型</a> <a href="#fnref49" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn50" class="footnote-item"><p><a target="_blank" rel="noopener" href="https://www.cyningsun.com/07-07-2018/memory-allocator-contrasts.html">ptmalloc、tcmalloc与jemalloc对比分析</a> <a href="#fnref50" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn51" class="footnote-item"><p><a target="_blank" rel="noopener" href="https://segmentfault.com/a/1190000037557620">MySQL的多版本并发控制(MVCC)是什么？</a> <a href="#fnref51" class="footnote-backref">↩︎</a></p>
</li>
</ol>
</section>
</p></div><div class="share"><span>Share</span>&nbsp;<span class="soc"><a href="javascript:(function(){EN_CLIP_HOST='http://www.evernote.com';try{var%20x=document.createElement('SCRIPT');x.type='text/javascript';x.src=EN_CLIP_HOST+'/public/bookmarkClipper.js?'+(new%20Date().getTime()/100000);document.getElementsByTagName('head')[0].appendChild(x);}catch(e){location.href=EN_CLIP_HOST+'/clip.action?url='+encodeURIComponent(location.href)+'&amp;title='+encodeURIComponent(document.title);}})();" ref="nofollow" target="_blank" class="fa fa-bookmark"></a></span><span class="soc"><a href="javascript:void((function(s,d,e){try{}catch(e){}var f='http://service.weibo.com/share/share.php?',u=d.location.href,p=['url=',e(u),'&amp;title=',e(d.title),'&amp;appkey=2924220432'].join('');function a(){if(!window.open([f,p].join(''),'mb',['toolbar=0,status=0,resizable=1,width=620,height=450,left=',(s.width-620)/2,',top=',(s.height-450)/2].join('')))u.href=[f,p].join('');};if(/Firefox/.test(navigator.userAgent)){setTimeout(a,0)}else{a()}})(screen,document,encodeURIComponent));" class="fa fa-weibo"></a></span><span class="soc"><a target="_blank" rel="noopener" href="http://twitter.com/home?status=https://blog.kleon.space/interview/resume/%20KLEON%20Common - Resume" class="fa fa-twitter"></a></span></div><div class="pagination"><p class="clearfix"><span class="pre pagbuttons"><a role="navigation" href="/interview/tech/kubernetes/" title="Tech - Kubernetes"><i class="fa fa-angle-double-left"></i>&nbsp;Previous post: Tech - Kubernetes</a></span><span>&nbsp;</span><span class="next pagbuttons"><a role="navigation" href="/interview/aboard/" title="Common - Aboard">Next post: Common - Aboard&nbsp;<i class="fa fa-angle-double-right"></i></a></span></p></div></div></div></div><div class="visible-xs site-bottom-footer"><footer><p>&copy;&nbsp;2022&nbsp;<a target="_blank" href="https://blog.kleon.space" rel="noopener noreferrer">Kleon</a></p><p>Theme&nbsp;<a target="_blank" href="https://github.com/SumiMakito/hexo-theme-typography" rel="noopener noreferrer">Typography</a>&nbsp;by&nbsp;<a target="_blank" href="https://www.keep.moe" rel="noopener noreferrer">Makito</a></p><p>Proudly published with&nbsp;<a target="_blank" href="https://hexo.io" rel="noopener noreferrer">Hexo</a></p></footer></div></div></div></div><script src="/js/jquery-3.1.0.min.js"></script><script src="/js/bootstrap.min.js"></script><script src="/js/jquery-migrate-1.2.1.min.js"></script><script src="/js/jquery.appear.js"></script><script src="/js/google-analytics.js"></script><script src="/js/typography.js"></script></body></html>