<!DOCTYPE html><html lang="zh-CN"><head><meta charset="utf-8"><meta name="X-UA-Compatible" content="IE=edge"><meta name="author"><title>Common - Resume · KLEON</title><meta name="description" content="Resumes.



Outline
Backend Developer Engineer

Experience
Skills


Machine Learning Engineer
Full Stack Engineer
后端开发工程师

工作经历
Q&amp;amp;A

Video Enhance"><meta name="og:description" content="Resumes.



Outline
Backend Developer Engineer

Experience
Skills


Machine Learning Engineer
Full Stack Engineer
后端开发工程师

工作经历
Q&amp;amp;A

Video Enhance"><meta name="twitter:site" content="KLEON"><meta name="twitter:title" content="Common - Resume"><meta name="twitter:card" content="summary"><meta name="keywords" content=""><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="renderer" content="webkit"><link rel="short icon" href="images/favicon.png" type="image/x-icon"><link rel="stylesheet" href="/css/github.min.css"><link rel="stylesheet" href="/css/bootstrap.min.css"><link rel="stylesheet" href="/css/font-awesome.min.css"><link rel="stylesheet" href="https://lf9-cdn-tos.bytecdntp.com/cdn/expire-1-M/KaTeX/0.10.2/katex.min.css"><link rel="stylesheet" href="/css/style.css"><link rel="alternate" type="application/atom+xml" title="ATOM 1.0" href="/atom.xml"><meta name="generator" content="Hexo 6.1.0"></head><body><div id="stage" class="container"><div class="row"><div id="side-bar" class="col-sm-3 col-xs-12 side-container invisible"><div class="vertical-text site-title"><h3 tabindex="-1" class="site-title-small"><a href="/" class="a-title"></a></h3><h1 tabindex="-1" class="site-title-large"><a href="/" class="a-title">吹拉弹唱</a></h1><!--h6(onclick="triggerSiteNav()") Trigger--></div><br class="visible-lg visible-md visible-sm"><div id="site-nav" class="site-title-links"><ul><li><a href="/">Home</a></li><li><a href="/archives">Archive</a></li><li><a href="/categories">Categories</a></li><li><a href="/tags">Tags</a></li><li><a href="/googlebe23cb0bc55fc412.html"></a></li><li><a href="/about/index.html"></a></li><li class="soc"><a href="https://github.com/kleon1024" target="_blank" rel="noopener noreferrer" aria-label="Github"><i class="fa fa-github">&nbsp;</i></a></li></ul><div class="visible-lg visible-md visible-sm site-nav-footer"><br class="site-nav-footer-br"><footer><p>&copy;&nbsp;2022&nbsp;<a target="_blank" href="https://blog.kleon.space" rel="noopener noreferrer">Kleon</a></p><p>Theme&nbsp;<a target="_blank" href="https://github.com/SumiMakito/hexo-theme-typography" rel="noopener noreferrer">Typography</a>&nbsp;by&nbsp;<a target="_blank" href="https://www.keep.moe" rel="noopener noreferrer">Makito</a></p><p>Proudly published with&nbsp;<a target="_blank" href="https://hexo.io" rel="noopener noreferrer">Hexo</a></p></footer></div></div></div><div id="main-container" class="col-sm-9 col-xs-12 main-container invisible"><div class="autopagerize_page_element"><div class="content"><div class="post-page"><div class="post-container"><p class="post-title"><a>Common - Resume</a></p><p class="post-meta"><span class="date meta-item">Posted at&nbsp;2022-04-20</span><span class="date meta-item">Updated at&nbsp;2022-05-14</span><span class="meta-item"><i class="fa fa-folder"></i><span>&nbsp;</span><a href="/categories/interview/" title="interview" class="a-tag">interview</a><span>&nbsp;</span></span><span class="meta-item"><i class="fa fa-tag"></i><span>&nbsp;</span><a href="/tags/interview/" title="interview" class="a-tag">interview</a><span>&nbsp;</span><a href="/tags/resume/" title="resume" class="a-tag">resume</a><span>&nbsp;</span></span></p><p class="post-abstract"><p>Resumes.</p>
<div class="toc">
<!-- toc -->
<ul>
<li><a href="#outline">Outline</a></li>
<li><a href="#backend-developer-engineer">Backend Developer Engineer</a>
<ul>
<li><a href="#experience">Experience</a></li>
<li><a href="#skills">Skills</a></li>
</ul>
</li>
<li><a href="#machine-learning-engineer">Machine Learning Engineer</a></li>
<li><a href="#full-stack-engineer">Full Stack Engineer</a></li>
<li><a href="#hou-duan-kai-fa-gong-cheng-shi">后端开发工程师</a>
<ul>
<li><a href="#gong-zuo-jing-li">工作经历</a></li>
<li><a href="#q-a">Q&amp;A</a>
<ul>
<li><a href="#video-enhancement">Video Enhancement</a></li>
<li><a href="#intelligent-marketing-platform">Intelligent Marketing Platform</a></li>
<li><a href="#recommend-engine">Recommend Engine</a></li>
<li><a href="#shen-du-mo-xing-tui-li-xing-neng-you-hua">深度模型推理性能优化</a></li>
<li><a href="#zi-yan-fpga-tui-li-jia-su-xin-pian-fang-an">自研FPGA推理加速芯片方案</a></li>
</ul>
</li>
</ul>
</li>
</ul>
<!-- tocstop -->
</div>
<h1><a href="#outline" class="header-anchor">#</a><span id="outline"> Outline</span></h1>
<ol>
<li>Business background</li>
<li>Solution</li>
<li>Implementation</li>
<li>Result (explained with data)</li>
<li>Problem/Bad case</li>
<li>Optimization</li>
</ol>
<h1><a href="#backend-developer-engineer" class="header-anchor">#</a><span id="backend-developer-engineer"> Backend Developer Engineer</span></h1>
<p>Mainly focus on the backend system design, middleware (MySQL/Postgres, Redis, Kafka, MongoDB) and golang.</p>
<h2><a href="#experience" class="header-anchor">#</a><span id="experience"> Experience</span></h2>
<p><strong>Senior Software Engineer</strong>, (August 2020 - present)<br>
Backend architecture and developer for AI application and SaaS, including recommendation engine, marketing platform with SMS ability. Integrated into Ali Cloud’s finance system.</p>
<ul>
<li>A general recommendation engine platform for traditional company like short videos, game distribution, e-commerce company.</li>
<li>A platform for marketing campaign integrated with algorithms predicting user behaviors and sms functionality.</li>
<li>A platform for video processing with the ability of AI enhancement. How many, how large, what kind of algorithm, performance, optimization?</li>
</ul>
<p><strong>Software Engineer</strong>, (July 2018 - July 2020)<br>
Developer on hardware, framework and inference optimization.</p>
<ul>
<li>Participated in the development of hardware accelerator of deep learning model. Designed and developed the hardware logic in Verilog, the universal runtime adapting different hardware arch and model in C++, integrated into Tensorflow and more.</li>
<li>Performance optimization with tools of TVM, TensorRT, Intel OneDNN and anything else.</li>
<li>Participated in the development of platform for AI infrastructure, including notebook, training platform, serverless inference platform.</li>
</ul>
<h2><a href="#skills" class="header-anchor">#</a><span id="skills"> Skills</span></h2>
<ul>
<li>Programming language of Golang, Python, C++, dart, javascript.</li>
<li>Knowledge of AI application, including recommendation engine, video enhancement.</li>
</ul>
<h1><a href="#machine-learning-engineer" class="header-anchor">#</a><span id="machine-learning-engineer"> Machine Learning Engineer</span></h1>
<p>Mainly focus on the framework (Tensorflow/PyTorch), specific algorithms and business applications.</p>
<h1><a href="#full-stack-engineer" class="header-anchor">#</a><span id="full-stack-engineer"> Full Stack Engineer</span></h1>
<p>Mainly focus on the frontend (Vue/Flutter), backend and devops(k8s/docker/aws)</p>
<h1><a href="#hou-duan-kai-fa-gong-cheng-shi" class="header-anchor">#</a><span id="hou-duan-kai-fa-gong-cheng-shi"> 后端开发工程师</span></h1>
<h2><a href="#gong-zuo-jing-li" class="header-anchor">#</a><span id="gong-zuo-jing-li"> 工作经历</span></h2>
<p><strong>高级开发工程师</strong> 2020-present</p>
<blockquote>
<p>AI Model/Go/Devops</p>
</blockquote>
<ul>
<li><strong>云端视频增强</strong>。技术责任人。负责设计实现云端视频增强服务，效果指标与友商基本持平，单位视频时间转换成本较友商公开数据低50%以上，在中小型电商与短视频平台尝试落地。模型效果层面，基于主流SISR模型，通过扩充训练集加入人像、字符、纹理等数据、业务场景数据fine-tune、调整模型结构、使用多种退化与增强做数据预处理等方法，模型可快速适配不同业务场景下的主观评分，平衡高频细节保留与降噪能力，同时避免了常见的伪影纹波等效应；模型性能层面，通过精简模型结构、量化与序列化等方法大幅提升推理性能，同时维持主观效果基本持平；服务层面使用Go提供API与任务状态同步、回调等服务，Python运行模型增强与编码服务，Kafka作为任务队列，通过Kubernetes集群弹性调度同时支持数百任务同时运行。</li>
</ul>
<blockquote>
<p>想想细节，分布式任务调度，遇到的问题和解决方案，分布式任务是job还是service。如果job怎么避免pull image的overhead，image cache是什么原理，GPU机器在image pulling时浪费的资源怎么算？如果是service，怎么解决分布式读数据库锁问题？有使用任务队列吗？Celery利弊？Kafka利弊？模型和编码怎么balance的？原始视频体积过大带宽受得了吗？用什么分布式存储？你觉得minio合适吗？pod之间共享怎么做？看过ffmpeg代码吗？</p>
</blockquote>
<ul>
<li><strong>营销增长平台</strong>。设计实现短信相关的内容注册与发送服务，管理营销相关的召回打分算法任务，与阿里云南天门产品和计量计费接口对接。短信服务基于Hologres(列存)与Kafka支持上万QPS短信输入，可支持每日千万级短信发送，通过分区表减小数据查询压力，通过拆分微服务配合k8s弹性扩缩容，包括API，短信发送，失败短信重发，发送统计，短信回执校验，定时分区，客户回执back-off推送，实时计费计量，定时短信服务，算法任务管理，监控服务等。算法层面支持通用数据传输协议，基于客户提供的数据质量，转化率有1-10%等不同程度的提升。</li>
</ul>
<blockquote>
<p>所以业务是发营销短信？通过算法节约成本或提高转化率。了解分布式任务系统吗？Kafka怎么用的？基本指标？为什么这么快？Hologres和HBase有什么区别？为什么不用MySQL，为什么不用MongoDB，为什么不用Redis。有流控吗？这么大QPS 数据库latency在多少？怎么优化的？开发过程中有遇到什么瓶颈吗？Kafka出错怎么处理？用的什么算法？怎么做通用化？有具体场景数据吗？k8s了解吗？怎么提供的服务？ingress是什么？有用过deployment吗？StatefulSet干什么的？k8s的基本模块了解吗？k8s遇到过性能问题吗？知道operator吗？写过吗？CRD写过吗？知道k8s底层资源限制是什么原理吗？</p>
</blockquote>
<ul>
<li><strong>推荐引擎</strong>。在跨境电商、短视频、游戏分发平台落地，业务指标提升满足客户需求。设计实现引擎架构，基于Golang实现，支持多数据源，支持召回(i2i,u2i,cf,离线)，打分，排序（精排，粗排，重排，加权），支持分页和已读过滤，支持离在线模型，支持客户端/服务端实时/近实时特征拼接(item/user/context)等功能，通用化+模块化的设计使得快速迁移到不同项目。</li>
</ul>
<blockquote>
<p>业务里用过什么模型？取得的效果如何？怎么通用化？怎么模块化？有遇到什么瓶颈吗？算法正确性怎么debug的？模块支持debug tracing，怎么实现的？有做什么性能优化吗？go的channel死锁知道吗？go为什么快？你们整个推荐端到端延迟是多少？模型怎么服务的？TensorFlow/PyTorch？模型怎么优化的？推荐类模型怎么优化的？模型训练知道吗？你们的Embedding怎么优化？有预热吗？有Cache吗？有Redis Cache吗？有Prefetch吗？模型怎么动态更新的？服务切流怎么不影响？服务版本和模型版本怎么适配的？有做Feature Store吗？离线特征怎么算的？在线特征是指什么？怎么拼接处理的？实时特征拼接指什么？怎么做的？Go有什么性能优化技巧吗？如果panic了怎么debug吗？数据库connection泄露了怎么查？sql相关有什么坑吗？怎么处理慢SQL？</p>
</blockquote>
<p><strong>开发工程师</strong> 2018-2020</p>
<blockquote>
<p>C++/Python/Tensorflow/PyTorch/TensorRT/Verilog</p>
</blockquote>
<ul>
<li>
<p><strong>推理优化</strong>。基于社区与厂商方案的集成推理优化工具。主要针对Intel CPU与NVidia GPU，使用如MKL-DNN，OpenVINO，TensorRT，TVM，ONNX Runtime等，从图层面、算子层面与系统层面进行优化，硬件不变的条件下加速比在2-5倍左右，模型服务端到端RT下降20%-80%。</p>
</li>
<li>
<p><strong>硬件加速</strong>。利用FPGA加速深度学习模型，支持CV，TTS，推荐类型模型，为芯片架构预研。负责编写硬件逻辑，软件通用化runtime与compiler, 以及接入Tensorflow，通过EAS平台(k8s model serving)/容器化/定制板卡等形式输出，模型加速效果数十倍到数百倍。</p>
</li>
</ul>
<h2><a href="#q-amp-a" class="header-anchor">#</a><span id="q-amp-a"> Q&amp;A</span></h2>
<h3><a href="#video-enhancement" class="header-anchor">#</a><span id="video-enhancement"> Video Enhancement</span></h3>
<p><strong>分布式任务系统</strong></p>
<ul>
<li>
<p>1 分布式任务是怎么实现的？基于 Job 还是 Service？</p>
<p>使用k8s的job和service来实现，自动调度和资源分配。</p>
</li>
<li>
<p>1.1 如果基于Job，怎么怎么避免image pull的overhead？</p>
<p>有两点，一个我们是基于ECI和ECS开发的，ECI是Elastic Container Image，负责弹性，ECS负责固定，ECI提供了ImageCache功能避免Image Pull。另一点是我们提前预热拉取image，随后就不需要了。</p>
</li>
<li>
<p>1.1.1 ImageCache的原理是什么？</p>
<p>一般情况下，k8s的node是VM，也就对应一个VM image，而eci维持了一个VM的pool，可以直接分配给第三方集群，同时提前制作一个ImageCache就相当于提前打包了一个包含目标docker image的VM image，启动pod时，eci会通过docker image的特征值查找对应的VM image，如果找到了就直接用对应的VM image，如此ECI就会assign pod到使用对应VM image的VM Node上，避免了每次的docker image重复拉取。基本上ImageCache可以做到30s内的启动。相对于ECS的弹性和docker image需要数分钟时间的启动过程，已经比较快了。</p>
</li>
<li>
<p>1.2 GPU在Pulling的时候占用Node吗？</p>
<p>问题在问Pod的生命周期<sup class="footnote-ref"><a href="#fn1" id="fnref1">[1]</a></sup>，容器Pulling的时候，Pod已经Scheduled了，Pod处于Pending状态。Pod处于Succeeded或Failed状态时释放资源。</p>
</li>
</ul>
<hr>
<ul>
<li>
<p>⚠️2 怎么处理任务状态同步问题？</p>
<p>任务直连数据库。</p>
</li>
<li>
<p>2.1 数据库连接数满了怎么办？你这个方案最多能支持多少任务并行？如果连接数满了，状态会不会丢，会不会卡任务？</p>
<p>扩容数据库？取决于连接数，会存在你说的情况。</p>
</li>
<li>
<p>2.1.1 可以优化一下吗？</p>
<p>使用状态写入服务批量写入，任务retry，可以扩容。但是实际还是出现了状态同步丢失的情况。<br>
或许可以状态写入服务可以加一个消息队列缓冲一下，from 3。</p>
</li>
<li>
<p>2</p>
</li>
</ul>
<hr>
<ul>
<li>
<p>⚠️3 如果是Service怎么实现的？</p>
<p>每个Service从数据库读取任务并且同步状态。</p>
</li>
<li>
<p>3.1 服务之间会重复读取吗？</p>
<p>有可能，需要加个分布式锁。</p>
</li>
<li>
<p>⚠️3.1.1 怎么加分布式锁？</p>
<p>参考<sup class="footnote-ref"><a href="#fn2" id="fnref2">[2]</a></sup><sup class="footnote-ref"><a href="#fn3" id="fnref3">[3]</a></sup></p>
<ol>
<li>ZooKeeper</li>
<li>Redis</li>
</ol>
</li>
<li>
<p>⚠️3.1.2 ZooKeeper知道吗？介绍一下？ZooKeeper是Kafka的基本组件。</p>
</li>
<li>
<p>3</p>
<p>每个服务从任务队列里读任务，并且将状态写回消息队列。</p>
</li>
<li>
<p>3.1 用的什么消息队列？为什么用消息队列？</p>
<p>Kafka。</p>
<ol>
<li>Asynchronous</li>
<li>Peak Clipping</li>
<li>Decoupling</li>
</ol>
</li>
<li>
<p>3.1.1 会重复读吗？怎么做到不重复读？</p>
<p>不会，把所有服务设置为同一个Comsumer Group。</p>
</li>
<li>
<p>3.1.1.1 Consumer Group是怎么实现不重复读的？</p>
<p>这要说道Consumer的Rebalance机制，对于Consumer Group中的每个Consumer，服务端尽量做到每个Consumer分配不同的Partition，如果P的数量&gt;C，那一个C就可能获取多个P，反之，会有C空闲。</p>
</li>
<li>
<p>3.1.2 消息队列支持有连接数限制吗？会影响同时并行的服务数量吗？</p>
<p>通常建议每个broker不超过1k个客户端，因为每个客户端与broker都需要建立socket连接。当连接数过多时会消耗过多资源在Socket处理上。</p>
</li>
<li>
<p>3.1.3 Kafka的结构和运行原理知道吗？</p>
<p>基础的节点单位是Broker，每个Topic为一个队列，每个Topic会分为多个Partition，一个Partition有至少三个副本分布在不同Broker上，其中一个是Leader，其他两个是Follower，Leader负责处理对Partition的操作，Follower同步复制操作。ZooKeeper负责处理分布式节点监控与恢复以及Leader失效后重新选出新Leader。对于客户端，Producer负责写入数据，并且尽可能均匀的写入Partition，如果Key不null，根据Key的Hash值计算分区号，如果Key null，则轮询写入。Consumer负责读取数据，通过Rebalance获取自己在Consumer Group中可以读取的Partition序号，顺序读取数据。</p>
</li>
<li>
<p>3.1.4 Kafka保序吗？如何保序？</p>
<p>参考<sup class="footnote-ref"><a href="#fn4" id="fnref4">[4]</a></sup>。Kafka分布式的单位是Partition，同一个Partition可以保证FIFO，不同Partition之间不能保证顺序。但是可以通过message key来保序，同一个key只会发送到同一个partition，能保证同一个key的message是保序的。同时如果需要所有信息严格保序，只设置一个partition即可。</p>
</li>
<li>
<p>3.1.4.1 如果Key Skew了怎么办？</p>
<p>区分原因，如果Key分布相对均匀，可以换Hash函数，如果Key分布不均匀，考虑去掉Key，或者重新选择Key，比如uid换成order id之类的。</p>
</li>
<li>
<p>⚠️3.1.4.1.1 Kafka常用的Hash函数有哪些？</p>
<ol>
<li>murmur2 % P</li>
</ol>
</li>
<li>
<p>3.1.5 Rebalance是什么？讲讲具体过程？如何避免Rebalance？</p>
<p>参考<sup class="footnote-ref"><a href="#fn4" id="fnref4:1">[4:1]</a></sup><sup class="footnote-ref"><a href="#fn5" id="fnref5">[5]</a></sup>。<br>
Rebalance发生在以下情况，需要避免:</p>
<ol>
<li>Consumer加入或退出或无心跳之后</li>
<li>在Partition数量变更之后</li>
<li>订阅主题数变更。在使用正则匹配Topic时新增了Topic订阅Topic数量发生改变之后。</li>
</ol>
</li>
<li>
<p>⚠️3.1.5.1 Rebalance策略有哪些？各自的优缺点是什么？</p>
<p>Range RoundRobin Sticky<sup class="footnote-ref"><a href="#fn5" id="fnref5:1">[5:1]</a></sup></p>
</li>
<li>
<p>3.1.6 Kafka怎么实现超高并发/吞吐的？为什么这么快？</p>
<ol>
<li>分区数据并行处理。</li>
<li>Partition顺序写入磁盘。</li>
<li>利用PageCache批量写入磁盘。</li>
<li>零拷贝技术。</li>
<li>批量发送读取。</li>
<li>数据压缩节省磁盘网络延迟。</li>
<li>reactor模式，I/O多路复用<sup class="footnote-ref"><a href="#fn6" id="fnref6">[6]</a></sup>。</li>
</ol>
</li>
<li>
<p>⚠️3.1.7 知道其他消息队列吗？为什么不用？</p>
<p>参考<sup class="footnote-ref"><a href="#fn7" id="fnref7">[7]</a></sup><sup class="footnote-ref"><a href="#fn8" id="fnref8">[8]</a></sup>。</p>
<p>RabbitMQ，RocketMQ。</p>
</li>
<li>
<p>3.1.7.1 RocketMQ有什么优势？</p>
</li>
<li>
<p>3.1.8 如何保证幂等性？也就是不重复消费？</p>
</li>
<li>
<p>3.1.9 如果MQ挂了怎么办？整个系统就挂了吗？</p>
</li>
<li>
<p>3.1.10 怎么保证Kafka消息不丢失？</p>
<p>配置ack=always</p>
<p>参考<sup class="footnote-ref"><a href="#fn9" id="fnref9">[9]</a></sup></p>
</li>
<li>
<p>⚠️3.2 如何区分优先级？</p>
</li>
<li>
<p>⚠️3.3 如何区分不同用户？每个用户应该有自己的任务队列，否则一个用户可能会耗尽资源。</p>
</li>
<li>
<p>3.4 如果临时终止任务怎么处理？</p>
<p>使用KILL TASK队列，每个Service 作为单独的Consumer读取，如果TASK ID和当前正在处理的任务一致则终止任务，并发送任务状态。</p>
</li>
<li>
<p>3.5 如何处理失败任务？</p>
<p>加异常处理，因各种原因失败的任务发送任务状态，以及失败原因。</p>
</li>
<li>
<p>3.6 如何处理节点突然失效？</p>
<p>如果是Node失效或Pod Crash，k8s的重启机制会保证Service重启，重新订阅Topic。如果是Pod本身卡死，则需要发送心跳包，维护一个在线Service列表，一旦心跳包超时则需要重启Service。Task心跳包超时后需重新下发Task。</p>
</li>
<li>
<p>3.7 怎么添加监控的？监控了什么指标？如何Alert？</p>
<p>监控Service状态，当前各状态的Task数量分布，输入输出视频的平均码率。</p>
</li>
<li>
<p>⚠️3.8 为什么不用成熟的任务调度框架？</p>
</li>
<li>
<p>3.9 怎么更新服务和模型的？</p>
</li>
<li>
<p>3.10 可以给不同用户使用不同模型吗？</p>
</li>
<li>
<p>4 视频的处理过程是怎样的？能详细说说吗？</p>
<p>视频处理分两阶段，先做模型处理，再做编码压缩。模型处理服务初始化或者更新的时候首先加载模型，使用OpenCV读取视频，并根据视频尺寸Batch化，根据GPU Memory大小，每种尺寸对应不同的Batch Size，防止OOM。处理好的视频OpenCV以无损格式写出。处理完成后的视频传输至Object Storage，我们搭建了一个VPC内的minio作为视频交换媒介。编码服务拉取视频并根据配置编码，回传至公网Object Storage，并回调通知用户服务。</p>
</li>
<li>
<p>4.1 无损格式写出的中间视频体积很大，会消耗存储和传输资源，这部分可以怎么避免吗？Minio没有出现过带宽瓶颈吗？</p>
</li>
</ul>
<p><strong>算法与模型</strong></p>
<ul>
<li>
<p>1 模型基本结构是什么？效果如何？有什么评价指标吗？</p>
</li>
<li>
<p>2 主流的超分或者视频增强模型有哪些？结构上有什么不同？可以用Transformer吗？</p>
</li>
<li>
<p>3 用什么方法避免ringing effect和artifact伪影呢？</p>
</li>
<li>
<p>4 用的什么Loss？</p>
</li>
<li>
<p>5 为什么要用GAN？用了有什么效果？</p>
</li>
<li>
<p>6 用了什么退化？</p>
</li>
<li>
<p>7 怎么训练的？分布式？为什么不用集群？</p>
</li>
</ul>
<p><strong>视频编码</strong></p>
<ul>
<li>
<p>1 ffmpeg编码质量怎么配置的？有改过代码吗？</p>
</li>
<li>
<p>2 用的什么编码？H264还是H265。</p>
</li>
<li>
<p>3 编码时间比是多少？怎么加速？</p>
</li>
</ul>
<h3><a href="#intelligent-marketing-platform" class="header-anchor">#</a><span id="intelligent-marketing-platform"> Intelligent Marketing Platform</span></h3>
<p><strong>高吞吐微服务系统</strong></p>
<ul>
<li>
<p>1 怎么支撑这么高的并发的？</p>
<p>通过5点：</p>
<ol>
<li>API-Server是无状态Deployment服务，可以扩容并行处理输入。</li>
<li>发送短信时需要阿里云鉴权，验证签名和模板的有效性，我们使用了阿里云本地的鉴权客户端，并且加了签名模板等资源的本地缓存，保证基本不读取数据库。</li>
<li>在API侧写数据库压力很大，并且因为API限制了每次请求batch数量，写入数据库的query碎片化，所以直接写入Kafka，等到发送完成后再写入数据库。这样就避免了同一条短信数据的两次数据库写入操作，节省了数据库带宽。</li>
<li>一开始是以短信为单位写入Kafka，发现写入和读取的速度相对比较慢，后面优化为以用户请求batch为单位为Kafka的一条信息，读写的速度有了明显提高，不再是瓶颈。</li>
<li>多协程操作，大batch化操作数据库，利用GoRoutine处理数据，放入写数据库channel中积累到一定数据或达到超时阈值后统一写回数据库。大Batch相比多次小Batch延迟明显降低。</li>
</ol>
</li>
<li>
<p>2 有做流控吗？怎么做的？</p>
<p>有做，分别在网关层，API输入层，短信发送层做了流控。</p>
<ul>
<li>网关层是阿里云提供的系统级流控，包括产品级与API级访问控制。</li>
<li>API输入层可配置策略限制单用户或单IP的QPS，防止挤占其他用户。</li>
<li>短信发送层配置短信发送速率，这是因为下游服务提供商没有提供有效的队列，当发送速率过高时短信的发送失败率过高。</li>
</ul>
<p>流控方法基本上就是滑动窗口法。</p>
</li>
<li>
<p>3 数据库有遇到瓶颈吗？Latency平均在多少？为什么不用MySQL/MongoDB/HBase之类的？</p>
</li>
<li>
<p>4 介绍一下Hologres的原理？</p>
<p>参考<sup class="footnote-ref"><a href="#fn10" id="fnref10">[10]</a></sup>。</p>
</li>
<li>
<p>5 本地缓存怎么做的？</p>
<p>go的Cache包，设置过期时间，使用LFU淘汰策略。</p>
</li>
<li>
<p>5.1 会有数据一致性问题吗？</p>
<p>不会，没有强一致性要求，因为需要缓存的对象设计的时候避免了Update操作，User表在用户首次开通产品时就已经确定无法更改。Signature表与Template表同样。在前端加入了从已有新建的快捷操作。</p>
</li>
<li>
<p>5.2 为什么不用Redis？</p>
<p>需要缓存的规模比较小，而且没有很强的一致性要求，所以就用了Local Cache。像用户Session信息都是由阿里云的网关服务负责的，我们产品的服务收到的请求头部里有用户相关的各类信息，比如用户主账号id，子账号id，以及一系列其他的鉴权相关的信息。<br>
问题其实在问什么时候应该用Redis，参考<sup class="footnote-ref"><a href="#fn10" id="fnref10:1">[10:1]</a></sup>，同时也是在问用Local Cache的局限性，参考<sup class="footnote-ref"><a href="#fn11" id="fnref11">[11]</a></sup>，同时也是在问能否结合Redis与本地缓存<sup class="footnote-ref"><a href="#fn12" id="fnref12">[12]</a></sup>。</p>
</li>
<li>
<p>5.3 Redis为什么快？</p>
<ol>
<li>in-memory 内存不需要访问磁盘。</li>
<li>single thread处理，减小多线程竞争的context switching开销，避免加锁开销以及死锁的情况。</li>
<li>IO 多路复用，处理并发连接。</li>
<li>数据结构简单，操作也简单，提升性能。</li>
<li>使用底层模型不同，它们之间底层实现方式以及与客户端之间通信的应用协议不一样，Redis 直接自己构建了 VM 机制 ，因为一般的系统调用系统函数的话，会浪费一定的时间去移动和请求。</li>
</ol>
<p>参考<sup class="footnote-ref"><a href="#fn13" id="fnref13">[13]</a></sup>。</p>
</li>
<li>
<p>5.3.1 说一下Redis的内存模型？</p>
<p><sup class="footnote-ref"><a href="#fn14" id="fnref14">[14]</a></sup></p>
</li>
<li>
<p>5.3.2 Redis是单线程的吗？</p>
<p>参考<sup class="footnote-ref"><a href="#fn15" id="fnref15">[15]</a></sup>。Redis在处理客户端的请求时，包括获取 (socket 读)、解析、执行、内容返回 (socket 写) 等都由一个顺序串行的主线程处理，这就是所谓的“单线程”。但如果严格来讲从Redis4.0之后并不是单线程，除了主线程外，它也有后台线程在处理一些较为缓慢的操作，例如清理脏数据、无用连接的释放、大 key 的删除等等。</p>
</li>
<li>
<p>5.3.2.1 为什么Redis不用多线程？</p>
<p>参考<sup class="footnote-ref"><a href="#fn16" id="fnref16">[16]</a></sup>。</p>
<p>官方曾做过类似问题的回复：使用Redis时，几乎不存在CPU成为瓶颈的情况， Redis主要受限于内存和网络。例如在一个普通的Linux系统上，Redis通过使用pipelining每秒可以处理100万个请求，所以如果应用程序主要使用O(N)或O(log(N))的命令，它几乎不会占用太多CPU。</p>
<p>使用了单线程后，可维护性高。多线程模型虽然在某些方面表现优异，但是它却引入了程序执行顺序的不确定性，带来了并发读写的一系列问题，增加了系统复杂度、同时可能存在线程切换、甚至加锁解锁、死锁造成的性能损耗。Redis通过AE事件模型以及IO多路复用等技术，处理性能非常高，因此没有必要使用多线程。单线程机制使得 Redis 内部实现的复杂度大大降低，Hash 的惰性 Rehash、Lpush 等等 “线程不安全” 的命令都可以无锁进行。</p>
</li>
<li>
<p>5.3.2.2 知道Redis 6.0之后多线程化了吗？为什么要引入多线程？</p>
<p>参考<sup class="footnote-ref"><a href="#fn16" id="fnref16:1">[16:1]</a></sup>。</p>
<p>Redis将所有数据放在内存中，内存的响应时长大约为100纳秒，对于小数据包，Redis服务器可以处理80,000到100,000 QPS，这也是Redis处理的极限了，对于80%的公司来说，单线程的Redis已经足够使用了。</p>
<p>但随着越来越复杂的业务场景，有些公司动不动就上亿的交易量，因此需要更大的QPS。常见的解决方案是在分布式架构中对数据进行分区并采用多个服务器，但该方案有非常大的缺点，例如要管理的Redis服务器太多，维护代价大；某些适用于单个Redis服务器的命令不适用于数据分区；数据分区无法解决热点读/写问题；数据偏斜，重新分配和放大/缩小变得更加复杂等等。</p>
<p>从Redis自身角度来说，因为读写网络的read/write系统调用占用了Redis执行期间大部分CPU时间，瓶颈主要在于网络的 IO 消耗, 优化主要有两个方向:</p>
<ul>
<li>提高网络 IO 性能，典型的实现比如使用 DPDK 来替代内核网络栈的方式</li>
<li>使用多线程充分利用多核，典型的实现比如 Memcached。</li>
</ul>
<p>协议栈优化的这种方式跟 Redis 关系不大，支持多线程是一种最有效最便捷的操作方式。所以总结起来，redis支持多线程主要就是两个原因：</p>
<ul>
<li>可以充分利用服务器 CPU 资源，目前主线程只能利用一个核</li>
<li>多线程任务可以分摊 Redis 同步 IO 读写负荷</li>
</ul>
</li>
<li>
<p>5.3.2.3 知道怎么配置6.0的多线程吗？</p>
<p>Redis6.0的多线程默认是禁用的，只使用主线程。如需开启需要修改redis.conf配置文件：io-threads-do-reads yes<br>
开启多线程后，还需要设置线程数，否则是不生效的。同样修改redis.conf配置文件。关于线程数的设置，官方有一个建议：4核的机器建议设置为2或3个线程，8核的建议设置为6个线程，线程数一定要小于机器核数。还需要注意的是，线程数并不是越大越好，官方认为超过了8个基本就没什么意义了。</p>
</li>
<li>
<p>5.3.2.4 开启多线程之后的性能如何？</p>
<p>Redis 作者 antirez 在 RedisConf 2019分享时曾提到：Redis 6 引入的多线程 IO 特性对性能提升至少是一倍以上。国内也有大牛曾使用unstable版本在阿里云esc进行过测试，GET/SET 命令在4线程 IO时性能相比单线程是几乎是翻倍了。<br>
说明1：这些性能验证的测试并没有针对严谨的延时控制和不同并发的场景进行压测。数据仅供验证参考而不能作为线上指标。<br>
说明2：如果开启多线程，至少要4核的机器，且Redis实例已经占用相当大的CPU耗时的时候才建议采用，否则使用多线程没有意义。所以估计80%的公司开发人员看看就好。</p>
</li>
<li>
<p>5.3.2.5 多线程的实现机制？</p>
<p>流程简述如下：</p>
<ol>
<li>主线程负责接收建立连接请求，获取 socket 放入全局等待读处理队列</li>
<li>主线程处理完读事件之后，通过 RR(Round Robin) 将这些连接分配给这些 IO 线程</li>
<li>主线程阻塞等待 IO 线程读取 socket 完毕</li>
<li>主线程通过单线程的方式执行请求命令，请求数据读取并解析完成，但并不执行</li>
<li>主线程阻塞等待 IO 线程将数据回写 socket 完毕</li>
<li>解除绑定，清空等待队列</li>
</ol>
</li>
<li>
<p>5.3.3 说一下什么是IO多路复用？</p>
<p>多路指的是多个socket连接，复用指的是复用一个线程。多路复用主要有三种技术：select，poll，epoll。epoll是最新的也是目前最好的多路复用技术。采用多路 I/O 复用技术可以让单个线程高效的处理多个连接请求（尽量减少网络IO的时间消耗），且Redis在内存中操作数据的速度非常快（内存内的操作不会成为这里的性能瓶颈），主要以上两点造就了Redis具有很高的吞吐量。</p>
</li>
<li>
<p>5.3.3.1 什么是epoll？</p>
<p>参考<sup class="footnote-ref"><a href="#fn17" id="fnref17">[17]</a></sup>。</p>
<p>select 和 poll 是 Linux 的底层synchronous通信机制。</p>
<p>epoll 是改进版。</p>
</li>
<li>
<p>5.3.4 Redis的基本数据结构？底层是怎么实现的？</p>
<p>参考<sup class="footnote-ref"><a href="#fn18" id="fnref18">[18]</a></sup>。</p>
<ul>
<li>string</li>
<li>list</li>
<li>hash</li>
<li>set</li>
<li>sorted set</li>
</ul>
</li>
<li>
<p>5.3.5 说说Redis的VM机制。</p>
<p>参考<sup class="footnote-ref"><a href="#fn19" id="fnref19">[19]</a></sup>。</p>
<p>Redis自己实现了一套虚拟内存的管理机制。</p>
</li>
<li>
<p>5.3.6 Redis Cluster的功能是？怎么实现的？有限制吗？可以无限扩展吗？</p>
<p>为了解决Redis单机容量有限的问题，提高并发量。本质上就是Sharding，在于扩展主从结构的写能力。<br>
官方推荐最大的节点数量为1000，由于Cluster架构中无Proxy层，Master与Slave之间使用异步replication。<br>
客户端容忍一定程度的数据丢失，集群尽可能保存Client write操作的数据，保证数据一致性。<br>
Redis集群通过partition来提供一定程度的可用性，当集群中的一部分节点失效或者无法进行通讯时，集群仍可以继续提供服务。</p>
<p>参考<sup class="footnote-ref"><a href="#fn20" id="fnref20">[20]</a></sup></p>
</li>
<li>
<p>5.3.6.1 为什么节点数量为1000？</p>
</li>
<li>
<p>5.3.6.2 Key是如何Sharding的？</p>
</li>
<li>
<p>5.3.6.3 什么是一致性哈希算法？如何解决哈希不均衡？</p>
</li>
<li>
<p>5.3.7 如果Redis挂了怎么吗？数据会丢失吗？说说Redis是提供了哪些高可用方案？</p>
<ol>
<li>持久化机制。AOF(Append Only File) 和 RDB (Redis Database)。</li>
<li>主从复制。</li>
<li>哨兵。Sentinel。</li>
<li>Cluster。</li>
</ol>
</li>
<li>
<p>5.3.7.1 具体讲讲持久化两个方案的原理和具体机制，以及如何配置？</p>
<p><sup class="footnote-ref"><a href="#fn21" id="fnref21">[21]</a></sup></p>
</li>
<li>
<p>5.3.7.2 讲讲哨兵Sentinel机制？</p>
</li>
<li>
<p>5.3.7.3 Redis是怎么主从复制的？</p>
</li>
<li>
<p>6 Kafka 是你们自己搭的吗？是怎么配置的？</p>
</li>
<li>
<p>6.1 Kafka为什么这么快？</p>
<ol>
<li>分Partition并行处理。kafka中的topic中的内容可以被分为多分区存在，每个分区又分为多个段，所以每次操作都是针对一小部分做操作，很轻便，并且增加并行操作的能力。</li>
<li>顺序写入磁盘。kafka的消息是不断追加到文件中的，这个特性使kafka可以充分利用磁盘的顺序读写性能，顺序读写不需要硬盘磁头的寻道时间，只需很少的扇区旋转时间，所以速度远快于随机读写。对于SSD而言，同样也是顺序读写速度高于随机读写。</li>
<li>Page Cache，减少写磁盘次数。</li>
<li>压缩，减少传输的数据量。。</li>
<li>批量发送。</li>
<li>零拷贝。利用Linux kernel&quot;零拷贝(zero-copy)&quot;系统调用机制，就是跳过“用户缓冲区”的拷贝，建立一个磁盘空间和内存的直接映射，数据不再复制到“用户态缓冲区”。</li>
</ol>
</li>
<li>
<p>7 怎么部署的服务？</p>
<p>阿里云ACK集群，k8s。</p>
</li>
<li>
<p>8 计量计费这块是怎么做的？怎么防止计费出错？</p>
</li>
<li>
<p>9 怎么做的监控？</p>
</li>
<li>
<p>10 怎么管理短信发送和算法任务的？</p>
</li>
<li>
<p>11 怎么区分不同优先级和不同用户的？</p>
<p>我们在三个维度上区分优先级。</p>
<ol>
<li>短信类型。短信类型可以分成营销、通知和验证码三类，分别对应的通道质量和要求是不一样的。营销短信的时效性通常在一天到一周左右，有可能遭到用户屏蔽。通知类短信的时效性在小时级别，验证码的时效性在分钟级别，因此这三类短信是分别用不同质量的通道账号维护的，会在API服务写入不同的Kafka Topic，每个Topic并行发送，互相独立，超时等配置略有区别，保证验证码短信的时效性和通道质量。</li>
<li>用户类型。在短信类型的维度上区分用户类型，优先保证VIP客户的发送质量，同样使用Topic区隔。</li>
<li>用户间，用户可能会出现一个用户集中发送，导致其他用户排队的情况，目前我们没有专门处理，而是使用Kafka的Key分区机制，让不同uid的客户分配到不同的Partition上去，consumer消费时尽量round robin交叉消费，缓解排队问题。如果有用户需要完全独立不受影响的通道或者更高质量的通道，我们可以增加一系列user_xxx的topic，并且用完全匹配或者正则匹配消费topic。或者在消费端增加用户Specific的Channel。</li>
</ol>
</li>
<li>
<p>11.1 Kafka的Topic有数量限制吗？</p>
</li>
<li>
<p>12 节点挂了怎么处理？升级的时候怎么不影响业务？</p>
</li>
</ul>
<p><strong>算法与模型</strong></p>
<ul>
<li>
<p>1 你们用的哪类算法？效果如何？</p>
</li>
<li>
<p>2 数据怎么清洗的？特征工程怎么做的？</p>
</li>
<li>
<p>3 模型怎么训练的？分布式训练知道怎么做吗？</p>
<ul>
<li>3.1 知道分布式训练的原理吗？</li>
</ul>
</li>
</ul>
<h3><a href="#recommend-engine" class="header-anchor">#</a><span id="recommend-engine"> Recommend Engine</span></h3>
<p><strong>Domain Specific System</strong></p>
<ul>
<li>
<p>1 描述一下系统有哪些模块，是怎么组织的？</p>
</li>
<li>
<p>2 如何训练并Serve模型的？</p>
</li>
</ul>
<p><strong>算法与模型</strong></p>
<ul>
<li>
<p>1 特征工程怎么做？</p>
</li>
<li>
<p>2 线下提升线上效果不好为什么，怎么解决？</p>
</li>
</ul>
<h3><a href="#shen-du-mo-xing-tui-li-xing-neng-you-hua" class="header-anchor">#</a><span id="shen-du-mo-xing-tui-li-xing-neng-you-hua"> 深度模型推理性能优化</span></h3>
<p><strong>框架相关</strong></p>
<p><strong>Device相关</strong></p>
<h3><a href="#zi-yan-fpga-tui-li-jia-su-xin-pian-fang-an" class="header-anchor">#</a><span id="zi-yan-fpga-tui-li-jia-su-xin-pian-fang-an"> 自研FPGA推理加速芯片方案</span></h3>
<p><strong>芯片相关</strong></p>
<p><strong>软件相关</strong></p>
<hr>
<hr class="footnotes-sep">
<section class="footnotes">
<ol class="footnotes-list">
<li id="fn1" class="footnote-item"><p><a target="_blank" rel="noopener" href="https://kubernetes.io/zh/docs/concepts/workloads/pods/pod-lifecycle/">Pod生命周期</a> <a href="#fnref1" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn2" class="footnote-item"><p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/42056183">分布式锁看这篇就够了</a> <a href="#fnref2" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn3" class="footnote-item"><p><a target="_blank" rel="noopener" href="https://juejin.cn/post/6844903688088059912">再有人问你分布式锁，这篇文章扔给他</a> <a href="#fnref3" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn4" class="footnote-item"><p><a target="_blank" rel="noopener" href="https://www.zhihu.com/question/266390197">kafka分布式的情况下，如何保证消息的顺序?</a> <a href="#fnref4" class="footnote-backref">↩︎</a> <a href="#fnref4:1" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn5" class="footnote-item"><p><a target="_blank" rel="noopener" href="https://blog.csdn.net/yidan7063/article/details/108234222">kafka 笔记四 kafka消费者 再均衡</a> <a href="#fnref5" class="footnote-backref">↩︎</a> <a href="#fnref5:1" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn6" class="footnote-item"><p><a target="_blank" rel="noopener" href="https://www.tpvlog.com/article/283">透彻理解Kafka（五）——通信机制：多路复用</a> <a href="#fnref6" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn7" class="footnote-item"><p><a target="_blank" rel="noopener" href="http://www.wangqingzheng.com/huaweiyun/15/218415.html">17 个方面，综合对比 Kafka、RabbitMQ、RocketMQ、ActiveMQ</a> <a href="#fnref7" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn8" class="footnote-item"><p><a target="_blank" rel="noopener" href="https://www.cnblogs.com/detectiveHLH/p/14412391.html">消息队列杂谈</a> <a href="#fnref8" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn9" class="footnote-item"><p><a target="_blank" rel="noopener" href="https://juejin.cn/post/6999572991340183588">Kafka：保证消息不重复不丢失</a> <a href="#fnref9" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn10" class="footnote-item"><p><a target="_blank" rel="noopener" href="https://developer.aliyun.com/article/778789">Hologres产品介绍与技术揭秘</a> <a href="#fnref10" class="footnote-backref">↩︎</a> <a href="#fnref10:1" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn11" class="footnote-item"><p><a target="_blank" rel="noopener" href="https://juejin.cn/post/6986470315584913415">什么时候使用Redis缓存</a> <a href="#fnref11" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn12" class="footnote-item"><p><a target="_blank" rel="noopener" href="https://blog.csdn.net/you18131371836/article/details/118212987">缓存基础----本地缓存、分布式缓存以及多级缓存</a> <a href="#fnref12" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn13" class="footnote-item"><p><a target="_blank" rel="noopener" href="https://blog.csdn.net/a745233700/article/details/113488673">Redis为什么这么快？Redis的线程模型与Redis多线程</a> <a href="#fnref13" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn14" class="footnote-item"><p><a target="_blank" rel="noopener" href="https://www.cnblogs.com/kismetv/p/8654978.html">深入学习Redis（1）：Redis内存模型 </a> <a href="#fnref14" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn15" class="footnote-item"><p><a target="_blank" rel="noopener" href="https://juejin.cn/post/7065960336335044645">Redis 究竟是单线程还是多线程呢？</a> <a href="#fnref15" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn16" class="footnote-item"><p><a target="_blank" rel="noopener" href="https://www.51cto.com/article/616601.html">Redis 6.0 新特性-多线程连环13问！</a> <a href="#fnref16" class="footnote-backref">↩︎</a> <a href="#fnref16:1" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn17" class="footnote-item"><p><a target="_blank" rel="noopener" href="https://segmentfault.com/a/1190000003063859">Linux IO模式及 select、poll、epoll详解</a> <a href="#fnref17" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn18" class="footnote-item"><p><a target="_blank" rel="noopener" href="https://blog.csdn.net/a745233700/article/details/113449889">Redis的五种数据结构的底层实现原理</a> <a href="#fnref18" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn19" class="footnote-item"><p><a target="_blank" rel="noopener" href="https://cloud.tencent.com/developer/article/1846145">拒绝躺平，Redis选择实现了自己的VM</a> <a href="#fnref19" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn20" class="footnote-item"><p><a target="_blank" rel="noopener" href="https://www.cnblogs.com/detectiveHLH/p/14154665.html">深度图解Redis Cluster原理</a> <a href="#fnref20" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn21" class="footnote-item"><p><a target="_blank" rel="noopener" href="https://juejin.cn/post/6844903655527677960">一文看懂Redis的持久化原理</a> <a href="#fnref21" class="footnote-backref">↩︎</a></p>
</li>
</ol>
</section>
</p></div><div class="share"><span>Share</span>&nbsp;<span class="soc"><a href="javascript:(function(){EN_CLIP_HOST='http://www.evernote.com';try{var%20x=document.createElement('SCRIPT');x.type='text/javascript';x.src=EN_CLIP_HOST+'/public/bookmarkClipper.js?'+(new%20Date().getTime()/100000);document.getElementsByTagName('head')[0].appendChild(x);}catch(e){location.href=EN_CLIP_HOST+'/clip.action?url='+encodeURIComponent(location.href)+'&amp;title='+encodeURIComponent(document.title);}})();" ref="nofollow" target="_blank" class="fa fa-bookmark"></a></span><span class="soc"><a href="javascript:void((function(s,d,e){try{}catch(e){}var f='http://service.weibo.com/share/share.php?',u=d.location.href,p=['url=',e(u),'&amp;title=',e(d.title),'&amp;appkey=2924220432'].join('');function a(){if(!window.open([f,p].join(''),'mb',['toolbar=0,status=0,resizable=1,width=620,height=450,left=',(s.width-620)/2,',top=',(s.height-450)/2].join('')))u.href=[f,p].join('');};if(/Firefox/.test(navigator.userAgent)){setTimeout(a,0)}else{a()}})(screen,document,encodeURIComponent));" class="fa fa-weibo"></a></span><span class="soc"><a target="_blank" rel="noopener" href="http://twitter.com/home?status=https://blog.kleon.space/interview/resume/%20KLEON%20Common - Resume" class="fa fa-twitter"></a></span></div><div class="pagination"><p class="clearfix"><span class="pre pagbuttons"><a role="navigation" href="/interview/tech/kubernetes/" title="Tech - Kubernetes"><i class="fa fa-angle-double-left"></i>&nbsp;Previous post: Tech - Kubernetes</a></span><span>&nbsp;</span><span class="next pagbuttons"><a role="navigation" href="/interview/aboard/" title="Common - Aboard">Next post: Common - Aboard&nbsp;<i class="fa fa-angle-double-right"></i></a></span></p></div></div></div></div><div class="visible-xs site-bottom-footer"><footer><p>&copy;&nbsp;2022&nbsp;<a target="_blank" href="https://blog.kleon.space" rel="noopener noreferrer">Kleon</a></p><p>Theme&nbsp;<a target="_blank" href="https://github.com/SumiMakito/hexo-theme-typography" rel="noopener noreferrer">Typography</a>&nbsp;by&nbsp;<a target="_blank" href="https://www.keep.moe" rel="noopener noreferrer">Makito</a></p><p>Proudly published with&nbsp;<a target="_blank" href="https://hexo.io" rel="noopener noreferrer">Hexo</a></p></footer></div></div></div></div><script src="/js/jquery-3.1.0.min.js"></script><script src="/js/bootstrap.min.js"></script><script src="/js/jquery-migrate-1.2.1.min.js"></script><script src="/js/jquery.appear.js"></script><script src="/js/google-analytics.js"></script><script src="/js/typography.js"></script></body></html>