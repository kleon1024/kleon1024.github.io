<!DOCTYPE html><html lang="zh-CN"><head><meta charset="utf-8"><meta name="X-UA-Compatible" content="IE=edge"><meta name="author"><title>机器学习系统 1-10 - 后端硬件框架接入 · KLEON</title><meta name="description" content="在开源背景下，框架在社区的加持下不断迭代，后端硬件通常不能cover所有应用场景，需要接入框架借用框架的能力。那什么样的实现最合适，又会有哪些问题？

按需求不同，可以有多种方法：

不接入

实际上还是借用了框架的模型定义。如果整个模型都能被支持，并且对性能有较高的要求，场景定制，那么可以不接入框"><meta name="og:description" content="在开源背景下，框架在社区的加持下不断迭代，后端硬件通常不能cover所有应用场景，需要接入框架借用框架的能力。那什么样的实现最合适，又会有哪些问题？

按需求不同，可以有多种方法：

不接入

实际上还是借用了框架的模型定义。如果整个模型都能被支持，并且对性能有较高的要求，场景定制，那么可以不接入框"><meta name="twitter:site" content="KLEON"><meta name="twitter:title" content="机器学习系统 1-10 - 后端硬件框架接入"><meta name="twitter:card" content="summary"><meta name="keywords" content=""><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="renderer" content="webkit"><link rel="short icon" href="images/favicon.png" type="image/x-icon"><link rel="stylesheet" href="/css/github.min.css"><link rel="stylesheet" href="/css/bootstrap.min.css"><link rel="stylesheet" href="/css/font-awesome.min.css"><link rel="stylesheet" href="https://lf9-cdn-tos.bytecdntp.com/cdn/expire-1-M/KaTeX/0.10.2/katex.min.css"><link rel="stylesheet" href="/css/style.css"><link rel="alternate" type="application/atom+xml" title="ATOM 1.0" href="/atom.xml"><meta name="generator" content="Hexo 6.1.0"></head><body><div id="stage" class="container"><div class="row"><div id="side-bar" class="col-sm-3 col-xs-12 side-container invisible"><div class="vertical-text site-title"><h3 tabindex="-1" class="site-title-small"><a href="/" class="a-title"></a></h3><h1 tabindex="-1" class="site-title-large"><a href="/" class="a-title">自说自话</a></h1><!--h6(onclick="triggerSiteNav()") Trigger--></div><br class="visible-lg visible-md visible-sm"><div id="site-nav" class="site-title-links"><ul><li><a href="/">Home</a></li><li><a href="/archives">Archive</a></li><li><a href="/categories">Categories</a></li><li><a href="/tags">Tags</a></li><li><a href="/googlebe23cb0bc55fc412.html"></a></li><li><a href="/about/index.html"></a></li><li class="soc"><a href="https://github.com/kleon1024" target="_blank" rel="noopener noreferrer" aria-label="Github"><i class="fa fa-github">&nbsp;</i></a></li></ul><div class="visible-lg visible-md visible-sm site-nav-footer"><br class="site-nav-footer-br"><footer><p>&copy;&nbsp;2022&nbsp;<a target="_blank" href="https://blog.kleon.space" rel="noopener noreferrer">Kleon</a></p><p>Theme&nbsp;<a target="_blank" href="https://github.com/SumiMakito/hexo-theme-typography" rel="noopener noreferrer">Typography</a>&nbsp;by&nbsp;<a target="_blank" href="https://www.keep.moe" rel="noopener noreferrer">Makito</a></p><p>Proudly published with&nbsp;<a target="_blank" href="https://hexo.io" rel="noopener noreferrer">Hexo</a></p></footer></div></div></div><div id="main-container" class="col-sm-9 col-xs-12 main-container invisible"><div class="autopagerize_page_element"><div class="content"><div class="post-page"><div class="post-container"><p class="post-title"><a>机器学习系统 1-10 - 后端硬件框架接入</a></p><p class="post-meta"><span class="date meta-item">Posted at&nbsp;2021-02-03</span><span class="date meta-item">Updated at&nbsp;2021-02-03</span><span class="meta-item"><i class="fa fa-folder"></i><span>&nbsp;</span><a href="/categories/机器学习/" title="机器学习" class="a-tag">机器学习</a><span>&nbsp;</span></span><span class="meta-item"><i class="fa fa-tag"></i><span>&nbsp;</span><a href="/tags/机器学习/" title="机器学习" class="a-tag">机器学习</a><span>&nbsp;</span><a href="/tags/FPGA/" title="FPGA" class="a-tag">FPGA</a><span>&nbsp;</span></span></p><p class="post-abstract"><p>在开源背景下，框架在社区的加持下不断迭代，后端硬件通常不能cover所有应用场景，需要接入框架借用框架的能力。那什么样的实现最合适，又会有哪些问题？</p>
<span id="more"></span>
<p>按需求不同，可以有多种方法：</p>
<ul>
<li>不接入</li>
</ul>
<p>实际上还是借用了框架的模型定义。如果整个模型都能被支持，并且对性能有较高的要求，场景定制，那么可以不接入框架，比如TensorRT可以独立运行。</p>
<p>后端软件栈可能需要不小的开发工作支持长尾算子，达到全图覆盖，对于GPGPU这种适用面极广的后端硬件是可行的，TensorRT也标榜可以达到最高性能。</p>
<ul>
<li>算子内接入</li>
</ul>
<p>最直接的接入方法，利用后端软件接口直接在算子内实现等价逻辑，不用关心模型长什么样，而且不管支持了多少算子都能运行，提高覆盖率只是一个体力活。</p>
<p>这种方法针对计算密集型算子优化明显，尤其是当密集计算占比较高，其他计算和通信几乎不影响系统整体性能的时候。比如基于CNN的一系列模型，都可以用这种简单粗暴的方法先支持起来。</p>
<p>但这种方法的缺点也很明显，一旦计算较分散，每次执行算子都要做一次数据交换，对于图像类模型，带宽占用不低，会拖慢系统整体性能。</p>
<p>而如果为了最大化硬件利用率——计算时间占总运行时间的比例——加入指令队列，不做密集算子的interleaving，可能会引入较高的性能抖动。</p>
<p>除此之外，单算子性能最优并不必然意味着系统性能最优，系统最优通常需要在更高层面协调优化。</p>
<ul>
<li>图层面接入</li>
</ul>
<p>稍微复杂，借用了框架的算子调度能力。主要工作在如何从现有计算图中划分出适合的子图。如果子图过小，那么设备context切换（内存交换，通信）的开销就可能过大。</p>
<p>有时候会分出过多子图，但覆盖率很高，可能是子图间的特殊算子。</p>
<p>如果是训练算子，通常不会占用主计算通路，可以提前使用清理工具去除。</p>
<p>如果是Fusion等优化引入的算子，就可能需要“反编译”，把fuse起来的算子break down。</p>
<p>如果是控制结构切割了子图，需要从建模层面尽量消除控制结果，比如并行，展开，将控制结构放在生成代码而不是计算图里。</p>
<p>如果子图间不存在数据依赖，可以融合子图，减少通信开销。</p>
<p>上面提到的方法都需要根据实际情况取舍，因此，分图算法可能会引入更复杂的策略。比如在估计子图大小上，可以用最简单的个数阈值，也可以构建cost model。</p>
<p>Cost model可以根据shape和算子估算，也可以通过profling测量，后者相对于前者更自动化，并且可以支持运行时（动态）场景，而前者基本可以在编译时（静态）确定。</p>
<p>有时候分图算法过于粗暴，比如直接使用算子集，而后端硬件对结构有要求，则可能出错，需要有fallback机制，或者使用更灵活的模板匹配算法。</p>
<p>由于框架算子层接口可能随大版本更新变动，比如Tensorflow的Grappler（通常是因为protobuf版本问题），可能需要考虑兼容多版本，尽量解耦，复用代码。</p>
<ul>
<li>编译层接入</li>
</ul>
<p>为了用更通用，更自动化的方法优化能，减少手工优化的工作量，不少研究者提出借鉴编译器的思路，其中Tensorflow的XLA算是较早开始尝试的。</p>
<p>XLA<a href="#refer-1"><sup>1</sup></a>同样是在图层面接入的，也有一套分图算法，由于XLA使用的是编译，因此只要标记符合的算子即可。</p>
<p>XLA嵌在Tensorflow中，在运行时JIT执行，在分图后，符合条件的子图会开始编译流程，转换为HLO表示——更小的粗指令集合，如Softmax等算子可能被打散。</p>
<p>转换后的HLO执行一系列的设备无关优化，再交由后端设备Service处理，执行一系列设备相关优化，CPU可以通过LLVM Emitter发射为LLVM IR，交由LLVM编译为CPU后端指令。GPU等较通用设备可以复用LLVM Emitter结构，生成对应的指令。</p>
<p>编译后的指令会缓存在XLA的Compilation Cache中，根据Shape和Op计算Hash值存储索引。</p>
<p>在编译层接入，需要硬件具有一定的通用性，并且要在图层面实现设备相关的分图逻辑。虽然HLO缩小了算子集，但要求对编译后端有足够的了解，开发工作量不小。同样，图层面接口需要注意和版本解耦。</p>
<ul>
<li>其他</li>
</ul>
<p>接入后端的一个重要问题是线程冲突，需要通过全局线程池统一来解决，可以使用同一个线程池实现，或者是可控的线程数量。</p>
<p>编译优化之路总是吸引人的，通用自动化不重复也是人们不屑的追求。如果要全面支持各类框架，工作量也是不小的，通常会是社区为了推广框架，做不少示范性接入工作，测些数据，发些paper。大厂是否跟进，还是取决于最终收益。</p>
<p>不过现实是模型的根基并没有百花齐放，而是依靠一小撮人探索出的最高效的结构趋同了，因此大厂因靠不断累积手工优化经验，也已经能支持成熟可商业化的模型了。而各类编译方法面临的困境是无法在所有场景下大幅超越手工优化，主要是填补长尾空间。</p>
<p>历史积累的力量是强大的，不仅展示了持续规划迭代的惊人成果，同样意味着推到底层设施重来的阻力必然很大。</p>
<hr>
<ul>
<li>[1] <span id="refer-1"></span> <a target="_blank" rel="noopener" href="https://www.tensorflow.org/xla">XLA: Optimizing Compiler for Machine Learning</a></li>
</ul>
</p></div><div class="share"><span>Share</span>&nbsp;<span class="soc"><a href="javascript:(function(){EN_CLIP_HOST='http://www.evernote.com';try{var%20x=document.createElement('SCRIPT');x.type='text/javascript';x.src=EN_CLIP_HOST+'/public/bookmarkClipper.js?'+(new%20Date().getTime()/100000);document.getElementsByTagName('head')[0].appendChild(x);}catch(e){location.href=EN_CLIP_HOST+'/clip.action?url='+encodeURIComponent(location.href)+'&amp;title='+encodeURIComponent(document.title);}})();" ref="nofollow" target="_blank" class="fa fa-bookmark"></a></span><span class="soc"><a href="javascript:void((function(s,d,e){try{}catch(e){}var f='http://service.weibo.com/share/share.php?',u=d.location.href,p=['url=',e(u),'&amp;title=',e(d.title),'&amp;appkey=2924220432'].join('');function a(){if(!window.open([f,p].join(''),'mb',['toolbar=0,status=0,resizable=1,width=620,height=450,left=',(s.width-620)/2,',top=',(s.height-450)/2].join('')))u.href=[f,p].join('');};if(/Firefox/.test(navigator.userAgent)){setTimeout(a,0)}else{a()}})(screen,document,encodeURIComponent));" class="fa fa-weibo"></a></span><span class="soc"><a target="_blank" rel="noopener" href="http://twitter.com/home?status=https://blog.kleon.space/ai/ml-system/hardware-backend/10-framework-integration/%20KLEON%20机器学习系统 1-10 - 后端硬件框架接入" class="fa fa-twitter"></a></span></div><div class="pagination"><p class="clearfix"><span class="pre pagbuttons"><a role="navigation" href="/ai/ml-system/hardware-backend/11-system/" title="机器学习系统 1-11 - 后端硬件系统"><i class="fa fa-angle-double-left"></i>&nbsp;Previous post: 机器学习系统 1-11 - 后端硬件系统</a></span><span>&nbsp;</span><span class="next pagbuttons"><a role="navigation" href="/ai/ml-system/hardware-backend/9-compiler/" title="机器学习系统 1-9 - 后端硬件编译器">Next post: 机器学习系统 1-9 - 后端硬件编译器&nbsp;<i class="fa fa-angle-double-right"></i></a></span></p></div></div></div></div><div class="visible-xs site-bottom-footer"><footer><p>&copy;&nbsp;2022&nbsp;<a target="_blank" href="https://blog.kleon.space" rel="noopener noreferrer">Kleon</a></p><p>Theme&nbsp;<a target="_blank" href="https://github.com/SumiMakito/hexo-theme-typography" rel="noopener noreferrer">Typography</a>&nbsp;by&nbsp;<a target="_blank" href="https://www.keep.moe" rel="noopener noreferrer">Makito</a></p><p>Proudly published with&nbsp;<a target="_blank" href="https://hexo.io" rel="noopener noreferrer">Hexo</a></p></footer></div></div></div></div><script src="/js/jquery-3.1.0.min.js"></script><script src="/js/bootstrap.min.js"></script><script src="/js/jquery-migrate-1.2.1.min.js"></script><script src="/js/jquery.appear.js"></script><script src="/js/google-analytics.js"></script><script src="/js/typography.js"></script></body></html>